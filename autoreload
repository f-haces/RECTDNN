{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c2de42c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTEBOOK IMPORTS\n",
    "import os, glob, warnings, pickle\n",
    "import numpy as np\n",
    "from shutil import copyfile, rmtree\n",
    "from datetime import datetime\n",
    "\n",
    "# IMAGE IMPORTS\n",
    "from PIL import Image, TiffImagePlugin\n",
    "import cv2\n",
    "\n",
    "# GIS IMPORTS\n",
    "from affine import Affine\n",
    "import pandas as pd\n",
    "\n",
    "# PLOTTING IMPORTS\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# CUSTOM UTILITIES\n",
    "from IndexUtils import * \n",
    "\n",
    "Image.MAX_IMAGE_PIXELS = 933120000\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "initialize = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e1955696",
   "metadata": {},
   "outputs": [],
   "source": [
    "username = os.getlogin()\n",
    "\n",
    "dnn_params = {}\n",
    "dnn_params['CLNN'] = {}\n",
    "dnn_params['TPNN'] = {\"legacy\" : True}\n",
    "dnn_params['RLNN'] = {}\n",
    "dnn_params['FLNN'] = {}\n",
    "dnn_params['TLNN'] = {}\n",
    "\n",
    "\n",
    "if username == 'fhacesga':\n",
    "    base_input_path   = r\"D:\\RECTDNN\\Uncompress\\\\\"\n",
    "    base_output_path  = r\"D:\\RECTDNN\\processing\\\\\"\n",
    "    ref_dir  = r\"C:\\Users\\fhacesga\\OneDrive - University Of Houston\\AAA_RECTDNN\\data\\AAA_ReferenceDatasets\\\\\"\n",
    "elif username == 'fhace':\n",
    "    base_input_path   = r\"C:\\Users\\fhace\\Desktop\\FIRMs\\data\\Uncompress\\\\\"\n",
    "    ref_dir = r\"C:\\Users\\fhace\\Desktop\\FIRMs\\data\\AAA_ReferenceDatasets\\\\\"\n",
    "    base_output_path = r\"C:\\Users\\fhace\\Desktop\\FIRMs\\data\\Outputs\\\\\"\n",
    "    # dnn_params['TLNN']['model_weights']    = r\"C:\\Users\\fhace\\Desktop\\FIRMs\\data\\BBNN\\curr_weights.pt\"\n",
    "    dnn_params['CLNN']['model_checkpoint'] = r\"C:\\Users\\fhace\\Desktop\\FIRMs\\data\\RLNN\\checkpoint_101423.pth\"\n",
    "    dnn_params['TPNN']['model_checkpoint'] = r\"C:\\Users\\fhace\\OneDrive - University Of Houston\\AAA_RECTDNN\\data\\TPNN\\checkpoint_091523_pyramids_2.pth\"\n",
    "    dnn_params['RLNN']['model_checkpoint'] = r\"C:\\Users\\fhace\\OneDrive - University Of Houston\\AAA_RECTDNN\\data\\RLNN\\checkpoint_091323.pth\"\n",
    "    \n",
    "else:\n",
    "    base_input_path   = r\"D:\\Desktop\\FIRMsDigitizing\\data\\HistoricalFIRMS\"\n",
    "    base_output_path  = r\"D:\\Desktop\\FIRMsDigitizing\\processing\"\n",
    "    ref_dir  = r\"C:\\Users\\franc\\OneDrive - University Of Houston\\AAA_RECTDNN\\data\\AAA_ReferenceDatasets\\\\\"\n",
    "\n",
    "if not initialize:\n",
    "    initialize = init_databases(ref_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d07c8310",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAKE PROCESSING DIRECTORY\n",
    "datetime_str = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "proc_dir     = os.path.join(base_output_path, datetime_str)\n",
    "\n",
    "# IF THERE ARE ANY ZIP FILES IN DIRECTORY, UNZIP THEM IN PLACE\n",
    "if len(glob.glob(base_input_path + \"*.zip*\")) != 0:\n",
    "    extractZipFiles(base_input_path, base_input_path)\n",
    "\n",
    "outputs_dir  = os.path.join(proc_dir, \"Outputs\")\n",
    "os.makedirs(outputs_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1aa8d4c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_files = []\n",
    "\n",
    "for filename in tqdm(glob.glob(base_input_path + \"\\\\*.tif*\")):\n",
    "    tiff_file = os.path.join(base_input_path, filename)\n",
    "    try:\n",
    "    # Check if the file is a multi-page TIFF\n",
    "        with Image.open(tiff_file) as img:\n",
    "            if img.is_animated:    \n",
    "                print(f\"Expanding {os.path.basename(tiff_file)} into {img.n_frames}\")\n",
    "                for i in range(img.n_frames):\n",
    "                    try:\n",
    "                        img.seek(i)\n",
    "                        output_filename = f\"{os.path.splitext(tiff_file)[0]}_{i+1}{os.path.splitext(tiff_file)[1]}\"\n",
    "                        img.save(output_filename, format=img.format)\n",
    "                    except:\n",
    "                        print(f\"Error with {tiff_file} page {i}\")\n",
    "                        continue\n",
    "                remove_files.append(tiff_file)\n",
    "    except Exception as e:\n",
    "        print(f\"Error opening {tiff_file}\")\n",
    "        print(e)\n",
    "        continue\n",
    "\n",
    "for tiff_file in remove_files:\n",
    "    os.remove(tiff_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a1cef0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LIST ALL IMAGES IN DIRECTORY\n",
    "image_files = glob.glob(f\"{base_input_path}/*48201*\")\n",
    "\n",
    "# FILTER IMAGES USING HEURISTICS\n",
    "patterns = [\"IND\", \"_1.\"]\n",
    "index_files = [file for pattern in patterns for file in glob.glob(base_input_path + \"\\\\*48201*\" + pattern + \"*\")]\n",
    "filtered_files = [file for file in image_files if len(os.path.basename(file)) < 12]\n",
    "index_files.extend(filtered_files)\n",
    "\n",
    "# CREATE DATAFRAME\n",
    "index_files = pd.DataFrame(index_files, columns=[\"FilePath\"])\n",
    "\n",
    "# INDEX ATTRIBUTES TO BE ADDED\n",
    "index_files[\"Basename\"] = [os.path.basename(file) for file in index_files[\"FilePath\"].to_list()]    # BASENAME\n",
    "index_files[\"Location\"] = index_files[\"Basename\"].apply(extract_numerical_chars).astype(np.int32)   # \n",
    "index_files[\"GEOID\"]    = index_files[\"Location\"].apply(getGEOID)       # GET GEOID FOR EACH INDEX\n",
    "index_files[\"geometry\"] = index_files[\"GEOID\"].apply(getGeometry)       # GET GEOMETRY FROM MATCHING GEOIDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "91f80b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "verbose = True\n",
    "\n",
    "TPNN = None\n",
    "RLNN = None\n",
    "CLNN = None\n",
    "\n",
    "try:\n",
    "    gen_dict\n",
    "    print(\"Starting with predefined dict\")\n",
    "except:\n",
    "    gen_dict = {}\n",
    "\n",
    "for i, row in tqdm(index_files.iterrows(), total=index_files.shape[0]):\n",
    "    \n",
    "        filename = os.path.basename(row[\"FilePath\"])\n",
    "        \n",
    "        if os.path.exists(os.path.join(outputs_dir, f\"{filename}.pkl\")):\n",
    "             print(f\"Skipping, found {os.path.join(outputs_dir, filename + '.pkl')}\")\n",
    "             continue\n",
    "\n",
    "        # READ FILES AND CONVERT TO GRAYSCALE\n",
    "        image = cv2.imread(row[\"FilePath\"])\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        image_arry = np.asarray(image)\n",
    "        \n",
    "        # SAVE IMAGE TO OUTPUT DIRECTORY\n",
    "        output_image_fn = os.path.join(outputs_dir, filename.split(\".\")[0] + \".tif\")\n",
    "        copyfile(row[\"FilePath\"], output_image_fn)\n",
    "\n",
    "        # GET BOUNDARY POINTS FROM RESPECTIVE SHAPEFILE\n",
    "        output = getBoundaryPoints(row, distance=100)\n",
    "        if output is None:\n",
    "            print(f\"COULD NOT FIND SHAPEFILE FOR {filename}\")\n",
    "            continue\n",
    "        point_boundary_gdf, shp_bounds = output\n",
    "        \n",
    "        # RUN IMAGES THROUGH DNNs\n",
    "        classifications, TPNN  = findKeypoints(image, model=TPNN, **dnn_params['TPNN'])\n",
    "        effectiveArea, RLNN    = findSquares(image, model=RLNN, **dnn_params['RLNN'])\n",
    "        countyArea, CLNN       = findCounty(image, model=CLNN, **dnn_params['CLNN'])\n",
    "        # tiles, TLNN            = findTiles(row[\"FilePath\"], model=TLNN, **dnn_params['TLNN'], verbose=False, device=\"cuda\",\n",
    "        #                                    save_dir=os.path.join(outputs_dir, filename.split(\".\")[0] + \"_BBNN.tif\"))\n",
    "\n",
    "        # tiles, TLNN = runTLNN(row['FilePath'])\n",
    "\n",
    "        dnn_outputs = {\n",
    "            \"classifications\"   : classifications,\n",
    "            \"effectiveArea\"     : effectiveArea,\n",
    "            \"countyArea\"    : countyArea,\n",
    "            # \"tiles\"         : tiles\n",
    "        }\n",
    "        \n",
    "        # GET COUNTY BOUNDS IDENTIFIED IN INDEX BY TLNN\n",
    "        # bounds_panels = tiles[\"county\"][\"bbox\"]\n",
    "        bounds_panels = find_bbox(dnn_outputs['countyArea'][:, :, 1])\n",
    "\n",
    "        # SKIP IF WE CAN'T FIND BOUNDARY IN EXISTING DATABASES\n",
    "        if point_boundary_gdf is None:\n",
    "            continue\n",
    "\n",
    "        # DEFINE BOUNDARY STRUCTU\n",
    "        boundaries = {\n",
    "            \"point_boundary_gdf\"    : point_boundary_gdf,\n",
    "            \"shp_bounds\"            : shp_bounds,\n",
    "            \"bounds_panels\"         : bounds_panels,\n",
    "        }\n",
    "\n",
    "        # WHAT ARE WE LOOKING FOR IN EACH IDENTIFIED SQUARE?\n",
    "        key = findKey(row[\"Basename\"])    \n",
    "        if key is None:\n",
    "            print(f\"Could not find key in {filename}\")\n",
    "        \n",
    "        # DO ICP\n",
    "        transform_dict = performICPonIndex(boundaries, dnn_outputs, debug=False, plot=True, rotation=True, shear=False, perspective=False, icp_iterations=30)\n",
    "\n",
    "        # GET TRANSFORM FROM ICP TO CRS TRANSFORM\n",
    "        output_transform, transform_dict = ICPtoCRSTransform(image_arry, transform_dict)\n",
    "\n",
    "        # GET OUTPUT TRANSFORM INTO AFFINE AND WRITE\n",
    "        output_affine = Affine(*output_transform.flatten()[:6])\n",
    "        with rio.open(output_image_fn, 'w',\n",
    "            driver='GTiff',\n",
    "            height=image.shape[0], width=image.shape[1],\n",
    "            count=1, dtype=image.dtype,\n",
    "            crs=f'EPSG:3857',\n",
    "            transform=rio.Affine(*output_transform.flatten()[:6])) as dst:\n",
    "                dst.write(image, 1)   \n",
    "\n",
    "        tiles['transform_info'] = transform_dict\n",
    "        tiles['output_transform'] = output_transform\n",
    "        gen_dict[filename] = tiles\n",
    "\n",
    "        with open(os.path.join(outputs_dir, f\"{filename}.pkl\"), 'wb') as handle:\n",
    "            pickle.dump(gen_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "\n",
    "with open(os.path.join(outputs_dir, \"IndexCoords.pkl\"), 'wb') as handle:\n",
    "    pickle.dump(gen_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "806f5969",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 3, figsize=(15, 5))\n",
    "axs[0].imshow(image, cmap=\"Greys_r\")\n",
    "axs[1].imshow(dnn_outputs[\"countyArea\"][:, :, 1])\n",
    "axs[2].imshow(cv2.dilate(thin_image, kernel=np.ones((10,10))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0407e21e",
   "metadata": {},
   "outputs": [],
   "source": [
    "thin_image = getCountyBoundaryFromImage(dnn_outputs[\"countyArea\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2a8ad2c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 3, figsize=(15, 5))\n",
    "axs[0].imshow(image, cmap=\"Greys_r\")\n",
    "axs[1].imshow(dnn_outputs[\"countyArea\"][:, :, 1])\n",
    "axs[2].imshow(cv2.dilate(thin_image, kernel=np.ones((10,10))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2a0594bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 3, figsize=(15, 5))\n",
    "axs[0].imshow(image, cmap=\"Greys_r\")\n",
    "axs[1].imshow(dnn_outputs[\"countyArea\"][:, :, 1])\n",
    "axs[2].imshow(cv2.dilate(thin_image, kernel=np.ones((10,10))))\n",
    "\n",
    "for ax in axs:\n",
    "    ax.set_xticks([])\n",
    "    ax.set_xticks([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1f77a14a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(15, 9))\n",
    "axs[0].imshow(image, cmap=\"Greys_r\")\n",
    "# axs[1].imshow(dnn_outputs[\"countyArea\"][:, :, 1])\n",
    "axs[1].imshow(cv2.dilate(thin_image, kernel=np.ones((25,25))))\n",
    "\n",
    "for ax in axs:\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fb065a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(15, 9))\n",
    "axs[0].imshow(cv2.dilate(image, kernel=np.ones((5,5))), cmap=\"Greys_r\")\n",
    "# axs[1].imshow(dnn_outputs[\"countyArea\"][:, :, 1])\n",
    "axs[1].imshow(cv2.dilate(thin_image, kernel=np.ones((25,25))))\n",
    "\n",
    "axs['0']\n",
    "\n",
    "for ax in axs:\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "00e73901",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(15, 9))\n",
    "axs[0].imshow(cv2.erode(image, kernel=np.ones((5,5))), cmap=\"Greys_r\")\n",
    "# axs[1].imshow(dnn_outputs[\"countyArea\"][:, :, 1])\n",
    "axs[1].imshow(cv2.dilate(thin_image, kernel=np.ones((25,25))))\n",
    "\n",
    "axs[0].set_title('Example Tile Index')\n",
    "axs[1].set_title('County Boundary Detected by Convolutional DNN')\n",
    "\n",
    "for ax in axs:\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "287f93f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(15, 12))\n",
    "axs[0].imshow(cv2.erode(image, kernel=np.ones((5,5))), cmap=\"Greys_r\")\n",
    "# axs[1].imshow(dnn_outputs[\"countyArea\"][:, :, 1])\n",
    "axs[1].imshow(cv2.dilate(thin_image, kernel=np.ones((25,25))))\n",
    "\n",
    "# axs[0].set_title('Example Tile Index')\n",
    "# axs[1].set_title('County Boundary Detected by Convolutional DNN')\n",
    "\n",
    "for ax in axs:\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c631e6fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(probability_to_rgb(dnn_outputs['classifications']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "26fc0c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_dict = performICPonIndex(boundaries, dnn_outputs, debug=False, plot=True, rotation=True, shear=False, perspective=False, icp_iterations=1, plot_every=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "16e8c51d",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_dict = performICPonIndex(boundaries, dnn_outputs, debug=False, plot=True, rotation=True, shear=False, perspective=False, icp_iterations=10, plot_every=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2bc263f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_dict = performICPonIndex(boundaries, dnn_outputs, debug=False, plot=True, rotation=True, shear=False, perspective=False, icp_iterations=10, plot_every=1)"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
