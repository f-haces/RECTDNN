{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c7621809",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTEBOOK IMPORTS\n",
    "import os, glob, warnings, pickle\n",
    "import numpy as np\n",
    "from shutil import copyfile, rmtree\n",
    "from datetime import datetime\n",
    "\n",
    "# IMAGE IMPORTS\n",
    "from PIL import Image, TiffImagePlugin\n",
    "import cv2\n",
    "\n",
    "# GIS IMPORTS\n",
    "from affine import Affine\n",
    "import pandas as pd\n",
    "\n",
    "# PLOTTING IMPORTS\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# CUSTOM UTILITIES\n",
    "from IndexUtils import * \n",
    "\n",
    "Image.MAX_IMAGE_PIXELS = 933120000\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "initialize = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ed09b63",
   "metadata": {},
   "source": [
    "IO directories depending on which machine. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "34617015",
   "metadata": {},
   "outputs": [],
   "source": [
    "username = os.getlogin()\n",
    "\n",
    "dnn_params = {}\n",
    "dnn_params['CLNN'] = {}\n",
    "dnn_params['TPNN'] = {}\n",
    "dnn_params['RLNN'] = {}\n",
    "dnn_params['FLNN'] = {}\n",
    "dnn_params['TLNN'] = {}\n",
    "\n",
    "\n",
    "if username == 'fhacesga':\n",
    "    base_input_path   = r\"D:\\RECTDNN\\Uncompress\\\\\"\n",
    "    base_output_path  = r\"D:\\RECTDNN\\processing\\\\\"\n",
    "    ref_dir  = r\"C:\\Users\\fhacesga\\OneDrive - University Of Houston\\AAA_RECTDNN\\data\\AAA_ReferenceDatasets\\\\\"\n",
    "elif username == 'fhace':\n",
    "    base_input_path   = r\"C:\\Users\\fhace\\Desktop\\FIRMs\\data\\Uncompress\\\\\"\n",
    "    ref_dir = r\"C:\\Users\\fhace\\Desktop\\FIRMs\\data\\AAA_ReferenceDatasets\\\\\"\n",
    "    base_output_path = r\"C:\\Users\\fhace\\Desktop\\FIRMs\\data\\Outputs\\\\\"\n",
    "    # dnn_params['TLNN']['model_weights']    = r\"C:\\Users\\fhace\\Desktop\\FIRMs\\data\\BBNN\\curr_weights.pt\"\n",
    "    dnn_params['CLNN']['model_checkpoint'] = r\"C:\\Users\\fhace\\Desktop\\FIRMs\\data\\RLNN\\checkpoint_101423.pth\"\n",
    "    dnn_params['TPNN']['model_checkpoint'] = r\"C:\\Users\\fhace\\OneDrive - University Of Houston\\AAA_RECTDNN\\data\\TPNN\\checkpoint_091523_pyramids_2.pth\"\n",
    "    dnn_params['RLNN']['model_checkpoint'] = r\"C:\\Users\\fhace\\OneDrive - University Of Houston\\AAA_RECTDNN\\data\\RLNN\\checkpoint_091323.pth\"\n",
    "    \n",
    "else:\n",
    "    base_input_path   = r\"D:\\Desktop\\FIRMsDigitizing\\data\\HistoricalFIRMS\"\n",
    "    base_output_path  = r\"D:\\Desktop\\FIRMsDigitizing\\processing\"\n",
    "    ref_dir  = r\"C:\\Users\\franc\\OneDrive - University Of Houston\\AAA_RECTDNN\\data\\AAA_ReferenceDatasets\\\\\"\n",
    "\n",
    "if not initialize:\n",
    "    initialize = init_databases(ref_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5ca1967",
   "metadata": {},
   "source": [
    "Create working dir and unzip all files if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eca9abcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAKE PROCESSING DIRECTORY\n",
    "datetime_str = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "proc_dir     = os.path.join(base_output_path, datetime_str)\n",
    "\n",
    "# IF THERE ARE ANY ZIP FILES IN DIRECTORY, UNZIP THEM IN PLACE\n",
    "if len(glob.glob(base_input_path + \"*.zip*\")) != 0:\n",
    "    extractZipFiles(base_input_path, base_input_path)\n",
    "\n",
    "outputs_dir  = os.path.join(proc_dir, \"Outputs\")\n",
    "os.makedirs(outputs_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "469fbdb7",
   "metadata": {},
   "source": [
    "Read through all the images in the directory. Some images are saved as Multi-page TIFF files. These need to be exported into individual images. We'll do that first in-place at uncompressed directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea68a26c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4559611d61ee48159e0a020a92b89308",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1710 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error opening C:\\Users\\fhace\\Desktop\\FIRMs\\data\\Uncompress\\485479B.tif\n",
      "cannot identify image file 'C:\\\\Users\\\\fhace\\\\Desktop\\\\FIRMs\\\\data\\\\Uncompress\\\\485479B.tif'\n",
      "Error opening C:\\Users\\fhace\\Desktop\\FIRMs\\data\\Uncompress\\485479C.tif\n",
      "cannot identify image file 'C:\\\\Users\\\\fhace\\\\Desktop\\\\FIRMs\\\\data\\\\Uncompress\\\\485479C.tif'\n",
      "Error opening C:\\Users\\fhace\\Desktop\\FIRMs\\data\\Uncompress\\485481A.tif\n",
      "cannot identify image file 'C:\\\\Users\\\\fhace\\\\Desktop\\\\FIRMs\\\\data\\\\Uncompress\\\\485481A.tif'\n",
      "Error opening C:\\Users\\fhace\\Desktop\\FIRMs\\data\\Uncompress\\485510.tif\n",
      "cannot identify image file 'C:\\\\Users\\\\fhace\\\\Desktop\\\\FIRMs\\\\data\\\\Uncompress\\\\485510.tif'\n",
      "Error opening C:\\Users\\fhace\\Desktop\\FIRMs\\data\\Uncompress\\485510B.tif\n",
      "cannot identify image file 'C:\\\\Users\\\\fhace\\\\Desktop\\\\FIRMs\\\\data\\\\Uncompress\\\\485510B.tif'\n",
      "Error opening C:\\Users\\fhace\\Desktop\\FIRMs\\data\\Uncompress\\485514B.tif\n",
      "cannot identify image file 'C:\\\\Users\\\\fhace\\\\Desktop\\\\FIRMs\\\\data\\\\Uncompress\\\\485514B.tif'\n",
      "Error opening C:\\Users\\fhace\\Desktop\\FIRMs\\data\\Uncompress\\485516A.tif\n",
      "cannot identify image file 'C:\\\\Users\\\\fhace\\\\Desktop\\\\FIRMs\\\\data\\\\Uncompress\\\\485516A.tif'\n"
     ]
    }
   ],
   "source": [
    "remove_files = []\n",
    "\n",
    "for filename in tqdm(glob.glob(base_input_path + \"\\\\*.tif*\")):\n",
    "    tiff_file = os.path.join(base_input_path, filename)\n",
    "    try:\n",
    "    # Check if the file is a multi-page TIFF\n",
    "        with Image.open(tiff_file) as img:\n",
    "            if img.is_animated:    \n",
    "                print(f\"Expanding {os.path.basename(tiff_file)} into {img.n_frames}\")\n",
    "                for i in range(img.n_frames):\n",
    "                    try:\n",
    "                        img.seek(i)\n",
    "                        output_filename = f\"{os.path.splitext(tiff_file)[0]}_{i+1}{os.path.splitext(tiff_file)[1]}\"\n",
    "                        img.save(output_filename, format=img.format)\n",
    "                    except:\n",
    "                        print(f\"Error with {tiff_file} page {i}\")\n",
    "                        continue\n",
    "                remove_files.append(tiff_file)\n",
    "    except Exception as e:\n",
    "        print(f\"Error opening {tiff_file}\")\n",
    "        print(e)\n",
    "        continue\n",
    "\n",
    "for tiff_file in remove_files:\n",
    "    os.remove(tiff_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acac9f90",
   "metadata": {},
   "source": [
    "Here we're using heuristics to identify indices within all the image files. These include:\n",
    "- Files that are shorter than 12 characters\n",
    "- Files that have the ```IND``` marker\n",
    "\n",
    "We create a Pandas DataFrame with the files matching. We then add several fields as below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d5180ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LIST ALL IMAGES IN DIRECTORY\n",
    "image_files = glob.glob(f\"{base_input_path}/*\")\n",
    "\n",
    "# FILTER IMAGES USING HEURISTICS\n",
    "patterns = [\"IND\", \"_1.\"]\n",
    "index_files = [file for pattern in patterns for file in glob.glob(base_input_path + \"\\\\*\" + pattern + \"*\")]\n",
    "filtered_files = [file for file in image_files if len(os.path.basename(file)) < 12]\n",
    "index_files.extend(filtered_files)\n",
    "\n",
    "# CREATE DATAFRAME\n",
    "index_files = pd.DataFrame(index_files, columns=[\"FilePath\"])\n",
    "\n",
    "# INDEX ATTRIBUTES TO BE ADDED\n",
    "index_files[\"Basename\"] = [os.path.basename(file) for file in index_files[\"FilePath\"].to_list()]    # BASENAME\n",
    "index_files[\"Location\"] = index_files[\"Basename\"].apply(extract_numerical_chars).astype(np.int32)   # \n",
    "index_files[\"GEOID\"]    = index_files[\"Location\"].apply(getGEOID)       # GET GEOID FOR EACH INDEX\n",
    "index_files[\"geometry\"] = index_files[\"GEOID\"].apply(getGeometry)       # GET GEOMETRY FROM MATCHING GEOIDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "544b54fd",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "250e4c6f16ae4adcba3793dcc4ef1881",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/183 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\fhace\\Desktop\\FIRMs\\RECTDNN\\IndexGeoreferencing.ipynb Cell 10\u001b[0m line \u001b[0;36m2\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/fhace/Desktop/FIRMs/RECTDNN/IndexGeoreferencing.ipynb#X12sZmlsZQ%3D%3D?line=229'>230</a>\u001b[0m effectiveArea, RLNN    \u001b[39m=\u001b[39m findSquares(image, model\u001b[39m=\u001b[39mRLNN, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mdnn_params[\u001b[39m'\u001b[39m\u001b[39mRLNN\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/fhace/Desktop/FIRMs/RECTDNN/IndexGeoreferencing.ipynb#X12sZmlsZQ%3D%3D?line=230'>231</a>\u001b[0m countyArea, CLNN       \u001b[39m=\u001b[39m findCounty(image, model\u001b[39m=\u001b[39mCLNN, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mdnn_params[\u001b[39m'\u001b[39m\u001b[39mCLNN\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m--> <a href='vscode-notebook-cell:/c%3A/Users/fhace/Desktop/FIRMs/RECTDNN/IndexGeoreferencing.ipynb#X12sZmlsZQ%3D%3D?line=231'>232</a>\u001b[0m tiles, TLNN            \u001b[39m=\u001b[39m findTiles(row[\u001b[39m\"\u001b[39;49m\u001b[39mFilePath\u001b[39;49m\u001b[39m\"\u001b[39;49m], model\u001b[39m=\u001b[39;49mTLNN, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mdnn_params[\u001b[39m'\u001b[39;49m\u001b[39mTLNN\u001b[39;49m\u001b[39m'\u001b[39;49m], verbose\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/fhace/Desktop/FIRMs/RECTDNN/IndexGeoreferencing.ipynb#X12sZmlsZQ%3D%3D?line=232'>233</a>\u001b[0m                                    save_dir\u001b[39m=\u001b[39;49mos\u001b[39m.\u001b[39;49mpath\u001b[39m.\u001b[39;49mjoin(outputs_dir, filename\u001b[39m.\u001b[39;49msplit(\u001b[39m\"\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m\"\u001b[39;49m)[\u001b[39m0\u001b[39;49m] \u001b[39m+\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39m_BBNN.tif\u001b[39;49m\u001b[39m\"\u001b[39;49m))\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/fhace/Desktop/FIRMs/RECTDNN/IndexGeoreferencing.ipynb#X12sZmlsZQ%3D%3D?line=234'>235</a>\u001b[0m dnn_outputs \u001b[39m=\u001b[39m {\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/fhace/Desktop/FIRMs/RECTDNN/IndexGeoreferencing.ipynb#X12sZmlsZQ%3D%3D?line=235'>236</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mclassifications\u001b[39m\u001b[39m\"\u001b[39m   : classifications,\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/fhace/Desktop/FIRMs/RECTDNN/IndexGeoreferencing.ipynb#X12sZmlsZQ%3D%3D?line=236'>237</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39meffectiveArea\u001b[39m\u001b[39m\"\u001b[39m     : effectiveArea,\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/fhace/Desktop/FIRMs/RECTDNN/IndexGeoreferencing.ipynb#X12sZmlsZQ%3D%3D?line=237'>238</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mcountyArea\u001b[39m\u001b[39m\"\u001b[39m    : countyArea,\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/fhace/Desktop/FIRMs/RECTDNN/IndexGeoreferencing.ipynb#X12sZmlsZQ%3D%3D?line=238'>239</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtiles\u001b[39m\u001b[39m\"\u001b[39m         : tiles\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/fhace/Desktop/FIRMs/RECTDNN/IndexGeoreferencing.ipynb#X12sZmlsZQ%3D%3D?line=239'>240</a>\u001b[0m }\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/fhace/Desktop/FIRMs/RECTDNN/IndexGeoreferencing.ipynb#X12sZmlsZQ%3D%3D?line=241'>242</a>\u001b[0m \u001b[39m# GET COUNTY BOUNDS IDENTIFIED IN INDEX BY TLNN\u001b[39;00m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/fhace/Desktop/FIRMs/RECTDNN/IndexGeoreferencing.ipynb#X12sZmlsZQ%3D%3D?line=242'>243</a>\u001b[0m \u001b[39m# bounds_panels = tiles[\"county\"][\"bbox\"]\u001b[39;00m\n",
      "\u001b[1;32mc:\\Users\\fhace\\Desktop\\FIRMs\\RECTDNN\\IndexGeoreferencing.ipynb Cell 10\u001b[0m line \u001b[0;36m1\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/fhace/Desktop/FIRMs/RECTDNN/IndexGeoreferencing.ipynb#X12sZmlsZQ%3D%3D?line=171'>172</a>\u001b[0m bbox \u001b[39m=\u001b[39m bbox \u001b[39m*\u001b[39m im_size_arry\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/fhace/Desktop/FIRMs/RECTDNN/IndexGeoreferencing.ipynb#X12sZmlsZQ%3D%3D?line=173'>174</a>\u001b[0m \u001b[39m# GET ID FROM TILE\u001b[39;00m\n\u001b[1;32m--> <a href='vscode-notebook-cell:/c%3A/Users/fhace/Desktop/FIRMs/RECTDNN/IndexGeoreferencing.ipynb#X12sZmlsZQ%3D%3D?line=174'>175</a>\u001b[0m text \u001b[39m=\u001b[39m pytesseract\u001b[39m.\u001b[39;49mimage_to_string(data, config\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m--psm 12 --oem 3\u001b[39;49m\u001b[39m'\u001b[39;49m) \u001b[39m# -c tessedit_char_whitelist=0123456789\u001b[39;00m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/fhace/Desktop/FIRMs/RECTDNN/IndexGeoreferencing.ipynb#X12sZmlsZQ%3D%3D?line=175'>176</a>\u001b[0m word \u001b[39m=\u001b[39m find_word_with_key(text, key, threshold\u001b[39m=\u001b[39m\u001b[39m80\u001b[39m, verbose\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/fhace/Desktop/FIRMs/RECTDNN/IndexGeoreferencing.ipynb#X12sZmlsZQ%3D%3D?line=177'>178</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(word, \u001b[39mlist\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\fhace\\miniforge-pypy3\\envs\\yolo\\lib\\site-packages\\pytesseract\\pytesseract.py:486\u001b[0m, in \u001b[0;36mimage_to_string\u001b[1;34m(image, lang, config, nice, output_type, timeout)\u001b[0m\n\u001b[0;32m    481\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    482\u001b[0m \u001b[39mReturns the result of a Tesseract OCR run on the provided image to string\u001b[39;00m\n\u001b[0;32m    483\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    484\u001b[0m args \u001b[39m=\u001b[39m [image, \u001b[39m'\u001b[39m\u001b[39mtxt\u001b[39m\u001b[39m'\u001b[39m, lang, config, nice, timeout]\n\u001b[1;32m--> 486\u001b[0m \u001b[39mreturn\u001b[39;00m {\n\u001b[0;32m    487\u001b[0m     Output\u001b[39m.\u001b[39;49mBYTES: \u001b[39mlambda\u001b[39;49;00m: run_and_get_output(\u001b[39m*\u001b[39;49m(args \u001b[39m+\u001b[39;49m [\u001b[39mTrue\u001b[39;49;00m])),\n\u001b[0;32m    488\u001b[0m     Output\u001b[39m.\u001b[39;49mDICT: \u001b[39mlambda\u001b[39;49;00m: {\u001b[39m'\u001b[39;49m\u001b[39mtext\u001b[39;49m\u001b[39m'\u001b[39;49m: run_and_get_output(\u001b[39m*\u001b[39;49margs)},\n\u001b[0;32m    489\u001b[0m     Output\u001b[39m.\u001b[39;49mSTRING: \u001b[39mlambda\u001b[39;49;00m: run_and_get_output(\u001b[39m*\u001b[39;49margs),\n\u001b[0;32m    490\u001b[0m }[output_type]()\n",
      "File \u001b[1;32mc:\\Users\\fhace\\miniforge-pypy3\\envs\\yolo\\lib\\site-packages\\pytesseract\\pytesseract.py:489\u001b[0m, in \u001b[0;36mimage_to_string.<locals>.<lambda>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    481\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    482\u001b[0m \u001b[39mReturns the result of a Tesseract OCR run on the provided image to string\u001b[39;00m\n\u001b[0;32m    483\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    484\u001b[0m args \u001b[39m=\u001b[39m [image, \u001b[39m'\u001b[39m\u001b[39mtxt\u001b[39m\u001b[39m'\u001b[39m, lang, config, nice, timeout]\n\u001b[0;32m    486\u001b[0m \u001b[39mreturn\u001b[39;00m {\n\u001b[0;32m    487\u001b[0m     Output\u001b[39m.\u001b[39mBYTES: \u001b[39mlambda\u001b[39;00m: run_and_get_output(\u001b[39m*\u001b[39m(args \u001b[39m+\u001b[39m [\u001b[39mTrue\u001b[39;00m])),\n\u001b[0;32m    488\u001b[0m     Output\u001b[39m.\u001b[39mDICT: \u001b[39mlambda\u001b[39;00m: {\u001b[39m'\u001b[39m\u001b[39mtext\u001b[39m\u001b[39m'\u001b[39m: run_and_get_output(\u001b[39m*\u001b[39margs)},\n\u001b[1;32m--> 489\u001b[0m     Output\u001b[39m.\u001b[39mSTRING: \u001b[39mlambda\u001b[39;00m: run_and_get_output(\u001b[39m*\u001b[39;49margs),\n\u001b[0;32m    490\u001b[0m }[output_type]()\n",
      "File \u001b[1;32mc:\\Users\\fhace\\miniforge-pypy3\\envs\\yolo\\lib\\site-packages\\pytesseract\\pytesseract.py:352\u001b[0m, in \u001b[0;36mrun_and_get_output\u001b[1;34m(image, extension, lang, config, nice, timeout, return_bytes)\u001b[0m\n\u001b[0;32m    341\u001b[0m \u001b[39mwith\u001b[39;00m save(image) \u001b[39mas\u001b[39;00m (temp_name, input_filename):\n\u001b[0;32m    342\u001b[0m     kwargs \u001b[39m=\u001b[39m {\n\u001b[0;32m    343\u001b[0m         \u001b[39m'\u001b[39m\u001b[39minput_filename\u001b[39m\u001b[39m'\u001b[39m: input_filename,\n\u001b[0;32m    344\u001b[0m         \u001b[39m'\u001b[39m\u001b[39moutput_filename_base\u001b[39m\u001b[39m'\u001b[39m: temp_name,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    349\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mtimeout\u001b[39m\u001b[39m'\u001b[39m: timeout,\n\u001b[0;32m    350\u001b[0m     }\n\u001b[1;32m--> 352\u001b[0m     run_tesseract(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    353\u001b[0m     \u001b[39mreturn\u001b[39;00m _read_output(\n\u001b[0;32m    354\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mkwargs[\u001b[39m'\u001b[39m\u001b[39moutput_filename_base\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m{\u001b[39;00mextsep\u001b[39m}\u001b[39;00m\u001b[39m{\u001b[39;00mextension\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    355\u001b[0m         return_bytes,\n\u001b[0;32m    356\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\fhace\\miniforge-pypy3\\envs\\yolo\\lib\\site-packages\\pytesseract\\pytesseract.py:282\u001b[0m, in \u001b[0;36mrun_tesseract\u001b[1;34m(input_filename, output_filename_base, extension, lang, config, nice, timeout)\u001b[0m\n\u001b[0;32m    279\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    280\u001b[0m         \u001b[39mraise\u001b[39;00m TesseractNotFoundError()\n\u001b[1;32m--> 282\u001b[0m \u001b[39mwith\u001b[39;00m timeout_manager(proc, timeout) \u001b[39mas\u001b[39;00m error_string:\n\u001b[0;32m    283\u001b[0m     \u001b[39mif\u001b[39;00m proc\u001b[39m.\u001b[39mreturncode:\n\u001b[0;32m    284\u001b[0m         \u001b[39mraise\u001b[39;00m TesseractError(proc\u001b[39m.\u001b[39mreturncode, get_errors(error_string))\n",
      "File \u001b[1;32mc:\\Users\\fhace\\miniforge-pypy3\\envs\\yolo\\lib\\contextlib.py:113\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__enter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[39mdel\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkwds, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunc\n\u001b[0;32m    112\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 113\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mnext\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgen)\n\u001b[0;32m    114\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m:\n\u001b[0;32m    115\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mgenerator didn\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt yield\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\fhace\\miniforge-pypy3\\envs\\yolo\\lib\\site-packages\\pytesseract\\pytesseract.py:144\u001b[0m, in \u001b[0;36mtimeout_manager\u001b[1;34m(proc, seconds)\u001b[0m\n\u001b[0;32m    142\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    143\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m seconds:\n\u001b[1;32m--> 144\u001b[0m         \u001b[39myield\u001b[39;00m proc\u001b[39m.\u001b[39;49mcommunicate()[\u001b[39m1\u001b[39m]\n\u001b[0;32m    145\u001b[0m         \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m    147\u001b[0m     \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\fhace\\miniforge-pypy3\\envs\\yolo\\lib\\subprocess.py:1028\u001b[0m, in \u001b[0;36mPopen.communicate\u001b[1;34m(self, input, timeout)\u001b[0m\n\u001b[0;32m   1025\u001b[0m     endtime \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   1027\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1028\u001b[0m     stdout, stderr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_communicate(\u001b[39minput\u001b[39;49m, endtime, timeout)\n\u001b[0;32m   1029\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyboardInterrupt\u001b[39;00m:\n\u001b[0;32m   1030\u001b[0m     \u001b[39m# https://bugs.python.org/issue25942\u001b[39;00m\n\u001b[0;32m   1031\u001b[0m     \u001b[39m# See the detailed comment in .wait().\u001b[39;00m\n\u001b[0;32m   1032\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\fhace\\miniforge-pypy3\\envs\\yolo\\lib\\subprocess.py:1415\u001b[0m, in \u001b[0;36mPopen._communicate\u001b[1;34m(self, input, endtime, orig_timeout)\u001b[0m\n\u001b[0;32m   1411\u001b[0m \u001b[39m# Wait for the reader threads, or time out.  If we time out, the\u001b[39;00m\n\u001b[0;32m   1412\u001b[0m \u001b[39m# threads remain reading and the fds left open in case the user\u001b[39;00m\n\u001b[0;32m   1413\u001b[0m \u001b[39m# calls communicate again.\u001b[39;00m\n\u001b[0;32m   1414\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstdout \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 1415\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstdout_thread\u001b[39m.\u001b[39;49mjoin(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_remaining_time(endtime))\n\u001b[0;32m   1416\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstdout_thread\u001b[39m.\u001b[39mis_alive():\n\u001b[0;32m   1417\u001b[0m         \u001b[39mraise\u001b[39;00m TimeoutExpired(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs, orig_timeout)\n",
      "File \u001b[1;32mc:\\Users\\fhace\\miniforge-pypy3\\envs\\yolo\\lib\\threading.py:1011\u001b[0m, in \u001b[0;36mThread.join\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m   1008\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mcannot join current thread\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   1010\u001b[0m \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 1011\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_wait_for_tstate_lock()\n\u001b[0;32m   1012\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1013\u001b[0m     \u001b[39m# the behavior of a negative timeout isn't documented, but\u001b[39;00m\n\u001b[0;32m   1014\u001b[0m     \u001b[39m# historically .join(timeout=x) for x<0 has acted as if timeout=0\u001b[39;00m\n\u001b[0;32m   1015\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_wait_for_tstate_lock(timeout\u001b[39m=\u001b[39m\u001b[39mmax\u001b[39m(timeout, \u001b[39m0\u001b[39m))\n",
      "File \u001b[1;32mc:\\Users\\fhace\\miniforge-pypy3\\envs\\yolo\\lib\\threading.py:1027\u001b[0m, in \u001b[0;36mThread._wait_for_tstate_lock\u001b[1;34m(self, block, timeout)\u001b[0m\n\u001b[0;32m   1025\u001b[0m \u001b[39mif\u001b[39;00m lock \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:  \u001b[39m# already determined that the C code is done\u001b[39;00m\n\u001b[0;32m   1026\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_is_stopped\n\u001b[1;32m-> 1027\u001b[0m \u001b[39melif\u001b[39;00m lock\u001b[39m.\u001b[39;49macquire(block, timeout):\n\u001b[0;32m   1028\u001b[0m     lock\u001b[39m.\u001b[39mrelease()\n\u001b[0;32m   1029\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stop()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def getBBOX_coords(tile_ds : rio.DatasetReader, bbox : list) -> list:\n",
    "    \"\"\"\n",
    "    Converts Bounding Box pixel coordinates into actual coordinates by using the input rasterio dataset\n",
    "\n",
    "    Parameters:\n",
    "        tile_ds (rasterio.Dataset): Post-ICP rasterio dataset saved with a world file.\n",
    "        bbox (iterable): Bounding box coordinates in format (x_min, y_min, x_max, y_max),\n",
    "                      normalized by the total image width and height.\n",
    "\n",
    "    Returns:\n",
    "        coords (list): list of raster coordinates in (x_min, y_min, x_max, y_max) format.\n",
    "    \"\"\"\n",
    "    # x1, y1 = rio.transform.xy(tile_ds.transform, bbox[0], bbox[1]) WRONG X, Y \n",
    "    # x2, y2 = rio.transform.xy(tile_ds.transform, bbox[2], bbox[3]) WRONG X, Y\n",
    "    x1, y1 = rio.transform.xy(tile_ds.transform, bbox[1], bbox[0]) \n",
    "    x2, y2 = rio.transform.xy(tile_ds.transform, bbox[3], bbox[2])\n",
    "    return [x1, y1, x2, y2]\n",
    "\n",
    "def bbox_to_coords(bbox):\n",
    "    '''\n",
    "    x1, y1, x2, y2 = bbox\n",
    "\n",
    "    x_min = np.min([x1, x2])    \n",
    "    x_max = np.max([x1, x2])    \n",
    "    y_min = np.min([y1, y2])    \n",
    "    y_max = np.max([y1, y2])    \n",
    "\n",
    "    \n",
    "    '''\n",
    "    x_min, y_min, x_max, y_max = bbox\n",
    "\n",
    "    xs = [x_min, x_max, x_min, x_max]\n",
    "    ys = [y_min, y_min, y_max, y_max]\n",
    "    return xs, ys# [(x_min, y_min), (x_max, y_min), (x_max, y_max), (x_min, y_max)]\n",
    "\n",
    "# def getTileTransform(tile):\n",
    "\n",
    "def getTileAffine(tile, baseaffine=None):\n",
    "\n",
    "    b = baseaffine\n",
    "\n",
    "    w, h = tile['data'].size\n",
    "\n",
    "    x_i = [0, w, 0, w]\n",
    "    y_i = [0, 0, h, h]\n",
    "    x_c, y_c = bbox_to_coords(tile['coords'])\n",
    "\n",
    "    test = pd.DataFrame()\n",
    "    test[\"x_i\"] = x_i\n",
    "    test[\"y_i\"] = y_i\n",
    "    test[\"x_c\"] = x_c\n",
    "    test[\"y_c\"] = y_c\n",
    "\n",
    "    a = affineTransformation(x_i, y_i, x_c, y_c)\n",
    "\n",
    "    matrix = None\n",
    "    if b is not None: \n",
    "        matrix = b.flatten()[:6]\n",
    "        matrix[2] = a.matrix.flatten()[2]\n",
    "        matrix[5] = a.matrix.flatten()[5]\n",
    "    else:\n",
    "        matrix = a.matrix.flatten()[:6]\n",
    "         \n",
    "\n",
    "    return rio.Affine(*matrix)\n",
    "\n",
    "def saveTile(fn, tile, baseaffine=None):\n",
    "    transform = tile['affine'] if 'affine' in tile else getTileAffine(tile, baseaffine=baseaffine)\n",
    "    image = np.asarray(tile['data'])\n",
    "    epsg_code = 3857\n",
    "    with rio.open(fn, 'w',\n",
    "        driver='GTiff',\n",
    "        height=image.shape[0],\n",
    "        width=image.shape[1],\n",
    "        count=1,\n",
    "        dtype=image.dtype,\n",
    "        crs=f'EPSG:{epsg_code}',\n",
    "        transform=transform) as dst:\n",
    "            dst.write(image, 1)    \n",
    "\n",
    "def ICPtoCRSTransform(image_arry, transform_dict):\n",
    "    # REVERSE Y AXIS\n",
    "    rev_y_axis = np.array([[1, 0, 0],\n",
    "                        [0,-1, 0],\n",
    "                        [0, 0, 1]])\n",
    "\n",
    "    # move = original_homography @ np.array([0, image_t.shape[0], 0])\n",
    "    translation = np.eye(3)\n",
    "    translation[1, 2] = image_arry.shape[0]\n",
    "\n",
    "    transform_dict['translation'] = translation\n",
    "    \n",
    "    # adjustment =  np.linalg.inv(transform_dict['best'].copy())\n",
    "    # rev_adj = adjustment.copy()\n",
    "    # rev_adj[1, 1] = rev_adj[1, 1] * -1\n",
    "    transform_dict['rev_adj'] = np.linalg.inv(transform_dict['best'].copy())\n",
    "\n",
    "    transform_dict['flip'] = np.array([\n",
    "    [1, 0, 0],\n",
    "    [0, -1, 0],\n",
    "    [0, 0, 1]\n",
    "    ])\n",
    "    \n",
    "    # output_transform = transform_dict['initial'] @ transform_dict['translation'] @ transform_dict['rev_adj']\n",
    "    output_transform = transform_dict['initial'] @ transform_dict['rev_adj'] @ transform_dict['translation']  @ transform_dict['flip']\n",
    "    offsets = output_transform @ np.array([[0, 0, 1], [image_arry.shape[0], 0, 1]]).T\n",
    "    offsets = offsets[:, 1] - offsets[:, 0]\n",
    "    transform_dict['offsets'] = offsets\n",
    "\n",
    "    return output_transform, transform_dict\n",
    "\n",
    "def findTiles(image_fn, model=None, \n",
    "        model_weights=f\"{data_dir}BBNN/weights042924.pt\",\n",
    "        creation_params=None,\n",
    "        save_dir=None,\n",
    "        device=\"cpu\",\n",
    "        verbose=True\n",
    "        ):\n",
    "        \n",
    "    input_folder = os.path.dirname(os.path.abspath(image_fn))\n",
    "\n",
    "    if creation_params is None:\n",
    "        target_size = 1920\n",
    "        original_shapes = []\n",
    "\n",
    "        # COCO DATASET PARAMS\n",
    "        category_labels = {\n",
    "            0 : \"Tile\",\n",
    "            1 : \"County\",\n",
    "            2 : \"Legend\",\n",
    "            3 : \"Box\"\n",
    "        }\n",
    "\n",
    "        categories=[0, 1]\n",
    "    \n",
    "    # Initialize model\n",
    "    if model is None:\n",
    "        model = ultralytics.YOLO(model_weights).to(\"cpu\")\n",
    "\n",
    "    model = model.to(device)\n",
    "    \n",
    "    results = model(image_fn, imgsz=target_size, verbose=verbose)\n",
    "\n",
    "    if device == \"cuda\":\n",
    "        results = results[0].cpu()\n",
    "        model   = model.to(\"cpu\")\n",
    "\n",
    "    # GET CLASSES AND CONFIDENCES OF EACH RESULT\n",
    "    classes = results[0].boxes.data.numpy()[:, -1]\n",
    "    conf    = results[0].boxes.data.numpy()[:, -2]\n",
    "\n",
    "    # GOTTA FIND CORRECT FILE BC RESIZED WERE SAVED WITH PNG EXTENSION\n",
    "    basen = os.path.basename(results[0].path)[:-4]\n",
    "    in_fn = glob.glob(os.path.join(input_folder,  basen + '*[!w]'))[0]\n",
    "    key = findKey(basen)\n",
    "\n",
    "    image = Image.open(in_fn)\n",
    "    width, height = image.size\n",
    "    im_size_arry  = np.array([width, height, width, height])\n",
    "\n",
    "    # OUTPUT STRUCTURE\n",
    "    outputs = {}\n",
    "\n",
    "    # FOR TILES\n",
    "    slice = np.logical_and(classes==1, conf > 0.92)\n",
    "    for i in np.where(slice)[0]: \n",
    "        \n",
    "        # GET TILE DATA\n",
    "        bbox = results[0].boxes.xyxyn.numpy()[i]\n",
    "        data = extract_bounded_area(image, bbox)\n",
    "\n",
    "        bbox = bbox * im_size_arry\n",
    "\n",
    "        # GET ID FROM TILE\n",
    "        text = pytesseract.image_to_string(data, config='--psm 12 --oem 3') # -c tessedit_char_whitelist=0123456789\n",
    "        word = find_word_with_key(text, key, threshold=80, verbose=False)\n",
    "\n",
    "        if isinstance(word, list):\n",
    "            word = \",\".join(word)\n",
    "\n",
    "        outputs[word] = {\"bbox\" : bbox, \"data\" : data, \"text\" : text} # (bbox, data)\n",
    "\n",
    "    # FOR COUNTY - GET MOST LIKELY BOX CLASSIFIED AS COUNTY\n",
    "    county_conf = conf.copy()\n",
    "    county_conf[classes != 2] = 0\n",
    "    slice = np.argmax(county_conf)\n",
    "\n",
    "    bbox = results[0].boxes.xyxyn.numpy()[slice]\n",
    "    outputs[\"county\"] = {\"bbox\" : bbox * im_size_arry, \"data\" : extract_bounded_area(image, bbox)}\n",
    "\n",
    "    if save_dir is not None:\n",
    "        results[0].save(save_dir)\n",
    "\n",
    "    return outputs, model\n",
    "\n",
    "\n",
    "verbose = True\n",
    "\n",
    "TPNN = None\n",
    "RLNN = None\n",
    "CLNN = None\n",
    "TLNN = None\n",
    "\n",
    "gen_dict = {}\n",
    "\n",
    "for i, row in tqdm(index_files.iterrows(), total=index_files.shape[0]):\n",
    "    \n",
    "    # try:\n",
    "\n",
    "        filename = os.path.basename(row[\"FilePath\"])\n",
    "        \n",
    "        # READ FILES AND CONVERT TO GRAYSCALE\n",
    "        image = cv2.imread(row[\"FilePath\"])\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        image_arry = np.asarray(image)\n",
    "        \n",
    "        # SAVE IMAGE TO OUTPUT DIRECTORY\n",
    "        output_image_fn = os.path.join(outputs_dir, filename.split(\".\")[0] + \".tif\")\n",
    "        copyfile(row[\"FilePath\"], output_image_fn)\n",
    "\n",
    "        # GET BOUNDARY POINTS FROM RESPECTIVE SHAPEFILE\n",
    "        output = getBoundaryPoints(row, distance=100)\n",
    "        if output is None:\n",
    "            print(f\"COULD NOT FIND SHAPEFILE FOR {filename}\")\n",
    "            continue\n",
    "        point_boundary_gdf, shp_bounds = output\n",
    "        \n",
    "        # RUN IMAGES THROUGH DNNs\n",
    "        classifications, TPNN  = findKeypoints(image, model=TPNN, **dnn_params['TPNN'])\n",
    "        effectiveArea, RLNN    = findSquares(image, model=RLNN, **dnn_params['RLNN'])\n",
    "        countyArea, CLNN       = findCounty(image, model=CLNN, **dnn_params['CLNN'])\n",
    "        tiles, TLNN            = findTiles(row[\"FilePath\"], model=TLNN, **dnn_params['TLNN'], verbose=False,\n",
    "                                           save_dir=os.path.join(outputs_dir, filename.split(\".\")[0] + \"_BBNN.tif\"))\n",
    "\n",
    "        dnn_outputs = {\n",
    "            \"classifications\"   : classifications,\n",
    "            \"effectiveArea\"     : effectiveArea,\n",
    "            \"countyArea\"    : countyArea,\n",
    "            \"tiles\"         : tiles\n",
    "        }\n",
    "        \n",
    "        # GET COUNTY BOUNDS IDENTIFIED IN INDEX BY TLNN\n",
    "        # bounds_panels = tiles[\"county\"][\"bbox\"]\n",
    "        bounds_panels = find_bbox(dnn_outputs['countyArea'][:, :, 1])\n",
    "\n",
    "        # SKIP IF WE CAN'T FIND BOUNDARY IN EXISTING DATABASES\n",
    "        if point_boundary_gdf is None:\n",
    "            continue\n",
    "\n",
    "        # DEFINE BOUNDARY STRUCTU\n",
    "        boundaries = {\n",
    "            \"point_boundary_gdf\"    : point_boundary_gdf,\n",
    "            \"shp_bounds\"            : shp_bounds,\n",
    "            \"bounds_panels\"         : bounds_panels,\n",
    "        }\n",
    "\n",
    "        # WHAT ARE WE LOOKING FOR IN EACH IDENTIFIED SQUARE?\n",
    "        key = findKey(row[\"Basename\"])    \n",
    "        if key is None:\n",
    "            print(f\"Could not find key in {filename}\")\n",
    "        \n",
    "        # DO ICP\n",
    "        transform_dict = performICPonIndex(boundaries, dnn_outputs, debug=False, plot=False, rotation=True, shear=False, perspective=False, icp_iterations=30)\n",
    "\n",
    "        # GET TRANSFORM FROM ICP TO CRS TRANSFORM\n",
    "        output_transform, transform_dict = ICPtoCRSTransform(image_arry, transform_dict)\n",
    "\n",
    "        # GET OUTPUT TRANSFORM INTO AFFINE AND WRITE\n",
    "        output_affine = Affine(*output_transform.flatten()[:6])\n",
    "        # write_world_file_from_affine(output_affine, get_world_file_path(output_image_fn))\n",
    "        with rio.open(output_image_fn, 'w',\n",
    "            driver='GTiff',\n",
    "            height=image.shape[0], width=image.shape[1],\n",
    "            count=1, dtype=image.dtype,\n",
    "            crs=f'EPSG:3857',\n",
    "            transform=rio.Affine(*output_transform.flatten()[:6])) as dst:\n",
    "                dst.write(image, 1)   \n",
    "\n",
    "        tiles['transform_info'] = transform_dict\n",
    "        tiles['output_transform'] = output_transform\n",
    "        gen_dict[filename] = tiles\n",
    "\n",
    "        \n",
    "        src = rio.open(output_image_fn)\n",
    "        for iii, (k, v) in enumerate(tiles.items()):\n",
    "            if k in ['transform_info', 'output_transform']:\n",
    "                continue\n",
    "            tiles[k]['coords'] = getBBOX_coords(src, tiles[k]['bbox'])\n",
    "            saveTile(os.path.join(outputs_dir, f\"{filename}_{k}.tif\"), v, baseaffine=output_transform)\n",
    "\n",
    "            '''\n",
    "            try:\n",
    "                if k in ['transform_info', 'output_transform']:\n",
    "                    continue\n",
    "                tiles[k]['coords'] = getBBOX_coords(src, tiles[k]['bbox'])\n",
    "                saveTile(os.path.join(outputs_dir, f\"{filename}_{k}.tif\"), v, baseaffine=output_transform)\n",
    "            except Exception as e:\n",
    "                print(\"ERROR : \"+str(e) + f\" {k}\")\n",
    "                continue\n",
    "            '''\n",
    "\n",
    "with open(os.path.join(outputs_dir, \"IndexCoords.pkl\"), 'wb') as handle:\n",
    "    pickle.dump(gen_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    " \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['48003503508', '4800350165B', None, '4800350475', '48003506258', '1480035', '4800350600', '4800350575B', '4800350295', '4800350075,48003500658', '4800350305', '4800350425B', '4800350315B', '4800350650', '4800350050', '4800350525', '4800350285', '4800350675B', '4800350310', '4800350025B', '4800350495B', '4800350320', '49003502250', '4800350275C', '4900350195', '4800350390B', '4800350150', '4800350125', '4800350375B', '4800350155B', '4800350485', '4800350100', '4800350380C', '48003501608', '4800350490B', '4800350395', '48003501908', 'county', 'transform_info', 'output_transform'])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tiles.keys()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
