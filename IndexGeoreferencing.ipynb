{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c7621809",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTEBOOK IMPORTS\n",
    "import os, glob, warnings, pickle\n",
    "import numpy as np\n",
    "from shutil import copyfile, rmtree\n",
    "from datetime import datetime\n",
    "\n",
    "# IMAGE IMPORTS\n",
    "from PIL import Image, TiffImagePlugin\n",
    "import cv2\n",
    "\n",
    "# GIS IMPORTS\n",
    "from affine import Affine\n",
    "import pandas as pd\n",
    "\n",
    "# PLOTTING IMPORTS\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# CUSTOM UTILITIES\n",
    "from IndexUtils import * \n",
    "\n",
    "Image.MAX_IMAGE_PIXELS = 933120000\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "initialize = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ed09b63",
   "metadata": {},
   "source": [
    "IO directories depending on which machine. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "34617015",
   "metadata": {},
   "outputs": [],
   "source": [
    "username = os.getlogin()\n",
    "\n",
    "dnn_params = {}\n",
    "dnn_params['CLNN'] = {}\n",
    "dnn_params['TPNN'] = {}\n",
    "dnn_params['RLNN'] = {}\n",
    "dnn_params['FLNN'] = {}\n",
    "dnn_params['TLNN'] = {}\n",
    "\n",
    "\n",
    "if username == 'fhacesga':\n",
    "    base_input_path   = r\"D:\\RECTDNN\\Uncompress\\\\\"\n",
    "    base_output_path  = r\"D:\\RECTDNN\\processing\\\\\"\n",
    "    ref_dir  = r\"C:\\Users\\fhacesga\\OneDrive - University Of Houston\\AAA_RECTDNN\\data\\AAA_ReferenceDatasets\\\\\"\n",
    "elif username == 'fhace':\n",
    "    ref_dir = r\"C:\\Users\\fhace\\Desktop\\FIRMs\\data\\AAA_ReferenceDatasets\\\\\"\n",
    "    base_output_path = r\"C:\\Users\\fhace\\Desktop\\FIRMs\\data\\Outputs\\\\\"\n",
    "    dnn_params['TLNN']['model_weights']    = r\"C:\\Users\\fhace\\Desktop\\FIRMs\\data\\BBNN\\curr_weights.pt\"\n",
    "    dnn_params['CLNN']['model_checkpoint'] = r\"C:\\Users\\fhace\\Desktop\\FIRMs\\data\\RLNN\\checkpoint_101423.pth\"\n",
    "    dnn_params['TPNN']['model_checkpoint'] = r\"C:\\Users\\fhace\\OneDrive - University Of Houston\\AAA_RECTDNN\\data\\TPNN\\checkpoint_091523_pyramids_2.pth\"\n",
    "    dnn_params['RLNN']['model_checkpoint'] = r\"C:\\Users\\fhace\\OneDrive - University Of Houston\\AAA_RECTDNN\\data\\RLNN\\checkpoint_091323.pth\"\n",
    "    \n",
    "else:\n",
    "    base_input_path   = r\"D:\\Desktop\\FIRMsDigitizing\\data\\HistoricalFIRMS\"\n",
    "    base_output_path  = r\"D:\\Desktop\\FIRMsDigitizing\\processing\"\n",
    "    ref_dir  = r\"C:\\Users\\franc\\OneDrive - University Of Houston\\AAA_RECTDNN\\data\\AAA_ReferenceDatasets\\\\\"\n",
    "\n",
    "if not initialize:\n",
    "    initialize = init_databases(ref_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5ca1967",
   "metadata": {},
   "source": [
    "Create working dir and unzip all files if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eca9abcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAKE PROCESSING DIRECTORY\n",
    "datetime_str = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "proc_dir     = os.path.join(base_output_path, datetime_str)\n",
    "\n",
    "# IF THERE ARE ANY ZIP FILES IN DIRECTORY, UNZIP THEM IN PLACE\n",
    "if len(glob.glob(base_input_path + \"*.zip*\")) != 0:\n",
    "    extractZipFiles(base_input_path, base_input_path)\n",
    "\n",
    "outputs_dir  = os.path.join(proc_dir, \"Outputs\")\n",
    "os.makedirs(outputs_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "469fbdb7",
   "metadata": {},
   "source": [
    "Read through all the images in the directory. Some images are saved as Multi-page TIFF files. These need to be exported into individual images. We'll do that first in-place at uncompressed directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea68a26c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18e30632d115466fa734fd85b55e0591",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1710 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error opening D:\\RECTDNN\\Uncompress\\485479B.tif\n",
      "cannot identify image file 'D:\\\\RECTDNN\\\\Uncompress\\\\485479B.tif'\n",
      "Error opening D:\\RECTDNN\\Uncompress\\485479C.tif\n",
      "cannot identify image file 'D:\\\\RECTDNN\\\\Uncompress\\\\485479C.tif'\n",
      "Error opening D:\\RECTDNN\\Uncompress\\485481A.tif\n",
      "cannot identify image file 'D:\\\\RECTDNN\\\\Uncompress\\\\485481A.tif'\n",
      "Error opening D:\\RECTDNN\\Uncompress\\485510.tif\n",
      "cannot identify image file 'D:\\\\RECTDNN\\\\Uncompress\\\\485510.tif'\n",
      "Error opening D:\\RECTDNN\\Uncompress\\485510B.tif\n",
      "cannot identify image file 'D:\\\\RECTDNN\\\\Uncompress\\\\485510B.tif'\n",
      "Error opening D:\\RECTDNN\\Uncompress\\485514B.tif\n",
      "cannot identify image file 'D:\\\\RECTDNN\\\\Uncompress\\\\485514B.tif'\n",
      "Error opening D:\\RECTDNN\\Uncompress\\485516A.tif\n",
      "cannot identify image file 'D:\\\\RECTDNN\\\\Uncompress\\\\485516A.tif'\n"
     ]
    }
   ],
   "source": [
    "remove_files = []\n",
    "\n",
    "for filename in tqdm(glob.glob(base_input_path + \"\\\\*.tif*\")):\n",
    "    tiff_file = os.path.join(base_input_path, filename)\n",
    "    try:\n",
    "    # Check if the file is a multi-page TIFF\n",
    "        with Image.open(tiff_file) as img:\n",
    "            if img.is_animated:    \n",
    "                print(f\"Expanding {os.path.basename(tiff_file)} into {img.n_frames}\")\n",
    "                for i in range(img.n_frames):\n",
    "                    try:\n",
    "                        img.seek(i)\n",
    "                        output_filename = f\"{os.path.splitext(tiff_file)[0]}_{i+1}{os.path.splitext(tiff_file)[1]}\"\n",
    "                        img.save(output_filename, format=img.format)\n",
    "                    except:\n",
    "                        print(f\"Error with {tiff_file} page {i}\")\n",
    "                        continue\n",
    "                remove_files.append(tiff_file)\n",
    "    except Exception as e:\n",
    "        print(f\"Error opening {tiff_file}\")\n",
    "        print(e)\n",
    "        continue\n",
    "\n",
    "for tiff_file in remove_files:\n",
    "    os.remove(tiff_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acac9f90",
   "metadata": {},
   "source": [
    "Here we're using heuristics to identify indices within all the image files. These include:\n",
    "- Files that are shorter than 12 characters\n",
    "- Files that have the ```IND``` marker\n",
    "\n",
    "We create a Pandas DataFrame with the files matching. We then add several fields as below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d5180ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LIST ALL IMAGES IN DIRECTORY\n",
    "image_files = glob.glob(f\"{base_input_path}/*\")\n",
    "\n",
    "# FILTER IMAGES USING HEURISTICS\n",
    "patterns = [\"IND\", \"_1.\"]\n",
    "index_files = [file for pattern in patterns for file in glob.glob(base_input_path + \"\\\\*\" + pattern + \"*\")]\n",
    "filtered_files = [file for file in image_files if len(os.path.basename(file)) < 12]\n",
    "index_files.extend(filtered_files)\n",
    "\n",
    "# CREATE DATAFRAME\n",
    "index_files = pd.DataFrame(index_files, columns=[\"FilePath\"])\n",
    "\n",
    "# INDEX ATTRIBUTES TO BE ADDED\n",
    "index_files[\"Basename\"] = [os.path.basename(file) for file in index_files[\"FilePath\"].to_list()]    # BASENAME\n",
    "index_files[\"Location\"] = index_files[\"Basename\"].apply(extract_numerical_chars).astype(np.int32)   # \n",
    "index_files[\"GEOID\"]    = index_files[\"Location\"].apply(getGEOID)       # GET GEOID FOR EACH INDEX\n",
    "index_files[\"geometry\"] = index_files[\"GEOID\"].apply(getGeometry)       # GET GEOMETRY FROM MATCHING GEOIDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "544b54fd",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "940509169f3f4f1e883825d3fe86a4a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/183 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COULD NOT FIND SHAPEFILE FOR 480243IND0_0583.jpg\n",
      "COULD NOT FIND SHAPEFILE FOR 480243IND0_1083.jpg\n",
      "ERROR : invalid dtype: dtype('bool') 4802660025\n",
      "ERROR : invalid dtype: dtype('bool') county\n",
      "ERROR : invalid dtype: dtype('bool') county\n",
      "ERROR : invalid dtype: dtype('bool') 4802690015\n",
      "ERROR : invalid dtype: dtype('bool') county\n",
      "ERROR : invalid dtype: dtype('bool') None\n",
      "ERROR : invalid dtype: dtype('bool') county\n",
      "ERROR : invalid dtype: dtype('bool') None\n",
      "ERROR : invalid dtype: dtype('bool') county\n",
      "ERROR : invalid dtype: dtype('bool') county\n",
      "ERROR : invalid dtype: dtype('bool') county\n",
      "ERROR : Source shape (1, 337, 294, 3) is inconsistent with given indexes 1 None\n",
      "ERROR : Source shape (1, 337, 294, 3) is inconsistent with given indexes 1 county\n",
      "ERROR : invalid dtype: dtype('bool') None\n",
      "ERROR : invalid dtype: dtype('bool') county\n",
      "ERROR : invalid dtype: dtype('bool') county\n",
      "ERROR : invalid dtype: dtype('bool') county\n",
      "ERROR : invalid dtype: dtype('bool') county\n",
      "ERROR : invalid dtype: dtype('bool') 48071C0500E\n",
      "ERROR : invalid dtype: dtype('bool') county\n",
      "ERROR : invalid dtype: dtype('bool') county\n",
      "ERROR : invalid dtype: dtype('bool') 4812710003\n",
      "ERROR : invalid dtype: dtype('bool') county\n",
      "ERROR : invalid dtype: dtype('bool') county\n",
      "ERROR : invalid dtype: dtype('bool') county\n",
      "ERROR : invalid dtype: dtype('bool') 4815700085,48157C0100\n",
      "ERROR : invalid dtype: dtype('bool') county\n",
      "ERROR : invalid dtype: dtype('bool') 48157C0375L\n",
      "ERROR : invalid dtype: dtype('bool') county\n",
      "ERROR : invalid dtype: dtype('bool') 48157C0350M\n",
      "ERROR : invalid dtype: dtype('bool') county\n",
      "ERROR : invalid dtype: dtype('bool') 48187C0335F\n",
      "ERROR : invalid dtype: dtype('bool') county\n",
      "ERROR : invalid dtype: dtype('bool') 48201C0360\n",
      "ERROR : invalid dtype: dtype('bool') county\n",
      "ERROR : invalid dtype: dtype('bool') county\n",
      "ERROR : invalid dtype: dtype('bool') county\n",
      "ERROR : invalid dtype: dtype('bool') county\n",
      "ERROR : invalid dtype: dtype('bool') county\n",
      "ERROR : invalid dtype: dtype('bool') county\n",
      "ERROR : invalid dtype: dtype('bool') county\n",
      "ERROR : invalid dtype: dtype('bool') county\n",
      "ERROR : invalid dtype: dtype('bool') county\n",
      "ERROR : invalid dtype: dtype('bool') 48259C0225F\n",
      "ERROR : invalid dtype: dtype('bool') county\n",
      "ERROR : invalid dtype: dtype('bool') 48325C0025C\n",
      "ERROR : invalid dtype: dtype('bool') county\n",
      "ERROR : invalid dtype: dtype('bool') None\n",
      "ERROR : invalid dtype: dtype('bool') county\n",
      "ERROR : invalid dtype: dtype('bool') 48473C0225E\n",
      "ERROR : invalid dtype: dtype('bool') county\n",
      "ERROR : invalid dtype: dtype('bool') county\n",
      "ERROR : invalid dtype: dtype('bool') None\n",
      "ERROR : invalid dtype: dtype('bool') county\n",
      "ERROR : invalid dtype: dtype('bool') 485470G21\n",
      "ERROR : invalid dtype: dtype('bool') county\n",
      "ERROR : invalid dtype: dtype('bool') None\n",
      "ERROR : invalid dtype: dtype('bool') county\n",
      "ERROR : invalid dtype: dtype('bool') 4854790015D\n",
      "ERROR : invalid dtype: dtype('bool') county\n",
      "ERROR : invalid dtype: dtype('bool') county\n",
      "ERROR : invalid dtype: dtype('bool') 4854860025D\n",
      "ERROR : invalid dtype: dtype('bool') county\n",
      "ERROR : index 0 is out of bounds for dimension 0 with size 0\n",
      "ERROR : invalid dtype: dtype('bool') 485488005D\n",
      "ERROR : invalid dtype: dtype('bool') county\n",
      "ERROR : invalid dtype: dtype('bool') 4854880020\n",
      "ERROR : invalid dtype: dtype('bool') county\n",
      "ERROR : invalid dtype: dtype('bool') county\n",
      "ERROR : invalid dtype: dtype('bool') county\n",
      "ERROR : invalid dtype: dtype('bool') county\n",
      "ERROR : invalid dtype: dtype('bool') county\n",
      "ERROR : invalid dtype: dtype('bool') county\n",
      "ERROR : invalid dtype: dtype('bool') county\n",
      "ERROR : invalid dtype: dtype('bool') county\n",
      "ERROR : invalid dtype: dtype('bool') county\n",
      "ERROR : invalid dtype: dtype('bool') county\n",
      "ERROR : invalid dtype: dtype('bool') county\n",
      "ERROR : invalid dtype: dtype('bool') county\n",
      "ERROR : invalid dtype: dtype('bool') county\n",
      "ERROR : invalid dtype: dtype('bool') county\n",
      "ERROR : invalid dtype: dtype('bool') county\n",
      "ERROR : invalid dtype: dtype('bool') county\n",
      "ERROR : invalid dtype: dtype('bool') None\n",
      "ERROR : invalid dtype: dtype('bool') county\n",
      "ERROR : invalid dtype: dtype('bool') county\n",
      "ERROR : invalid dtype: dtype('bool') None\n",
      "ERROR : invalid dtype: dtype('bool') county\n",
      "COULD NOT FIND SHAPEFILE FOR 480243_1.tif\n",
      "ERROR : invalid dtype: dtype('bool') county\n",
      "ERROR : invalid dtype: dtype('bool') None\n",
      "ERROR : invalid dtype: dtype('bool') county\n",
      "ERROR : invalid dtype: dtype('bool') county\n",
      "ERROR : invalid dtype: dtype('bool') county\n",
      "ERROR : invalid dtype: dtype('bool') county\n",
      "ERROR : invalid dtype: dtype('bool') county\n",
      "ERROR : invalid dtype: dtype('bool') county\n",
      "ERROR : invalid dtype: dtype('bool') county\n",
      "ERROR : invalid dtype: dtype('bool') county\n",
      "ERROR : invalid dtype: dtype('bool') county\n",
      "ERROR : invalid dtype: dtype('bool') county\n",
      "ERROR : invalid dtype: dtype('bool') county\n",
      "ERROR : invalid dtype: dtype('bool') county\n",
      "ERROR : invalid dtype: dtype('bool') county\n",
      "ERROR : invalid dtype: dtype('bool') county\n",
      "ERROR : invalid dtype: dtype('bool') county\n",
      "ERROR : invalid dtype: dtype('bool') None\n",
      "ERROR : invalid dtype: dtype('bool') county\n",
      "COULD NOT FIND SHAPEFILE FOR 480303A_1.tif\n",
      "COULD NOT FIND SHAPEFILE FOR 480303_1.tif\n",
      "ERROR : invalid dtype: dtype('bool') county\n",
      "ERROR : invalid dtype: dtype('bool') county\n",
      "ERROR : invalid dtype: dtype('bool') county\n",
      "ERROR : invalid dtype: dtype('bool') county\n",
      "ERROR : invalid dtype: dtype('bool') county\n",
      "ERROR : invalid dtype: dtype('bool') county\n",
      "ERROR : invalid dtype: dtype('bool') county\n",
      "ERROR : invalid dtype: dtype('bool') None\n",
      "ERROR : invalid dtype: dtype('bool') county\n",
      "ERROR : invalid dtype: dtype('bool') None\n",
      "ERROR : invalid dtype: dtype('bool') county\n",
      "ERROR : invalid dtype: dtype('bool') None\n",
      "ERROR : invalid dtype: dtype('bool') county\n",
      "ERROR : invalid dtype: dtype('bool') county\n",
      "ERROR : invalid dtype: dtype('bool') county\n",
      "ERROR : invalid dtype: dtype('bool') county\n",
      "ERROR : invalid dtype: dtype('bool') county\n",
      "ERROR : invalid dtype: dtype('bool') county\n",
      "ERROR : invalid dtype: dtype('bool') county\n",
      "ERROR : invalid dtype: dtype('bool') county\n",
      "ERROR : invalid dtype: dtype('bool') county\n",
      "ERROR : invalid dtype: dtype('bool') county\n",
      "ERROR : invalid dtype: dtype('bool') county\n",
      "ERROR : invalid dtype: dtype('bool') county\n",
      "ERROR : invalid dtype: dtype('bool') None\n",
      "ERROR : invalid dtype: dtype('bool') county\n",
      "ERROR : invalid dtype: dtype('bool') county\n",
      "ERROR : invalid dtype: dtype('bool') county\n",
      "ERROR : invalid dtype: dtype('bool') county\n",
      "ERROR : invalid dtype: dtype('bool') county\n",
      "ERROR : invalid dtype: dtype('bool') None\n",
      "ERROR : invalid dtype: dtype('bool') county\n",
      "ERROR : invalid dtype: dtype('bool') county\n",
      "ERROR : invalid dtype: dtype('bool') None\n",
      "ERROR : invalid dtype: dtype('bool') county\n",
      "ERROR : invalid dtype: dtype('bool') county\n",
      "ERROR : invalid dtype: dtype('bool') county\n",
      "ERROR : invalid dtype: dtype('bool') county\n",
      "ERROR : invalid dtype: dtype('bool') county\n",
      "ERROR : invalid dtype: dtype('bool') county\n",
      "ERROR : invalid dtype: dtype('bool') county\n",
      "ERROR : invalid dtype: dtype('bool') county\n",
      "ERROR : invalid dtype: dtype('bool') county\n",
      "ERROR : invalid dtype: dtype('bool') county\n",
      "ERROR : index 0 is out of bounds for dimension 0 with size 0\n",
      "ERROR : cannot identify image file 'D:\\\\RECTDNN\\\\Uncompress\\\\485479B.tif'\n",
      "ERROR : cannot identify image file 'D:\\\\RECTDNN\\\\Uncompress\\\\485479C.tif'\n",
      "ERROR : cannot identify image file 'D:\\\\RECTDNN\\\\Uncompress\\\\485481A.tif'\n",
      "ERROR : Source shape (1, 3392, 3392, 3) is inconsistent with given indexes 1 county\n",
      "ERROR : cannot identify image file 'D:\\\\RECTDNN\\\\Uncompress\\\\485510.tif'\n",
      "ERROR : cannot identify image file 'D:\\\\RECTDNN\\\\Uncompress\\\\485510B.tif'\n",
      "ERROR : invalid dtype: dtype('bool') county\n",
      "ERROR : cannot identify image file 'D:\\\\RECTDNN\\\\Uncompress\\\\485514B.tif'\n",
      "ERROR : cannot identify image file 'D:\\\\RECTDNN\\\\Uncompress\\\\485516A.tif'\n"
     ]
    }
   ],
   "source": [
    "def getBBOX_coords(tile_ds : rio.DatasetReader, bbox : list) -> list:\n",
    "    \"\"\"\n",
    "    Converts Bounding Box pixel coordinates into actual coordinates by using the input rasterio dataset\n",
    "\n",
    "    Parameters:\n",
    "        tile_ds (rasterio.Dataset): Post-ICP rasterio dataset saved with a world file.\n",
    "        bbox (iterable): Bounding box coordinates in format (x_min, y_min, x_max, y_max),\n",
    "                      normalized by the total image width and height.\n",
    "\n",
    "    Returns:\n",
    "        coords (list): list of raster coordinates in (x_min, y_min, x_max, y_max) format.\n",
    "    \"\"\"\n",
    "    # x1, y1 = rio.transform.xy(tile_ds.transform, bbox[0], bbox[1]) WRONG X, Y \n",
    "    # x2, y2 = rio.transform.xy(tile_ds.transform, bbox[2], bbox[3]) WRONG X, Y\n",
    "    x1, y1 = rio.transform.xy(tile_ds.transform, bbox[1], bbox[0]) \n",
    "    x2, y2 = rio.transform.xy(tile_ds.transform, bbox[3], bbox[2])\n",
    "    return [x1, y1, x2, y2]\n",
    "\n",
    "def bbox_to_coords(bbox):\n",
    "    '''\n",
    "    x1, y1, x2, y2 = bbox\n",
    "\n",
    "    x_min = np.min([x1, x2])    \n",
    "    x_max = np.max([x1, x2])    \n",
    "    y_min = np.min([y1, y2])    \n",
    "    y_max = np.max([y1, y2])    \n",
    "\n",
    "    \n",
    "    '''\n",
    "    x_min, y_min, x_max, y_max = bbox\n",
    "\n",
    "    xs = [x_min, x_max, x_min, x_max]\n",
    "    ys = [y_min, y_min, y_max, y_max]\n",
    "    return xs, ys# [(x_min, y_min), (x_max, y_min), (x_max, y_max), (x_min, y_max)]\n",
    "\n",
    "# def getTileTransform(tile):\n",
    "\n",
    "def getTileAffine(tile, baseaffine=None):\n",
    "\n",
    "    b = baseaffine\n",
    "\n",
    "    w, h = tile['data'].size\n",
    "\n",
    "    x_i = [0, w, 0, w]\n",
    "    y_i = [0, 0, h, h]\n",
    "    x_c, y_c = bbox_to_coords(tile['coords'])\n",
    "\n",
    "    test = pd.DataFrame()\n",
    "    test[\"x_i\"] = x_i\n",
    "    test[\"y_i\"] = y_i\n",
    "    test[\"x_c\"] = x_c\n",
    "    test[\"y_c\"] = y_c\n",
    "\n",
    "    a = affineTransformation(x_i, y_i, x_c, y_c)\n",
    "\n",
    "    matrix = None\n",
    "    if b is not None: \n",
    "        matrix = b.flatten()[:6]\n",
    "        matrix[2] = a.matrix.flatten()[2]\n",
    "        matrix[5] = a.matrix.flatten()[5]\n",
    "    else:\n",
    "        matrix = a.matrix.flatten()[:6]\n",
    "         \n",
    "\n",
    "    return rio.Affine(*matrix)\n",
    "\n",
    "def saveTile(fn, tile, baseaffine=None):\n",
    "    transform = tile['affine'] if 'affine' in tile else getTileAffine(tile, baseaffine=baseaffine)\n",
    "    image = np.asarray(tile['data'])\n",
    "    epsg_code = 3857\n",
    "    with rio.open(fn, 'w',\n",
    "        driver='GTiff',\n",
    "        height=image.shape[0],\n",
    "        width=image.shape[1],\n",
    "        count=1,\n",
    "        dtype=image.dtype,\n",
    "        crs=f'EPSG:{epsg_code}',\n",
    "        transform=transform) as dst:\n",
    "            dst.write(image, 1)    \n",
    "\n",
    "def ICPtoCRSTransform(image_arry, transform_dict):\n",
    "    # REVERSE Y AXIS\n",
    "    rev_y_axis = np.array([[1, 0, 0],\n",
    "                        [0,-1, 0],\n",
    "                        [0, 0, 1]])\n",
    "\n",
    "    # move = original_homography @ np.array([0, image_t.shape[0], 0])\n",
    "    translation = np.eye(3)\n",
    "    translation[1, 2] = image_arry.shape[0]\n",
    "\n",
    "    transform_dict['translation'] = translation\n",
    "    \n",
    "    # adjustment =  np.linalg.inv(transform_dict['best'].copy())\n",
    "    # rev_adj = adjustment.copy()\n",
    "    # rev_adj[1, 1] = rev_adj[1, 1] * -1\n",
    "    transform_dict['rev_adj'] = np.linalg.inv(transform_dict['best'].copy())\n",
    "\n",
    "    transform_dict['flip'] = np.array([\n",
    "    [1, 0, 0],\n",
    "    [0, -1, 0],\n",
    "    [0, 0, 1]\n",
    "    ])\n",
    "    \n",
    "    # output_transform = transform_dict['initial'] @ transform_dict['translation'] @ transform_dict['rev_adj']\n",
    "    output_transform = transform_dict['initial'] @ transform_dict['rev_adj'] @ transform_dict['translation']  @ transform_dict['flip']\n",
    "    offsets = output_transform @ np.array([[0, 0, 1], [image_arry.shape[0], 0, 1]]).T\n",
    "    offsets = offsets[:, 1] - offsets[:, 0]\n",
    "    transform_dict['offsets'] = offsets\n",
    "\n",
    "    return output_transform, transform_dict\n",
    "\n",
    "def findTiles(image_fn, model=None, \n",
    "        model_weights=f\"{data_dir}BBNN/weights042924.pt\",\n",
    "        creation_params=None,\n",
    "        save_dir=None,\n",
    "        device=\"cpu\",\n",
    "        verbose=True\n",
    "        ):\n",
    "        \n",
    "    input_folder = os.path.dirname(os.path.abspath(image_fn))\n",
    "\n",
    "    if creation_params is None:\n",
    "        target_size = 1920\n",
    "        original_shapes = []\n",
    "\n",
    "        # COCO DATASET PARAMS\n",
    "        category_labels = {\n",
    "            0 : \"Tile\",\n",
    "            1 : \"County\",\n",
    "            2 : \"Legend\",\n",
    "            3 : \"Box\"\n",
    "        }\n",
    "\n",
    "        categories=[0, 1]\n",
    "    \n",
    "    # Initialize model\n",
    "    if model is None:\n",
    "        model = ultralytics.YOLO(model_weights).to(\"cpu\")\n",
    "\n",
    "    model = model.to(device)\n",
    "    \n",
    "    results = model(image_fn, imgsz=target_size, verbose=verbose)\n",
    "\n",
    "    if device == \"cuda\":\n",
    "        results = results[0].cpu()\n",
    "        model   = model.to(\"cpu\")\n",
    "\n",
    "    # GET CLASSES AND CONFIDENCES OF EACH RESULT\n",
    "    classes = results[0].boxes.data.numpy()[:, -1]\n",
    "    conf    = results[0].boxes.data.numpy()[:, -2]\n",
    "\n",
    "    # GOTTA FIND CORRECT FILE BC RESIZED WERE SAVED WITH PNG EXTENSION\n",
    "    basen = os.path.basename(results[0].path)[:-4]\n",
    "    in_fn = glob.glob(os.path.join(input_folder,  basen + '*[!w]'))[0]\n",
    "    key = findKey(basen)\n",
    "\n",
    "    image = Image.open(in_fn)\n",
    "    width, height = image.size\n",
    "    im_size_arry  = np.array([width, height, width, height])\n",
    "\n",
    "    # OUTPUT STRUCTURE\n",
    "    outputs = {}\n",
    "\n",
    "    # FOR TILES\n",
    "    slice = np.logical_and(classes==1, conf > 0.92)\n",
    "    for i in np.where(slice)[0]: \n",
    "        \n",
    "        # GET TILE DATA\n",
    "        bbox = results[0].boxes.xyxyn.numpy()[i]\n",
    "        data = extract_bounded_area(image, bbox)\n",
    "\n",
    "        bbox = bbox * im_size_arry\n",
    "\n",
    "        # GET ID FROM TILE\n",
    "        text = pytesseract.image_to_string(data, config='--psm 12 --oem 3') # -c tessedit_char_whitelist=0123456789\n",
    "        word = find_word_with_key(text, key, threshold=80, verbose=False)\n",
    "\n",
    "        if isinstance(word, list):\n",
    "            word = \",\".join(word)\n",
    "\n",
    "        outputs[word] = {\"bbox\" : bbox, \"data\" : data, \"text\" : text} # (bbox, data)\n",
    "\n",
    "    # FOR COUNTY - GET MOST LIKELY BOX CLASSIFIED AS COUNTY\n",
    "    county_conf = conf.copy()\n",
    "    county_conf[classes != 2] = 0\n",
    "    slice = np.argmax(county_conf)\n",
    "\n",
    "    bbox = results[0].boxes.xyxyn.numpy()[slice]\n",
    "    outputs[\"county\"] = {\"bbox\" : bbox * im_size_arry, \"data\" : extract_bounded_area(image, bbox)}\n",
    "\n",
    "    if save_dir is not None:\n",
    "        results[0].save(save_dir)\n",
    "\n",
    "    return outputs, model\n",
    "\n",
    "\n",
    "verbose = True\n",
    "\n",
    "TPNN = None\n",
    "RLNN = None\n",
    "CLNN = None\n",
    "TLNN = None\n",
    "\n",
    "gen_dict = {}\n",
    "\n",
    "for i, row in tqdm(index_files.iterrows(), total=index_files.shape[0]):\n",
    "    \n",
    "    try:\n",
    "\n",
    "        filename = os.path.basename(row[\"FilePath\"])\n",
    "        \n",
    "        # READ FILES AND CONVERT TO GRAYSCALE\n",
    "        image = cv2.imread(row[\"FilePath\"])\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        image_arry = np.asarray(image)\n",
    "        \n",
    "        # SAVE IMAGE TO OUTPUT DIRECTORY\n",
    "        output_image_fn = os.path.join(outputs_dir, filename.split(\".\")[0] + \".tif\")\n",
    "        copyfile(row[\"FilePath\"], output_image_fn)\n",
    "\n",
    "        # GET BOUNDARY POINTS FROM RESPECTIVE SHAPEFILE\n",
    "        output = getBoundaryPoints(row, distance=100)\n",
    "        if output is None:\n",
    "            print(f\"COULD NOT FIND SHAPEFILE FOR {filename}\")\n",
    "            continue\n",
    "        point_boundary_gdf, shp_bounds = output\n",
    "        \n",
    "        # RUN IMAGES THROUGH DNNs\n",
    "        classifications, TPNN  = findKeypoints(image, model=TPNN, **dnn_params['TPNN'])\n",
    "        effectiveArea, RLNN    = findSquares(image, model=RLNN, **dnn_params['RLNN'])\n",
    "        countyArea, CLNN       = findCounty(image, model=CLNN, **dnn_params['CLNN'])\n",
    "        tiles, TLNN            = findTiles(row[\"FilePath\"], model=TLNN, **dnn_params['TLNN'], device=\"cuda\", verbose=False,\n",
    "                                           save_dir=os.path.join(outputs_dir, filename.split(\".\")[0] + \"_BBNN.tif\"))\n",
    "\n",
    "        dnn_outputs = {\n",
    "            \"classifications\"   : classifications,\n",
    "            \"effectiveArea\"     : effectiveArea,\n",
    "            \"countyArea\"    : countyArea,\n",
    "            \"tiles\"         : tiles\n",
    "        }\n",
    "        \n",
    "        # GET COUNTY BOUNDS IDENTIFIED IN INDEX BY TLNN\n",
    "        # bounds_panels = tiles[\"county\"][\"bbox\"]\n",
    "        bounds_panels = find_bbox(dnn_outputs['countyArea'][:, :, 1])\n",
    "\n",
    "        # SKIP IF WE CAN'T FIND BOUNDARY IN EXISTING DATABASES\n",
    "        if point_boundary_gdf is None:\n",
    "            continue\n",
    "\n",
    "        # DEFINE BOUNDARY STRUCTU\n",
    "        boundaries = {\n",
    "            \"point_boundary_gdf\"    : point_boundary_gdf,\n",
    "            \"shp_bounds\"            : shp_bounds,\n",
    "            \"bounds_panels\"         : bounds_panels,\n",
    "        }\n",
    "\n",
    "        # WHAT ARE WE LOOKING FOR IN EACH IDENTIFIED SQUARE?\n",
    "        key = findKey(row[\"Basename\"])    \n",
    "        if key is None:\n",
    "            print(f\"Could not find key in {filename}\")\n",
    "        \n",
    "        # DO ICP\n",
    "        transform_dict = performICPonIndex(boundaries, dnn_outputs, debug=False, plot=False, rotation=True, shear=False, perspective=False, icp_iterations=30)\n",
    "\n",
    "        # GET TRANSFORM FROM ICP TO CRS TRANSFORM\n",
    "        output_transform, transform_dict = ICPtoCRSTransform(image_arry, transform_dict)\n",
    "\n",
    "        # GET OUTPUT TRANSFORM INTO AFFINE AND WRITE\n",
    "        output_affine = Affine(*output_transform.flatten()[:6])\n",
    "        # write_world_file_from_affine(output_affine, get_world_file_path(output_image_fn))\n",
    "        with rio.open(output_image_fn, 'w',\n",
    "            driver='GTiff',\n",
    "            height=image.shape[0], width=image.shape[1],\n",
    "            count=1, dtype=image.dtype,\n",
    "            crs=f'EPSG:3857',\n",
    "            transform=rio.Affine(*output_transform.flatten()[:6])) as dst:\n",
    "                dst.write(image, 1)   \n",
    "\n",
    "        tiles['transform_info'] = transform_dict\n",
    "        tiles['output_transform'] = output_transform\n",
    "        gen_dict[filename] = tiles\n",
    "\n",
    "        \n",
    "        src = rio.open(output_image_fn)\n",
    "        for iii, (k, v) in enumerate(tiles.items()):\n",
    "            try:\n",
    "                if k in ['transform_info', 'output_transform']:\n",
    "                    continue\n",
    "                tiles[k]['coords'] = getBBOX_coords(src, tiles[k]['bbox'])\n",
    "                saveTile(os.path.join(outputs_dir, f\"{filename}_{k}.tif\"), v, baseaffine=output_transform)\n",
    "            except Exception as e:\n",
    "                print(\"ERROR : \"+str(e) + f\" {k}\")\n",
    "                continue\n",
    "    except Exception as e:\n",
    "        print(\"ERROR : \"+str(e))\n",
    "        continue\n",
    "\n",
    "with open(os.path.join(outputs_dir, \"IndexCoords.pkl\"), 'wb') as handle:\n",
    "    pickle.dump(gen_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    " \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
