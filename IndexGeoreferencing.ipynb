{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c7621809",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTEBOOK IMPORTS\n",
    "import os, glob, warnings, pickle\n",
    "import numpy as np\n",
    "from shutil import copyfile, rmtree\n",
    "from datetime import datetime\n",
    "\n",
    "# IMAGE IMPORTS\n",
    "from PIL import Image, TiffImagePlugin\n",
    "import cv2\n",
    "\n",
    "# GIS IMPORTS\n",
    "from affine import Affine\n",
    "import pandas as pd\n",
    "\n",
    "# PLOTTING IMPORTS\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# CUSTOM UTILITIES\n",
    "from IndexUtils import * \n",
    "\n",
    "Image.MAX_IMAGE_PIXELS = 933120000\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "initialize = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ed09b63",
   "metadata": {},
   "source": [
    "IO directories depending on which machine. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "34617015",
   "metadata": {},
   "outputs": [],
   "source": [
    "username = os.getlogin()\n",
    "\n",
    "dnn_params = {}\n",
    "dnn_params['CLNN'] = {}\n",
    "dnn_params['TPNN'] = {}\n",
    "dnn_params['RLNN'] = {}\n",
    "dnn_params['FLNN'] = {}\n",
    "dnn_params['TLNN'] = {}\n",
    "\n",
    "\n",
    "if username == 'fhacesga':\n",
    "    base_input_path   = r\"D:\\RECTDNN\\Uncompress\\\\\"\n",
    "    base_output_path  = r\"D:\\RECTDNN\\processing\\\\\"\n",
    "    ref_dir  = r\"C:\\Users\\fhacesga\\OneDrive - University Of Houston\\AAA_RECTDNN\\data\\AAA_ReferenceDatasets\\\\\"\n",
    "elif username == 'fhace':\n",
    "    base_input_path   = r\"C:\\Users\\fhace\\Desktop\\FIRMs\\data\\Uncompress\\\\\"\n",
    "    ref_dir = r\"C:\\Users\\fhace\\Desktop\\FIRMs\\data\\AAA_ReferenceDatasets\\\\\"\n",
    "    base_output_path = r\"C:\\Users\\fhace\\Desktop\\FIRMs\\data\\Outputs\\\\\"\n",
    "    # dnn_params['TLNN']['model_weights']    = r\"C:\\Users\\fhace\\Desktop\\FIRMs\\data\\BBNN\\curr_weights.pt\"\n",
    "    dnn_params['CLNN']['model_checkpoint'] = r\"C:\\Users\\fhace\\Desktop\\FIRMs\\data\\RLNN\\checkpoint_101423.pth\"\n",
    "    dnn_params['TPNN']['model_checkpoint'] = r\"C:\\Users\\fhace\\OneDrive - University Of Houston\\AAA_RECTDNN\\data\\TPNN\\checkpoint_091523_pyramids_2.pth\"\n",
    "    dnn_params['RLNN']['model_checkpoint'] = r\"C:\\Users\\fhace\\OneDrive - University Of Houston\\AAA_RECTDNN\\data\\RLNN\\checkpoint_091323.pth\"\n",
    "    \n",
    "else:\n",
    "    base_input_path   = r\"D:\\Desktop\\FIRMsDigitizing\\data\\HistoricalFIRMS\"\n",
    "    base_output_path  = r\"D:\\Desktop\\FIRMsDigitizing\\processing\"\n",
    "    ref_dir  = r\"C:\\Users\\franc\\OneDrive - University Of Houston\\AAA_RECTDNN\\data\\AAA_ReferenceDatasets\\\\\"\n",
    "\n",
    "if not initialize:\n",
    "    initialize = init_databases(ref_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5ca1967",
   "metadata": {},
   "source": [
    "Create working dir and unzip all files if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eca9abcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAKE PROCESSING DIRECTORY\n",
    "datetime_str = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "proc_dir     = os.path.join(base_output_path, datetime_str)\n",
    "\n",
    "# IF THERE ARE ANY ZIP FILES IN DIRECTORY, UNZIP THEM IN PLACE\n",
    "if len(glob.glob(base_input_path + \"*.zip*\")) != 0:\n",
    "    extractZipFiles(base_input_path, base_input_path)\n",
    "\n",
    "outputs_dir  = os.path.join(proc_dir, \"Outputs\")\n",
    "os.makedirs(outputs_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "469fbdb7",
   "metadata": {},
   "source": [
    "Read through all the images in the directory. Some images are saved as Multi-page TIFF files. These need to be exported into individual images. We'll do that first in-place at uncompressed directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea68a26c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2083f95949274765883289e9d8036e53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1710 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error opening D:\\RECTDNN\\Uncompress\\485479B.tif\n",
      "cannot identify image file 'D:\\\\RECTDNN\\\\Uncompress\\\\485479B.tif'\n",
      "Error opening D:\\RECTDNN\\Uncompress\\485479C.tif\n",
      "cannot identify image file 'D:\\\\RECTDNN\\\\Uncompress\\\\485479C.tif'\n",
      "Error opening D:\\RECTDNN\\Uncompress\\485481A.tif\n",
      "cannot identify image file 'D:\\\\RECTDNN\\\\Uncompress\\\\485481A.tif'\n",
      "Error opening D:\\RECTDNN\\Uncompress\\485510.tif\n",
      "cannot identify image file 'D:\\\\RECTDNN\\\\Uncompress\\\\485510.tif'\n",
      "Error opening D:\\RECTDNN\\Uncompress\\485510B.tif\n",
      "cannot identify image file 'D:\\\\RECTDNN\\\\Uncompress\\\\485510B.tif'\n",
      "Error opening D:\\RECTDNN\\Uncompress\\485514B.tif\n",
      "cannot identify image file 'D:\\\\RECTDNN\\\\Uncompress\\\\485514B.tif'\n",
      "Error opening D:\\RECTDNN\\Uncompress\\485516A.tif\n",
      "cannot identify image file 'D:\\\\RECTDNN\\\\Uncompress\\\\485516A.tif'\n"
     ]
    }
   ],
   "source": [
    "remove_files = []\n",
    "\n",
    "for filename in tqdm(glob.glob(base_input_path + \"\\\\*.tif*\")):\n",
    "    tiff_file = os.path.join(base_input_path, filename)\n",
    "    try:\n",
    "    # Check if the file is a multi-page TIFF\n",
    "        with Image.open(tiff_file) as img:\n",
    "            if img.is_animated:    \n",
    "                print(f\"Expanding {os.path.basename(tiff_file)} into {img.n_frames}\")\n",
    "                for i in range(img.n_frames):\n",
    "                    try:\n",
    "                        img.seek(i)\n",
    "                        output_filename = f\"{os.path.splitext(tiff_file)[0]}_{i+1}{os.path.splitext(tiff_file)[1]}\"\n",
    "                        img.save(output_filename, format=img.format)\n",
    "                    except:\n",
    "                        print(f\"Error with {tiff_file} page {i}\")\n",
    "                        continue\n",
    "                remove_files.append(tiff_file)\n",
    "    except Exception as e:\n",
    "        print(f\"Error opening {tiff_file}\")\n",
    "        print(e)\n",
    "        continue\n",
    "\n",
    "for tiff_file in remove_files:\n",
    "    os.remove(tiff_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acac9f90",
   "metadata": {},
   "source": [
    "Here we're using heuristics to identify indices within all the image files. These include:\n",
    "- Files that are shorter than 12 characters\n",
    "- Files that have the ```IND``` marker\n",
    "\n",
    "We create a Pandas DataFrame with the files matching. We then add several fields as below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d5180ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LIST ALL IMAGES IN DIRECTORY\n",
    "image_files = glob.glob(f\"{base_input_path}/*\")\n",
    "\n",
    "# FILTER IMAGES USING HEURISTICS\n",
    "patterns = [\"IND\", \"_1.\"]\n",
    "index_files = [file for pattern in patterns for file in glob.glob(base_input_path + \"\\\\*\" + pattern + \"*\")]\n",
    "filtered_files = [file for file in image_files if len(os.path.basename(file)) < 12]\n",
    "index_files.extend(filtered_files)\n",
    "\n",
    "# CREATE DATAFRAME\n",
    "index_files = pd.DataFrame(index_files, columns=[\"FilePath\"])\n",
    "\n",
    "# INDEX ATTRIBUTES TO BE ADDED\n",
    "index_files[\"Basename\"] = [os.path.basename(file) for file in index_files[\"FilePath\"].to_list()]    # BASENAME\n",
    "index_files[\"Location\"] = index_files[\"Basename\"].apply(extract_numerical_chars).astype(np.int32)   # \n",
    "index_files[\"GEOID\"]    = index_files[\"Location\"].apply(getGEOID)       # GET GEOID FOR EACH INDEX\n",
    "index_files[\"geometry\"] = index_files[\"GEOID\"].apply(getGeometry)       # GET GEOMETRY FROM MATCHING GEOIDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "544b54fd",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def getBBOX_coords(tile_ds : rio.DatasetReader, bbox : list) -> list:\n",
    "    \"\"\"\n",
    "    Converts Bounding Box pixel coordinates into actual coordinates by using the input rasterio dataset\n",
    "\n",
    "    Parameters:\n",
    "        tile_ds (rasterio.Dataset): Post-ICP rasterio dataset saved with a world file.\n",
    "        bbox (iterable): Bounding box coordinates in format (x_min, y_min, x_max, y_max),\n",
    "                      normalized by the total image width and height.\n",
    "\n",
    "    Returns:\n",
    "        coords (list): list of raster coordinates in (x_min, y_min, x_max, y_max) format.\n",
    "    \"\"\"\n",
    "    # x1, y1 = rio.transform.xy(tile_ds.transform, bbox[0], bbox[1]) WRONG X, Y \n",
    "    # x2, y2 = rio.transform.xy(tile_ds.transform, bbox[2], bbox[3]) WRONG X, Y\n",
    "    x1, y1 = rio.transform.xy(tile_ds.transform, bbox[1], bbox[0]) \n",
    "    x2, y2 = rio.transform.xy(tile_ds.transform, bbox[3], bbox[2])\n",
    "    return [x1, y1, x2, y2]\n",
    "\n",
    "def bbox_to_coords(bbox):\n",
    "    '''\n",
    "    x1, y1, x2, y2 = bbox\n",
    "\n",
    "    x_min = np.min([x1, x2])    \n",
    "    x_max = np.max([x1, x2])    \n",
    "    y_min = np.min([y1, y2])    \n",
    "    y_max = np.max([y1, y2])    \n",
    "\n",
    "    \n",
    "    '''\n",
    "    x_min, y_min, x_max, y_max = bbox\n",
    "\n",
    "    xs = [x_min, x_max, x_min, x_max]\n",
    "    ys = [y_min, y_min, y_max, y_max]\n",
    "    return xs, ys# [(x_min, y_min), (x_max, y_min), (x_max, y_max), (x_min, y_max)]\n",
    "\n",
    "# def getTileTransform(tile):\n",
    "\n",
    "def getTileAffine(tile, baseaffine=None):\n",
    "\n",
    "    b = baseaffine\n",
    "\n",
    "    w, h = tile['data'].size\n",
    "\n",
    "    x_i = [0, w, 0, w]\n",
    "    y_i = [0, 0, h, h]\n",
    "    x_c, y_c = bbox_to_coords(tile['coords'])\n",
    "\n",
    "    test = pd.DataFrame()\n",
    "    test[\"x_i\"] = x_i\n",
    "    test[\"y_i\"] = y_i\n",
    "    test[\"x_c\"] = x_c\n",
    "    test[\"y_c\"] = y_c\n",
    "\n",
    "    a = affineTransformation(x_i, y_i, x_c, y_c)\n",
    "\n",
    "    matrix = None\n",
    "    if b is not None: \n",
    "        matrix = b.flatten()[:6]\n",
    "        matrix[2] = a.matrix.flatten()[2]\n",
    "        matrix[5] = a.matrix.flatten()[5]\n",
    "    else:\n",
    "        matrix = a.matrix.flatten()[:6]\n",
    "         \n",
    "\n",
    "    return rio.Affine(*matrix)\n",
    "\n",
    "def saveTile(fn, tile, baseaffine=None):\n",
    "    transform = tile['affine'] if 'affine' in tile else getTileAffine(tile, baseaffine=baseaffine)\n",
    "    image = np.asarray(tile['data']).astype(np.uint8)\n",
    "    epsg_code = 3857\n",
    "    with rio.open(fn, 'w',\n",
    "        driver='GTiff',\n",
    "        height=image.shape[0],\n",
    "        width=image.shape[1],\n",
    "        count=1,\n",
    "        dtype='uint8',\n",
    "        crs=f'EPSG:{epsg_code}',\n",
    "        transform=transform) as dst:\n",
    "            dst.write(image, 1)    \n",
    "\n",
    "def ICPtoCRSTransform(image_arry, transform_dict):\n",
    "    # REVERSE Y AXIS\n",
    "    rev_y_axis = np.array([[1, 0, 0],\n",
    "                        [0,-1, 0],\n",
    "                        [0, 0, 1]])\n",
    "\n",
    "    # move = original_homography @ np.array([0, image_t.shape[0], 0])\n",
    "    translation = np.eye(3)\n",
    "    translation[1, 2] = image_arry.shape[0]\n",
    "\n",
    "    transform_dict['translation'] = translation\n",
    "    \n",
    "    # adjustment =  np.linalg.inv(transform_dict['best'].copy())\n",
    "    # rev_adj = adjustment.copy()\n",
    "    # rev_adj[1, 1] = rev_adj[1, 1] * -1\n",
    "    transform_dict['rev_adj'] = np.linalg.inv(transform_dict['best'].copy())\n",
    "\n",
    "    transform_dict['flip'] = np.array([\n",
    "    [1, 0, 0],\n",
    "    [0, -1, 0],\n",
    "    [0, 0, 1]\n",
    "    ])\n",
    "    \n",
    "    # output_transform = transform_dict['initial'] @ transform_dict['translation'] @ transform_dict['rev_adj']\n",
    "    output_transform = transform_dict['initial'] @ transform_dict['rev_adj'] @ transform_dict['translation']  @ transform_dict['flip']\n",
    "    offsets = output_transform @ np.array([[0, 0, 1], [image_arry.shape[0], 0, 1]]).T\n",
    "    offsets = offsets[:, 1] - offsets[:, 0]\n",
    "    transform_dict['offsets'] = offsets\n",
    "\n",
    "    return output_transform, transform_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3a761c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def runYOLO_Text(image_fn, model=None, \n",
    "        model_weights=f\"{data_dir}BBNN/weights042924.pt\",\n",
    "        save_dir=None,\n",
    "        device=\"cuda\",\n",
    "        verbose=True,\n",
    "        find_text = True,\n",
    "        keyed_text = False,\n",
    "        target_size = 1920,\n",
    "        conf_threshold = 0.92\n",
    "        ):\n",
    "    \n",
    "    \n",
    "    input_folder = os.path.dirname(os.path.abspath(image_fn))\n",
    "\n",
    "    # INITIALIZE MODEL AS NEEDED\n",
    "    if model is None:\n",
    "        model = ultralytics.YOLO(model_weights).to(\"cpu\")\n",
    "    model = model.to(device)\n",
    "    \n",
    "    # RUN MODEL\n",
    "    results = model(image_fn, imgsz=target_size, verbose=verbose)\n",
    "\n",
    "    if device == \"cuda\":\n",
    "        results = [result.cpu() for result in results]\n",
    "        model   = model.to(\"cpu\")\n",
    "\n",
    "    # FIND KEY FOR FILE\n",
    "    basen = os.path.basename(results[0].path)[:-4]\n",
    "    key = findKey(basen)\n",
    "\n",
    "    # GOTTA FIND CORRECT FILE BC RESIZED WERE SAVED WITH PNG EXTENSION\n",
    "    in_fn = glob.glob(os.path.join(input_folder,  basen + '*[!w]'))[0]\n",
    "    image = Image.open(in_fn)\n",
    "    width, height = image.size\n",
    "    im_size_arry  = np.array([width, height, width, height])\n",
    "\n",
    "    # OUTPUT STRUCTURE\n",
    "    outputs = {}\n",
    "    \n",
    "    # YOLO CONFIDENCE\n",
    "    conf = results[0].boxes.data.numpy()[:, -2] # GET CONFIDENCE LEVELS\n",
    "    slice = conf > conf_threshold               # SLICE CONFIDENCE LEVELS WITH THRESHOLDS\n",
    "\n",
    "    # FOR EACH RESULT \n",
    "    for i in range(results[0].boxes.xyxyn.numpy().shape[0]): # np.where(slice)[0]: \n",
    "        \n",
    "        # GET BBOX DATA\n",
    "        bbox = results[0].boxes.xyxyn.numpy()[i]\n",
    "        data = extract_bounded_area(image, bbox)\n",
    "\n",
    "        bbox = bbox * im_size_arry\n",
    "\n",
    "        # FIND TE\n",
    "        if find_text:\n",
    "            text = pytesseract.image_to_string(data, config='--psm 12 --oem 3') # -c tessedit_char_whitelist=0123456789\n",
    "\n",
    "            if keyed_text:\n",
    "                word = find_word_with_key(text, key, threshold=80, verbose=False)\n",
    "\n",
    "                if isinstance(word, list):\n",
    "                    word = \",\".join(word)\n",
    "            else:\n",
    "                word = None\n",
    "        else:\n",
    "            text, word = None, None\n",
    "\n",
    "        outputs[i] = {\"bbox\" : bbox, \"data\" : data, \"text\" : text, \"keyed_text\" : word, \"confidence\" : conf[i]}\n",
    "\n",
    "    if save_dir is not None:\n",
    "        results[0].save(save_dir)\n",
    "\n",
    "    return outputs, model\n",
    "\n",
    "def saveTiles(tiles, output_image_fn):\n",
    "    # DO NOT USE, IS WRONG\n",
    "    src = rio.open(output_image_fn)\n",
    "    for iii, (k, v) in enumerate(tiles.items()):\n",
    "        if k in ['transform_info', 'output_transform']:\n",
    "            continue\n",
    "\n",
    "        tiles[k]['coords'] = getBBOX_coords(src, tiles[k]['bbox'])\n",
    "        saveTile(os.path.join(outputs_dir, f\"{filename}_{k}.tif\"), v, baseaffine=output_transform)\n",
    "\n",
    "        try:\n",
    "            if k in ['transform_info', 'output_transform']:\n",
    "                continue\n",
    "            tiles[k]['coords'] = getBBOX_coords(src, tiles[k]['bbox'])\n",
    "            saveTile(os.path.join(outputs_dir, f\"{filename}_{k}.tif\"), v, baseaffine=output_transform)\n",
    "        except Exception as e:\n",
    "            print(\"ERROR : \"+str(e) + f\" {k}\")\n",
    "            continue\n",
    "\n",
    "\n",
    "def runTLNN(filename, TLNN=None):\n",
    "    if TLNN is None:\n",
    "        TLNN = {\n",
    "            \"tile\"      : {\"model\" : None, \"keyed_text\" : True,  \"model_weights\" : f\"{data_dir}BBNN/TileBBNN.pt\"}, \n",
    "            \"county\"    : {\"model\" : None, \"keyed_text\" : False, \"model_weights\" : f\"{data_dir}BBNN/CountyBBNN.pt\"}, \n",
    "            \"legend\"    : {\"model\" : None, \"keyed_text\" : False, \"model_weights\" : f\"{data_dir}BBNN/LegendBBNN.pt\"}}\n",
    "        \n",
    "    outputs = {}\n",
    "\n",
    "    # FOR EACH YOLO NN\n",
    "    for i, (k,v) in enumerate(TLNN.items()):\n",
    "        \n",
    "        # OUTPUT FILE\n",
    "        save_dir = os.path.join(outputs_dir, os.path.basename(filename).split(\".\")[0] + f\"_{k}BBNN.tif\")\n",
    "        \n",
    "        results, model = runYOLO_Text(filename, save_dir=None, **v)\n",
    "        outputs[k] = results\n",
    "        \n",
    "        # UPDATE WITH MODEL \n",
    "        v['model'] = model\n",
    "        TLNN[k]  = v\n",
    "\n",
    "    return outputs, TLNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f855f845",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting with predefined dict\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b28d4fd1973042cab71657f8acc2d885",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/183 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping, found D:\\RECTDNN\\processing\\\\2024-05-31_14-05-48\\Outputs\\480035IND0_0490.jpg.pkl\n",
      "Skipping, found D:\\RECTDNN\\processing\\\\2024-05-31_14-05-48\\Outputs\\480035IND0_0789.jpg.pkl\n",
      "Skipping, found D:\\RECTDNN\\processing\\\\2024-05-31_14-05-48\\Outputs\\480035IND0_0990.jpg.pkl\n",
      "Skipping, found D:\\RECTDNN\\processing\\\\2024-05-31_14-05-48\\Outputs\\480035IND0_1084.jpg.pkl\n",
      "Skipping, found D:\\RECTDNN\\processing\\\\2024-05-31_14-05-48\\Outputs\\480035IND0_1091.jpg.pkl\n",
      "Skipping, found D:\\RECTDNN\\processing\\\\2024-05-31_14-05-48\\Outputs\\480038IND0_1185.jpg.pkl\n",
      "Skipping, found D:\\RECTDNN\\processing\\\\2024-05-31_14-05-48\\Outputs\\480045IND0_0186.jpg.pkl\n",
      "Skipping, found D:\\RECTDNN\\processing\\\\2024-05-31_14-05-48\\Outputs\\480045IND0_0189.jpg.pkl\n",
      "Skipping, found D:\\RECTDNN\\processing\\\\2024-05-31_14-05-48\\Outputs\\480045IND0_0486.jpg.pkl\n",
      "Skipping, found D:\\RECTDNN\\processing\\\\2024-05-31_14-05-48\\Outputs\\480045IND0_0678.jpg.pkl\n",
      "Skipping, found D:\\RECTDNN\\processing\\\\2024-05-31_14-05-48\\Outputs\\480045IND0_0791.jpg.pkl\n",
      "Skipping, found D:\\RECTDNN\\processing\\\\2024-05-31_14-05-48\\Outputs\\480045IND0_0890.jpg.pkl\n",
      "Skipping, found D:\\RECTDNN\\processing\\\\2024-05-31_14-05-48\\Outputs\\480045IND0_1184.jpg.pkl\n",
      "Skipping, found D:\\RECTDNN\\processing\\\\2024-05-31_14-05-48\\Outputs\\480045IND0_1283.jpg.pkl\n",
      "Skipping, found D:\\RECTDNN\\processing\\\\2024-05-31_14-05-48\\Outputs\\480046IND0_0780.jpg.pkl\n",
      "Skipping, found D:\\RECTDNN\\processing\\\\2024-05-31_14-05-48\\Outputs\\480233IND0_0382.jpg.pkl\n",
      "COULD NOT FIND SHAPEFILE FOR 480243IND0_0583.jpg\n",
      "COULD NOT FIND SHAPEFILE FOR 480243IND0_1083.jpg\n",
      "Skipping, found D:\\RECTDNN\\processing\\\\2024-05-31_14-05-48\\Outputs\\480266IND0.tif.pkl\n",
      "Skipping, found D:\\RECTDNN\\processing\\\\2024-05-31_14-05-48\\Outputs\\480267IND0.tif.pkl\n",
      "Skipping, found D:\\RECTDNN\\processing\\\\2024-05-31_14-05-48\\Outputs\\480267IND0_0581.jpg.pkl\n",
      "Skipping, found D:\\RECTDNN\\processing\\\\2024-05-31_14-05-48\\Outputs\\480269IND0.tif.pkl\n",
      "Skipping, found D:\\RECTDNN\\processing\\\\2024-05-31_14-05-48\\Outputs\\480269IND0_0992.jpg.pkl\n",
      "Skipping, found D:\\RECTDNN\\processing\\\\2024-05-31_14-05-48\\Outputs\\480287IND0_0281.jpg.pkl\n",
      "Skipping, found D:\\RECTDNN\\processing\\\\2024-05-31_14-05-48\\Outputs\\480287IND0_0288.jpg.pkl\n",
      "Skipping, found D:\\RECTDNN\\processing\\\\2024-05-31_14-05-48\\Outputs\\480287IND0_0382.jpg.pkl\n",
      "Skipping, found D:\\RECTDNN\\processing\\\\2024-05-31_14-05-48\\Outputs\\480287IND0_0985.jpg.pkl\n",
      "Skipping, found D:\\RECTDNN\\processing\\\\2024-05-31_14-05-48\\Outputs\\480296IND0_0982.jpg.pkl\n",
      "Skipping, found D:\\RECTDNN\\processing\\\\2024-05-31_14-05-48\\Outputs\\480296IND0_0985.jpg.pkl\n",
      "Skipping, found D:\\RECTDNN\\processing\\\\2024-05-31_14-05-48\\Outputs\\480296IND0_0987.jpg.pkl\n",
      "Skipping, found D:\\RECTDNN\\processing\\\\2024-05-31_14-05-48\\Outputs\\480296IND0_1279.jpg.pkl\n",
      "Skipping, found D:\\RECTDNN\\processing\\\\2024-05-31_14-05-48\\Outputs\\48029CIND0.tif.pkl\n",
      "Skipping, found D:\\RECTDNN\\processing\\\\2024-05-31_14-05-48\\Outputs\\48029CIND0A.tif.pkl\n",
      "Skipping, found D:\\RECTDNN\\processing\\\\2024-05-31_14-05-48\\Outputs\\48029CIND0B.tif.pkl\n",
      "Skipping, found D:\\RECTDNN\\processing\\\\2024-05-31_14-05-48\\Outputs\\48029CIND0C.tif.pkl\n",
      "Skipping, found D:\\RECTDNN\\processing\\\\2024-05-31_14-05-48\\Outputs\\48029CIND0D.png.pkl\n",
      "Skipping, found D:\\RECTDNN\\processing\\\\2024-05-31_14-05-48\\Outputs\\48029CIND0_0296.tif.pkl\n",
      "Skipping, found D:\\RECTDNN\\processing\\\\2024-05-31_14-05-48\\Outputs\\480304IND0_0182.jpg.pkl\n",
      "Skipping, found D:\\RECTDNN\\processing\\\\2024-05-31_14-05-48\\Outputs\\480304IND0_1077.jpg.pkl\n",
      "Skipping, found D:\\RECTDNN\\processing\\\\2024-05-31_14-05-48\\Outputs\\480304IND0_1287.jpg.pkl\n",
      "Skipping, found D:\\RECTDNN\\processing\\\\2024-05-31_14-05-48\\Outputs\\480307IND0_0686.jpg.pkl\n",
      "Skipping, found D:\\RECTDNN\\processing\\\\2024-05-31_14-05-48\\Outputs\\48039CIND0.tif.pkl\n",
      "Skipping, found D:\\RECTDNN\\processing\\\\2024-05-31_14-05-48\\Outputs\\480423IND0.tif.pkl\n",
      "Skipping, found D:\\RECTDNN\\processing\\\\2024-05-31_14-05-48\\Outputs\\480423IND0_0384.jpg.pkl\n",
      "Skipping, found D:\\RECTDNN\\processing\\\\2024-05-31_14-05-48\\Outputs\\480424IND0.tif.pkl\n",
      "Skipping, found D:\\RECTDNN\\processing\\\\2024-05-31_14-05-48\\Outputs\\48071CIND0A.tif.pkl\n",
      "Skipping, found D:\\RECTDNN\\processing\\\\2024-05-31_14-05-48\\Outputs\\481271IND0.tif.pkl\n",
      "Skipping, found D:\\RECTDNN\\processing\\\\2024-05-31_14-05-48\\Outputs\\481271IND0A.tif.pkl\n",
      "Skipping, found D:\\RECTDNN\\processing\\\\2024-05-31_14-05-48\\Outputs\\481562IND0.tif.pkl\n",
      "Skipping, found D:\\RECTDNN\\processing\\\\2024-05-31_14-05-48\\Outputs\\481569IND0.tif.pkl\n",
      "Skipping, found D:\\RECTDNN\\processing\\\\2024-05-31_14-05-48\\Outputs\\481569IND0_0283.jpg.pkl\n",
      "Skipping, found D:\\RECTDNN\\processing\\\\2024-05-31_14-05-48\\Outputs\\481569IND0_0391.jpg.pkl\n",
      "Skipping, found D:\\RECTDNN\\processing\\\\2024-05-31_14-05-48\\Outputs\\48157CIND0.tif.pkl\n",
      "Skipping, found D:\\RECTDNN\\processing\\\\2024-05-31_14-05-48\\Outputs\\48157CIND0A.tif.pkl\n",
      "Skipping, found D:\\RECTDNN\\processing\\\\2024-05-31_14-05-48\\Outputs\\48157CIND0B.tif.pkl\n",
      "Skipping, found D:\\RECTDNN\\processing\\\\2024-05-31_14-05-48\\Outputs\\48187CIND0A.tif.pkl\n",
      "Skipping, found D:\\RECTDNN\\processing\\\\2024-05-31_14-05-48\\Outputs\\48201CIND0.tif.pkl\n",
      "Skipping, found D:\\RECTDNN\\processing\\\\2024-05-31_14-05-48\\Outputs\\48201CIND0A.tif.pkl\n",
      "Skipping, found D:\\RECTDNN\\processing\\\\2024-05-31_14-05-48\\Outputs\\48201CIND0B.tif.pkl\n",
      "Skipping, found D:\\RECTDNN\\processing\\\\2024-05-31_14-05-48\\Outputs\\48201CIND0C.tif.pkl\n",
      "Skipping, found D:\\RECTDNN\\processing\\\\2024-05-31_14-05-48\\Outputs\\48201CIND0D.tif.pkl\n",
      "Skipping, found D:\\RECTDNN\\processing\\\\2024-05-31_14-05-48\\Outputs\\48201CIND0E.tif.pkl\n",
      "Skipping, found D:\\RECTDNN\\processing\\\\2024-05-31_14-05-48\\Outputs\\48201CIND0F.tif.pkl\n",
      "Skipping, found D:\\RECTDNN\\processing\\\\2024-05-31_14-05-48\\Outputs\\48201CIND0_0990.jpg.pkl\n",
      "Skipping, found D:\\RECTDNN\\processing\\\\2024-05-31_14-05-48\\Outputs\\48201CIND0_0992.tif.pkl\n",
      "Skipping, found D:\\RECTDNN\\processing\\\\2024-05-31_14-05-48\\Outputs\\48201CIND0_1196.tif.pkl\n",
      "Skipping, found D:\\RECTDNN\\processing\\\\2024-05-31_14-05-48\\Outputs\\48259CIND0A.tif.pkl\n",
      "Skipping, found D:\\RECTDNN\\processing\\\\2024-05-31_14-05-48\\Outputs\\48325CIND0A.tif.pkl\n",
      "Skipping, found D:\\RECTDNN\\processing\\\\2024-05-31_14-05-48\\Outputs\\48339CIND0.tif.pkl\n",
      "Skipping, found D:\\RECTDNN\\processing\\\\2024-05-31_14-05-48\\Outputs\\48473CIND0A.tif.pkl\n",
      "Skipping, found D:\\RECTDNN\\processing\\\\2024-05-31_14-05-48\\Outputs\\485456IND0_0279.jpg.pkl\n",
      "Skipping, found D:\\RECTDNN\\processing\\\\2024-05-31_14-05-48\\Outputs\\485456IND0_0982.jpg.pkl\n",
      "Skipping, found D:\\RECTDNN\\processing\\\\2024-05-31_14-05-48\\Outputs\\485456IND0_1185.jpg.pkl\n",
      "Skipping, found D:\\RECTDNN\\processing\\\\2024-05-31_14-05-48\\Outputs\\485468IND0_0483.jpg.pkl\n",
      "Skipping, found D:\\RECTDNN\\processing\\\\2024-05-31_14-05-48\\Outputs\\485469IND0.tif.pkl\n",
      "Skipping, found D:\\RECTDNN\\processing\\\\2024-05-31_14-05-48\\Outputs\\485469IND0A.tif.pkl\n",
      "Skipping, found D:\\RECTDNN\\processing\\\\2024-05-31_14-05-48\\Outputs\\485469IND0_0592.jpg.pkl\n",
      "Skipping, found D:\\RECTDNN\\processing\\\\2024-05-31_14-05-48\\Outputs\\485469IND0_0680.jpg.pkl\n",
      "Skipping, found D:\\RECTDNN\\processing\\\\2024-05-31_14-05-48\\Outputs\\485469IND0_0883.jpg.pkl\n",
      "Skipping, found D:\\RECTDNN\\processing\\\\2024-05-31_14-05-48\\Outputs\\485469IND0_1084.jpg.pkl\n",
      "Skipping, found D:\\RECTDNN\\processing\\\\2024-05-31_14-05-48\\Outputs\\485470IND0.tif.pkl\n",
      "Skipping, found D:\\RECTDNN\\processing\\\\2024-05-31_14-05-48\\Outputs\\485470IND0A.tif.pkl\n",
      "Skipping, found D:\\RECTDNN\\processing\\\\2024-05-31_14-05-48\\Outputs\\485470IND0_0583.jpg.pkl\n",
      "Skipping, found D:\\RECTDNN\\processing\\\\2024-05-31_14-05-48\\Outputs\\485470IND0_0892.jpg.pkl\n",
      "Skipping, found D:\\RECTDNN\\processing\\\\2024-05-31_14-05-48\\Outputs\\485470IND0_1083.jpg.pkl\n",
      "Skipping, found D:\\RECTDNN\\processing\\\\2024-05-31_14-05-48\\Outputs\\485470IND0_1190.jpg.pkl\n",
      "Skipping, found D:\\RECTDNN\\processing\\\\2024-05-31_14-05-48\\Outputs\\485479IND0.tif.pkl\n",
      "Skipping, found D:\\RECTDNN\\processing\\\\2024-05-31_14-05-48\\Outputs\\485481IND0.tif.pkl\n",
      "Skipping, found D:\\RECTDNN\\processing\\\\2024-05-31_14-05-48\\Outputs\\485486IND0.tif.pkl\n",
      "Skipping, found D:\\RECTDNN\\processing\\\\2024-05-31_14-05-48\\Outputs\\485486IND0_0877.jpg.pkl\n",
      "Skipping, found D:\\RECTDNN\\processing\\\\2024-05-31_14-05-48\\Outputs\\485486IND0_1078.jpg.pkl\n",
      "Skipping, found D:\\RECTDNN\\processing\\\\2024-05-31_14-05-48\\Outputs\\485487IND0_1185.jpg.pkl\n",
      "Skipping, found D:\\RECTDNN\\processing\\\\2024-05-31_14-05-48\\Outputs\\485488IND0.tif.pkl\n",
      "Skipping, found D:\\RECTDNN\\processing\\\\2024-05-31_14-05-48\\Outputs\\485488IND0_0583.jpg.pkl\n",
      "Skipping, found D:\\RECTDNN\\processing\\\\2024-05-31_14-05-48\\Outputs\\485488IND0_0990.tif.pkl\n",
      "Skipping, found D:\\RECTDNN\\processing\\\\2024-05-31_14-05-48\\Outputs\\485514IND0.tif.pkl\n",
      "Skipping, found D:\\RECTDNN\\processing\\\\2024-05-31_14-05-48\\Outputs\\485514IND0_0583.jpg.pkl\n",
      "Skipping, found D:\\RECTDNN\\processing\\\\2024-05-31_14-05-48\\Outputs\\485516IND0_0281.jpg.pkl\n",
      "Skipping, found D:\\RECTDNN\\processing\\\\2024-05-31_14-05-48\\Outputs\\480035A_1.tif.pkl\n",
      "Skipping, found D:\\RECTDNN\\processing\\\\2024-05-31_14-05-48\\Outputs\\480036A_1.tif.pkl\n",
      "Skipping, found D:\\RECTDNN\\processing\\\\2024-05-31_14-05-48\\Outputs\\480037A_1.tif.pkl\n",
      "Skipping, found D:\\RECTDNN\\processing\\\\2024-05-31_14-05-48\\Outputs\\480038A_1.tif.pkl\n",
      "Skipping, found D:\\RECTDNN\\processing\\\\2024-05-31_14-05-48\\Outputs\\480039_1.tif.pkl\n",
      "Skipping, found D:\\RECTDNN\\processing\\\\2024-05-31_14-05-48\\Outputs\\480040A_1.tif.pkl\n",
      "Skipping, found D:\\RECTDNN\\processing\\\\2024-05-31_14-05-48\\Outputs\\480041A_1.tif.pkl\n",
      "Skipping, found D:\\RECTDNN\\processing\\\\2024-05-31_14-05-48\\Outputs\\480041_1.tif.pkl\n",
      "Skipping, found D:\\RECTDNN\\processing\\\\2024-05-31_14-05-48\\Outputs\\480042A_1.tif.pkl\n",
      "Skipping, found D:\\RECTDNN\\processing\\\\2024-05-31_14-05-48\\Outputs\\480043A_1.tif.pkl\n",
      "Skipping, found D:\\RECTDNN\\processing\\\\2024-05-31_14-05-48\\Outputs\\480043_1.tif.pkl\n",
      "Skipping, found D:\\RECTDNN\\processing\\\\2024-05-31_14-05-48\\Outputs\\480046_1.tif.pkl\n",
      "Skipping, found D:\\RECTDNN\\processing\\\\2024-05-31_14-05-48\\Outputs\\480047A_1.tif.pkl\n",
      "Skipping, found D:\\RECTDNN\\processing\\\\2024-05-31_14-05-48\\Outputs\\480048A_1.tif.pkl\n",
      "Skipping, found D:\\RECTDNN\\processing\\\\2024-05-31_14-05-48\\Outputs\\480049A_1.tif.pkl\n",
      "Skipping, found D:\\RECTDNN\\processing\\\\2024-05-31_14-05-48\\Outputs\\480077A_1.tif.pkl\n",
      "Skipping, found D:\\RECTDNN\\processing\\\\2024-05-31_14-05-48\\Outputs\\480077_1.tif.pkl\n",
      "COULD NOT FIND SHAPEFILE FOR 480243_1.tif\n",
      "Skipping, found D:\\RECTDNN\\processing\\\\2024-05-31_14-05-48\\Outputs\\480267A_1.tif.pkl\n",
      "Skipping, found D:\\RECTDNN\\processing\\\\2024-05-31_14-05-48\\Outputs\\480269A_1.tif.pkl\n",
      "Skipping, found D:\\RECTDNN\\processing\\\\2024-05-31_14-05-48\\Outputs\\480269_1.tif.pkl\n",
      "Skipping, found D:\\RECTDNN\\processing\\\\2024-05-31_14-05-48\\Outputs\\480287B_1.tif.pkl\n",
      "Skipping, found D:\\RECTDNN\\processing\\\\2024-05-31_14-05-48\\Outputs\\480289A_1.tif.pkl\n",
      "Skipping, found D:\\RECTDNN\\processing\\\\2024-05-31_14-05-48\\Outputs\\480289_1.tif.pkl\n",
      "Skipping, found D:\\RECTDNN\\processing\\\\2024-05-31_14-05-48\\Outputs\\480290A_1.tif.pkl\n",
      "Skipping, found D:\\RECTDNN\\processing\\\\2024-05-31_14-05-48\\Outputs\\480291_1.tif.pkl\n",
      "Skipping, found D:\\RECTDNN\\processing\\\\2024-05-31_14-05-48\\Outputs\\480293A_1.tif.pkl\n",
      "Skipping, found D:\\RECTDNN\\processing\\\\2024-05-31_14-05-48\\Outputs\\480293_1.tif.pkl\n",
      "Skipping, found D:\\RECTDNN\\processing\\\\2024-05-31_14-05-48\\Outputs\\480295A_1.tif.pkl\n",
      "Skipping, found D:\\RECTDNN\\processing\\\\2024-05-31_14-05-48\\Outputs\\480296A_1.tif.pkl\n",
      "Skipping, found D:\\RECTDNN\\processing\\\\2024-05-31_14-05-48\\Outputs\\480297A_1.tif.pkl\n",
      "Skipping, found D:\\RECTDNN\\processing\\\\2024-05-31_14-05-48\\Outputs\\480298A_1.tif.pkl\n",
      "Skipping, found D:\\RECTDNN\\processing\\\\2024-05-31_14-05-48\\Outputs\\480299_1.tif.pkl\n",
      "Skipping, found D:\\RECTDNN\\processing\\\\2024-05-31_14-05-48\\Outputs\\480300A_1.tif.pkl\n",
      "Skipping, found D:\\RECTDNN\\processing\\\\2024-05-31_14-05-48\\Outputs\\480301A_1.tif.pkl\n",
      "COULD NOT FIND SHAPEFILE FOR 480303A_1.tif\n",
      "COULD NOT FIND SHAPEFILE FOR 480303_1.tif\n",
      "Skipping, found D:\\RECTDNN\\processing\\\\2024-05-31_14-05-48\\Outputs\\480304_1.tif.pkl\n",
      "Skipping, found D:\\RECTDNN\\processing\\\\2024-05-31_14-05-48\\Outputs\\480305A_1.tif.pkl\n",
      "Skipping, found D:\\RECTDNN\\processing\\\\2024-05-31_14-05-48\\Outputs\\480307A_1.tif.pkl\n",
      "Skipping, found D:\\RECTDNN\\processing\\\\2024-05-31_14-05-48\\Outputs\\480307C_1.tif.pkl\n",
      "Skipping, found D:\\RECTDNN\\processing\\\\2024-05-31_14-05-48\\Outputs\\480308_1.tif.pkl\n",
      "Skipping, found D:\\RECTDNN\\processing\\\\2024-05-31_14-05-48\\Outputs\\480311A_1.tif.pkl\n",
      "Skipping, found D:\\RECTDNN\\processing\\\\2024-05-31_14-05-48\\Outputs\\480313A_1.tif.pkl\n",
      "Skipping, found D:\\RECTDNN\\processing\\\\2024-05-31_14-05-48\\Outputs\\480315_1.tif.pkl\n",
      "Skipping, found D:\\RECTDNN\\processing\\\\2024-05-31_14-05-48\\Outputs\\480423_1.tif.pkl\n",
      "Skipping, found D:\\RECTDNN\\processing\\\\2024-05-31_14-05-48\\Outputs\\480424A_1.tif.pkl\n",
      "Skipping, found D:\\RECTDNN\\processing\\\\2024-05-31_14-05-48\\Outputs\\480424B_1.tif.pkl\n",
      "Skipping, found D:\\RECTDNN\\processing\\\\2024-05-31_14-05-48\\Outputs\\480424_1.tif.pkl\n",
      "Skipping, found D:\\RECTDNN\\processing\\\\2024-05-31_14-05-48\\Outputs\\480641A_1.tif.pkl\n",
      "Skipping, found D:\\RECTDNN\\processing\\\\2024-05-31_14-05-48\\Outputs\\480692A_1.tif.pkl\n",
      "Skipping, found D:\\RECTDNN\\processing\\\\2024-05-31_14-05-48\\Outputs\\480710_1.tif.pkl\n",
      "Skipping, found D:\\RECTDNN\\processing\\\\2024-05-31_14-05-48\\Outputs\\481094_1.tif.pkl\n",
      "Skipping, found D:\\RECTDNN\\processing\\\\2024-05-31_14-05-48\\Outputs\\481141_1.tif.pkl\n",
      "Skipping, found D:\\RECTDNN\\processing\\\\2024-05-31_14-05-48\\Outputs\\485456A_1.tif.pkl\n",
      "Skipping, found D:\\RECTDNN\\processing\\\\2024-05-31_14-05-48\\Outputs\\485466B_1.tif.pkl\n",
      "Skipping, found D:\\RECTDNN\\processing\\\\2024-05-31_14-05-48\\Outputs\\485468A_1.tif.pkl\n",
      "Skipping, found D:\\RECTDNN\\processing\\\\2024-05-31_14-05-48\\Outputs\\485468B_1.tif.pkl\n",
      "Skipping, found D:\\RECTDNN\\processing\\\\2024-05-31_14-05-48\\Outputs\\485469B_1.tif.pkl\n",
      "Skipping, found D:\\RECTDNN\\processing\\\\2024-05-31_14-05-48\\Outputs\\485470A_1.tif.pkl\n",
      "Skipping, found D:\\RECTDNN\\processing\\\\2024-05-31_14-05-48\\Outputs\\485470B_1.tif.pkl\n",
      "Skipping, found D:\\RECTDNN\\processing\\\\2024-05-31_14-05-48\\Outputs\\485486A_1.tif.pkl\n",
      "Skipping, found D:\\RECTDNN\\processing\\\\2024-05-31_14-05-48\\Outputs\\485487B_1.tif.pkl\n",
      "Skipping, found D:\\RECTDNN\\processing\\\\2024-05-31_14-05-48\\Outputs\\485487C_1.tif.pkl\n",
      "Skipping, found D:\\RECTDNN\\processing\\\\2024-05-31_14-05-48\\Outputs\\485487_1.tif.pkl\n",
      "Skipping, found D:\\RECTDNN\\processing\\\\2024-05-31_14-05-48\\Outputs\\485488A_1.tif.pkl\n",
      "Skipping, found D:\\RECTDNN\\processing\\\\2024-05-31_14-05-48\\Outputs\\485491B_1.tif.pkl\n",
      "Skipping, found D:\\RECTDNN\\processing\\\\2024-05-31_14-05-48\\Outputs\\485491C_1.tif.pkl\n",
      "Skipping, found D:\\RECTDNN\\processing\\\\2024-05-31_14-05-48\\Outputs\\485491D_1.tif.pkl\n",
      "Skipping, found D:\\RECTDNN\\processing\\\\2024-05-31_14-05-48\\Outputs\\485513A_1.tif.pkl\n",
      "Skipping, found D:\\RECTDNN\\processing\\\\2024-05-31_14-05-48\\Outputs\\485514A_1.tif.pkl\n",
      "Skipping, found D:\\RECTDNN\\processing\\\\2024-05-31_14-05-48\\Outputs\\485516_1.tif.pkl\n",
      "Skipping, found D:\\RECTDNN\\processing\\\\2024-05-31_14-05-48\\Outputs\\481264A.tif.pkl\n",
      "Skipping, found D:\\RECTDNN\\processing\\\\2024-05-31_14-05-48\\Outputs\\485461.tif.pkl\n",
      "Skipping, found D:\\RECTDNN\\processing\\\\2024-05-31_14-05-48\\Outputs\\485466.tif.pkl\n",
      "Skipping, found D:\\RECTDNN\\processing\\\\2024-05-31_14-05-48\\Outputs\\485469A.tif.pkl\n",
      "\n",
      "image 1/1 D:\\RECTDNN\\Uncompress\\485479B.tif: 1248x1920 6 tiles, 241.7ms\n",
      "Speed: 18.9ms preprocess, 241.7ms inference, 2.0ms postprocess per image at shape (1, 3, 1248, 1920)\n",
      "\n",
      "image 1/1 D:\\RECTDNN\\Uncompress\\485479C.tif: 1248x1920 7 tiles, 238.7ms\n",
      "Speed: 20.1ms preprocess, 238.7ms inference, 2.0ms postprocess per image at shape (1, 3, 1248, 1920)\n",
      "\n",
      "image 1/1 D:\\RECTDNN\\Uncompress\\485481A.tif: 1120x1920 2 tiles, 226.9ms\n",
      "Speed: 16.0ms preprocess, 226.9ms inference, 1.0ms postprocess per image at shape (1, 3, 1120, 1920)\n",
      "\n",
      "image 1/1 D:\\RECTDNN\\Uncompress\\485491.tif: 1248x1920 2 tiles, 234.2ms\n",
      "Speed: 20.1ms preprocess, 234.2ms inference, 1.0ms postprocess per image at shape (1, 3, 1248, 1920)\n",
      "\n",
      "image 1/1 D:\\RECTDNN\\Uncompress\\485491.tif: 1248x1920 (no detections), 245.2ms\n",
      "Speed: 18.9ms preprocess, 245.2ms inference, 0.0ms postprocess per image at shape (1, 3, 1248, 1920)\n",
      "\n",
      "image 1/1 D:\\RECTDNN\\Uncompress\\485491.tif: 1248x1920 (no detections), 237.4ms\n",
      "Speed: 19.0ms preprocess, 237.4ms inference, 1.0ms postprocess per image at shape (1, 3, 1248, 1920)\n",
      "\n",
      "image 1/1 D:\\RECTDNN\\Uncompress\\485510.tif: 1216x1920 15 tiles, 232.1ms\n",
      "Speed: 18.0ms preprocess, 232.1ms inference, 1.0ms postprocess per image at shape (1, 3, 1216, 1920)\n",
      "\n",
      "image 1/1 D:\\RECTDNN\\Uncompress\\485510B.tif: 1248x1920 2 tiles, 241.4ms\n",
      "Speed: 21.9ms preprocess, 241.4ms inference, 1.0ms postprocess per image at shape (1, 3, 1248, 1920)\n",
      "\n",
      "image 1/1 D:\\RECTDNN\\Uncompress\\485513.tif: 1248x1920 5 tiles, 239.7ms\n",
      "Speed: 20.1ms preprocess, 239.7ms inference, 1.0ms postprocess per image at shape (1, 3, 1248, 1920)\n",
      "\n",
      "image 1/1 D:\\RECTDNN\\Uncompress\\485513.tif: 1248x1920 1 county, 238.2ms\n",
      "Speed: 20.1ms preprocess, 238.2ms inference, 1.0ms postprocess per image at shape (1, 3, 1248, 1920)\n",
      "\n",
      "image 1/1 D:\\RECTDNN\\Uncompress\\485513.tif: 1248x1920 1 legend, 240.2ms\n",
      "Speed: 18.0ms preprocess, 240.2ms inference, 2.0ms postprocess per image at shape (1, 3, 1248, 1920)\n",
      "\n",
      "image 1/1 D:\\RECTDNN\\Uncompress\\485514B.tif: 1216x1920 36 tiles, 231.3ms\n",
      "Speed: 18.1ms preprocess, 231.3ms inference, 1.0ms postprocess per image at shape (1, 3, 1216, 1920)\n",
      "\n",
      "image 1/1 D:\\RECTDNN\\Uncompress\\485516A.tif: 1248x1920 6 tiles, 238.3ms\n",
      "Speed: 19.0ms preprocess, 238.3ms inference, 1.0ms postprocess per image at shape (1, 3, 1248, 1920)\n"
     ]
    }
   ],
   "source": [
    "verbose = True\n",
    "\n",
    "TPNN = None\n",
    "RLNN = None\n",
    "CLNN = None\n",
    "\n",
    "try:\n",
    "    gen_dict\n",
    "    print(\"Starting with predefined dict\")\n",
    "except:\n",
    "    gen_dict = {}\n",
    "\n",
    "for i, row in tqdm(index_files.iterrows(), total=index_files.shape[0]):\n",
    "    \n",
    "    try:\n",
    "\n",
    "        filename = os.path.basename(row[\"FilePath\"])\n",
    "        \n",
    "        if os.path.exists(os.path.join(outputs_dir, f\"{filename}.pkl\")):\n",
    "             print(f\"Skipping, found {os.path.join(outputs_dir, filename + '.pkl')}\")\n",
    "             continue\n",
    "\n",
    "        # READ FILES AND CONVERT TO GRAYSCALE\n",
    "        image = cv2.imread(row[\"FilePath\"])\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        image_arry = np.asarray(image)\n",
    "        \n",
    "        # SAVE IMAGE TO OUTPUT DIRECTORY\n",
    "        output_image_fn = os.path.join(outputs_dir, filename.split(\".\")[0] + \".tif\")\n",
    "        copyfile(row[\"FilePath\"], output_image_fn)\n",
    "\n",
    "        # GET BOUNDARY POINTS FROM RESPECTIVE SHAPEFILE\n",
    "        output = getBoundaryPoints(row, distance=100)\n",
    "        if output is None:\n",
    "            print(f\"COULD NOT FIND SHAPEFILE FOR {filename}\")\n",
    "            continue\n",
    "        point_boundary_gdf, shp_bounds = output\n",
    "        \n",
    "        # RUN IMAGES THROUGH DNNs\n",
    "        classifications, TPNN  = findKeypoints(image, model=TPNN, **dnn_params['TPNN'])\n",
    "        effectiveArea, RLNN    = findSquares(image, model=RLNN, **dnn_params['RLNN'])\n",
    "        countyArea, CLNN       = findCounty(image, model=CLNN, **dnn_params['CLNN'])\n",
    "        # tiles, TLNN            = findTiles(row[\"FilePath\"], model=TLNN, **dnn_params['TLNN'], verbose=False, device=\"cuda\",\n",
    "        #                                    save_dir=os.path.join(outputs_dir, filename.split(\".\")[0] + \"_BBNN.tif\"))\n",
    "\n",
    "        tiles, TLNN = runTLNN(row['FilePath'])\n",
    "\n",
    "        dnn_outputs = {\n",
    "            \"classifications\"   : classifications,\n",
    "            \"effectiveArea\"     : effectiveArea,\n",
    "            \"countyArea\"    : countyArea,\n",
    "            \"tiles\"         : tiles\n",
    "        }\n",
    "        \n",
    "        # GET COUNTY BOUNDS IDENTIFIED IN INDEX BY TLNN\n",
    "        # bounds_panels = tiles[\"county\"][\"bbox\"]\n",
    "        bounds_panels = find_bbox(dnn_outputs['countyArea'][:, :, 1])\n",
    "\n",
    "        # SKIP IF WE CAN'T FIND BOUNDARY IN EXISTING DATABASES\n",
    "        if point_boundary_gdf is None:\n",
    "            continue\n",
    "\n",
    "        # DEFINE BOUNDARY STRUCTU\n",
    "        boundaries = {\n",
    "            \"point_boundary_gdf\"    : point_boundary_gdf,\n",
    "            \"shp_bounds\"            : shp_bounds,\n",
    "            \"bounds_panels\"         : bounds_panels,\n",
    "        }\n",
    "\n",
    "        # WHAT ARE WE LOOKING FOR IN EACH IDENTIFIED SQUARE?\n",
    "        key = findKey(row[\"Basename\"])    \n",
    "        if key is None:\n",
    "            print(f\"Could not find key in {filename}\")\n",
    "        \n",
    "        # DO ICP\n",
    "        transform_dict = performICPonIndex(boundaries, dnn_outputs, debug=False, plot=False, rotation=True, shear=False, perspective=False, icp_iterations=30)\n",
    "\n",
    "        # GET TRANSFORM FROM ICP TO CRS TRANSFORM\n",
    "        output_transform, transform_dict = ICPtoCRSTransform(image_arry, transform_dict)\n",
    "\n",
    "        # GET OUTPUT TRANSFORM INTO AFFINE AND WRITE\n",
    "        output_affine = Affine(*output_transform.flatten()[:6])\n",
    "        with rio.open(output_image_fn, 'w',\n",
    "            driver='GTiff',\n",
    "            height=image.shape[0], width=image.shape[1],\n",
    "            count=1, dtype=image.dtype,\n",
    "            crs=f'EPSG:3857',\n",
    "            transform=rio.Affine(*output_transform.flatten()[:6])) as dst:\n",
    "                dst.write(image, 1)   \n",
    "\n",
    "        tiles['transform_info'] = transform_dict\n",
    "        tiles['output_transform'] = output_transform\n",
    "        gen_dict[filename] = tiles\n",
    "\n",
    "        with open(os.path.join(outputs_dir, f\"{filename}.pkl\"), 'wb') as handle:\n",
    "            pickle.dump(gen_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "\n",
    "\n",
    "with open(os.path.join(outputs_dir, \"IndexCoords.pkl\"), 'wb') as handle:\n",
    "    pickle.dump(gen_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "628ad38a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "171"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(gen_dict.keys())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
