{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7621809",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\fhace\\miniforge-pypy3\\envs\\rectdnn\\lib\\site-packages\\fuzzywuzzy\\fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
      "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"
     ]
    }
   ],
   "source": [
    "# NOTEBOOK IMPORTS\n",
    "import os, glob, warnings\n",
    "import numpy as np\n",
    "from shutil import copyfile, rmtree\n",
    "from datetime import datetime\n",
    "\n",
    "# IMAGE IMPORTS\n",
    "from PIL import Image\n",
    "\n",
    "# GIS IMPORTS\n",
    "from affine import Affine\n",
    "import pandas as pd\n",
    "\n",
    "# PLOTTING IMPORTS\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# CUSTOM UTILITIES\n",
    "from IndexUtils import * \n",
    "\n",
    "Image.MAX_IMAGE_PIXELS = 933120000\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ed09b63",
   "metadata": {},
   "source": [
    "IO directories depending on which machine. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "34617015",
   "metadata": {},
   "outputs": [],
   "source": [
    "username = os.getlogin()\n",
    "\n",
    "dnn_params = {}\n",
    "dnn_params['CLNN'] = {}\n",
    "dnn_params['TPNN'] = {}\n",
    "dnn_params['RLNN'] = {}\n",
    "dnn_params['FLNN'] = {}\n",
    "dnn_params['TLNN'] = {}\n",
    "\n",
    "\n",
    "if username == 'fhacesga':\n",
    "    base_input_path   = r\"D:\\FloodChange\\AAA_HistoricalDownload\"\n",
    "    base_output_path  = r\"C:\\Users\\\\\"+username+\"\\Desktop\\FIRMsDigitizing\\processing\"\n",
    "    ref_dir  = r\"C:\\Users\\fhacesga\\OneDrive - University Of Houston\\AAA_RECTDNN\\data\\AAA_ReferenceDatasets\\\\\"\n",
    "elif username == 'fhace':\n",
    "    ref_dir = r\"C:\\Users\\fhace\\Desktop\\FIRMs\\data\\AAA_ReferenceDatasets\\\\\"\n",
    "    base_output_path = r\"C:\\Users\\fhace\\Desktop\\FIRMs\\data\\Outputs\\\\\"\n",
    "    dnn_params['TLNN']['model_weights']    = r\"C:\\Users\\fhace\\Desktop\\FIRMs\\data\\BBNN\\curr_weights.pt\"\n",
    "    dnn_params['CLNN']['model_checkpoint'] = r\"C:\\Users\\fhace\\Desktop\\FIRMs\\data\\BBNN\\curr_weights.pt\"\n",
    "else:\n",
    "    base_input_path   = r\"D:\\Desktop\\FIRMsDigitizing\\data\\HistoricalFIRMS\"\n",
    "    base_output_path  = r\"D:\\Desktop\\FIRMsDigitizing\\processing\"\n",
    "    ref_dir  = r\"C:\\Users\\franc\\OneDrive - University Of Houston\\AAA_RECTDNN\\data\\AAA_ReferenceDatasets\\\\\"\n",
    "\n",
    "init_databases(ref_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5ca1967",
   "metadata": {},
   "source": [
    "Create working dir and unzip all files if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eca9abcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fhace\\Desktop\\FIRMs\\data\\Outputs\\\\2024-05-06_13-49-48\n"
     ]
    }
   ],
   "source": [
    "proc_dir = None\n",
    "\n",
    "if proc_dir is None:\n",
    "    datetime_str = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "    proc_dir     = os.path.join(base_output_path, datetime_str)\n",
    "    unzipped_dir = r\"C:\\Users\\fhace\\Desktop\\FIRMs\\data\\Indices\\\\\" # os.path.join(proc_dir, \"Inputs\")\n",
    "    outputs_dir  = os.path.join(proc_dir, \"Outputs\")\n",
    "    print(proc_dir)\n",
    "    os.makedirs(proc_dir)\n",
    "    # os.makedirs(unzipped_dir)\n",
    "    os.makedirs(outputs_dir)\n",
    "    # extractZipFiles(base_input_path, unzipped_dir)\n",
    "else:\n",
    "    unzipped_dir = os.path.join(proc_dir, \"Inputs\")\n",
    "    outputs_dir  = os.path.join(proc_dir, \"Outputs\")\n",
    "    rmtree(outputs_dir)\n",
    "    os.makedirs(outputs_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "469fbdb7",
   "metadata": {},
   "source": [
    "Read through all the images in the directory. Some images are saved as Multi-page TIFF files. These need to be exported into individual images. We'll do that first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ea68a26c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9868935addc4de39b495c16fbfd10d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for filename in tqdm(glob.glob(unzipped_dir + \"\\\\*.tif*\")):\n",
    "    tiff_file = os.path.join(unzipped_dir, filename)\n",
    "    try:\n",
    "    # Check if the file is a multi-page TIFF\n",
    "        with Image.open(tiff_file) as img:\n",
    "            if img.is_animated:    \n",
    "                for i in range(img.n_frames):\n",
    "                    try:\n",
    "                        img.seek(i)\n",
    "                        output_filename = f\"{os.path.splitext(tiff_file)[0]}_{i+1}{os.path.splitext(tiff_file)[1]}\"\n",
    "                        img.save(output_filename, format=img.format)\n",
    "                    except:\n",
    "                        print(f\"Error with {tiff_file} page {i}\")\n",
    "                        continue\n",
    "    except:\n",
    "        print(f\"Error opening {tiff_file}\")\n",
    "        continue\n",
    "\n",
    "    os.remove(tiff_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acac9f90",
   "metadata": {},
   "source": [
    "Here we're using heuristics to identify indices within all the image files. These include:\n",
    "- Files that are shorter than 12 characters\n",
    "- Files that have the ```IND``` marker\n",
    "\n",
    "We create a Pandas DataFrame with the files matching. We then add several fields as below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d5180ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LIST ALL IMAGES IN DIRECTORY\n",
    "image_files = glob.glob(f\"{unzipped_dir}/*\")\n",
    "\n",
    "# FILTER IMAGES USING HEURISTICS\n",
    "patterns = [\"IND\", \"_1.\"]\n",
    "index_files = [file for pattern in patterns for file in glob.glob(unzipped_dir + \"\\\\*\" + pattern + \"*\")]\n",
    "filtered_files = [file for file in image_files if len(os.path.basename(file)) < 12]\n",
    "index_files.extend(filtered_files)\n",
    "\n",
    "# CREATE DATAFRAME\n",
    "index_files = pd.DataFrame(index_files, columns=[\"FilePath\"])\n",
    "\n",
    "# INDEX ATTRIBUTES TO BE ADDED\n",
    "index_files[\"Basename\"] = [os.path.basename(file) for file in index_files[\"FilePath\"].to_list()]    # BASENAME\n",
    "index_files[\"Location\"] = index_files[\"Basename\"].apply(extract_numerical_chars).astype(np.int32)   # \n",
    "index_files[\"GEOID\"]    = index_files[\"Location\"].apply(getGEOID)       # GET GEOID FOR EACH INDEX\n",
    "index_files[\"geometry\"] = index_files[\"GEOID\"].apply(getGeometry)       # GET GEOMETRY FROM MATCHING GEOIDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "544b54fd",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fhace\\Desktop\\FIRMs\\data\\Indices\\480233IND0_0382.png\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:\\\\Users\\\\franc\\\\OneDrive - University Of Houston\\\\AAA_RECTDNN\\\\data/TPNN/checkpoint_091523_pyramids_2.pth'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\fhace\\Desktop\\FIRMs\\RECTDNN\\IndexGeorectification.ipynb Cell 10\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/fhace/Desktop/FIRMs/RECTDNN/IndexGeorectification.ipynb#X12sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m copyfile(row[\u001b[39m\"\u001b[39m\u001b[39mFilePath\u001b[39m\u001b[39m\"\u001b[39m], output_image_fn)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/fhace/Desktop/FIRMs/RECTDNN/IndexGeorectification.ipynb#X12sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m \u001b[39m# RUN IMAGES THROUGH DNNs\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/fhace/Desktop/FIRMs/RECTDNN/IndexGeorectification.ipynb#X12sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m classifications, TPNN  \u001b[39m=\u001b[39m findKeypoints(image, model\u001b[39m=\u001b[39;49mTPNN)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/fhace/Desktop/FIRMs/RECTDNN/IndexGeorectification.ipynb#X12sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m effectiveArea, RLNN    \u001b[39m=\u001b[39m findSquares(image, model\u001b[39m=\u001b[39mRLNN)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/fhace/Desktop/FIRMs/RECTDNN/IndexGeorectification.ipynb#X12sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m countyArea, CLNN       \u001b[39m=\u001b[39m findCounty(image, model\u001b[39m=\u001b[39mCLNN)\n",
      "File \u001b[1;32mc:\\Users\\fhace\\Desktop\\FIRMs\\RECTDNN\\IndexUtils.py:419\u001b[0m, in \u001b[0;36mfindKeypoints\u001b[1;34m(image, model, num_classes, num_pyramids, cnn_run_params, cnn_creation_params, device, model_checkpoint)\u001b[0m\n\u001b[0;32m    417\u001b[0m \u001b[39mif\u001b[39;00m model \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    418\u001b[0m     model \u001b[39m=\u001b[39m TPNN(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcnn_creation_params)\n\u001b[1;32m--> 419\u001b[0m     model\u001b[39m.\u001b[39mload_state_dict(torch\u001b[39m.\u001b[39;49mload(model_checkpoint)[\u001b[39m'\u001b[39m\u001b[39mmodel_state_dict\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m    420\u001b[0m model \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m    422\u001b[0m \u001b[39m# PROCESS IMAGE\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\fhace\\miniforge-pypy3\\envs\\rectdnn\\lib\\site-packages\\torch\\serialization.py:997\u001b[0m, in \u001b[0;36mload\u001b[1;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[0;32m    994\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mencoding\u001b[39m\u001b[39m'\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m pickle_load_args\u001b[39m.\u001b[39mkeys():\n\u001b[0;32m    995\u001b[0m     pickle_load_args[\u001b[39m'\u001b[39m\u001b[39mencoding\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m--> 997\u001b[0m \u001b[39mwith\u001b[39;00m _open_file_like(f, \u001b[39m'\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m'\u001b[39;49m) \u001b[39mas\u001b[39;00m opened_file:\n\u001b[0;32m    998\u001b[0m     \u001b[39mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[0;32m    999\u001b[0m         \u001b[39m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[0;32m   1000\u001b[0m         \u001b[39m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[0;32m   1001\u001b[0m         \u001b[39m# reset back to the original position.\u001b[39;00m\n\u001b[0;32m   1002\u001b[0m         orig_position \u001b[39m=\u001b[39m opened_file\u001b[39m.\u001b[39mtell()\n",
      "File \u001b[1;32mc:\\Users\\fhace\\miniforge-pypy3\\envs\\rectdnn\\lib\\site-packages\\torch\\serialization.py:444\u001b[0m, in \u001b[0;36m_open_file_like\u001b[1;34m(name_or_buffer, mode)\u001b[0m\n\u001b[0;32m    442\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[0;32m    443\u001b[0m     \u001b[39mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[1;32m--> 444\u001b[0m         \u001b[39mreturn\u001b[39;00m _open_file(name_or_buffer, mode)\n\u001b[0;32m    445\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    446\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mw\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m mode:\n",
      "File \u001b[1;32mc:\\Users\\fhace\\miniforge-pypy3\\envs\\rectdnn\\lib\\site-packages\\torch\\serialization.py:425\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[1;34m(self, name, mode)\u001b[0m\n\u001b[0;32m    424\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, name, mode):\n\u001b[1;32m--> 425\u001b[0m     \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(\u001b[39mopen\u001b[39;49m(name, mode))\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:\\\\Users\\\\franc\\\\OneDrive - University Of Houston\\\\AAA_RECTDNN\\\\data/TPNN/checkpoint_091523_pyramids_2.pth'"
     ]
    }
   ],
   "source": [
    "verbose = True\n",
    "\n",
    "TPNN = None\n",
    "RLNN = None\n",
    "CLNN = None\n",
    "TLNN = None\n",
    "\n",
    "for i, row in index_files.iterrows():\n",
    "    print(row[\"FilePath\"])\n",
    "    \n",
    "    filename = os.path.basename(row[\"FilePath\"])\n",
    "    \n",
    "    # READ FILES AND CONVERT TO GRAYSCALE\n",
    "    image = cv2.imread(row[\"FilePath\"])\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    image_arry = np.asarray(image)\n",
    "    \n",
    "    # SAVE IMAGE TO OUTPUT DIRECTORY\n",
    "    output_image_fn = os.path.join(outputs_dir, filename)\n",
    "    copyfile(row[\"FilePath\"], output_image_fn)\n",
    "    \n",
    "    # RUN IMAGES THROUGH DNNs\n",
    "    # classifications, TPNN  = findKeypoints(image, model=TPNN, **dnn_params['TPNN'])\n",
    "    # effectiveArea, RLNN    = findSquares(image, model=RLNN, **dnn_params['RLNN'])\n",
    "    countyArea, CLNN       = findCounty(image, model=CLNN, **dnn_params['CLNN'])\n",
    "    tiles, TLNN            = findTiles(row[\"FilePath\"], model=TLNN, **dnn_params['TLNN'])\n",
    "\n",
    "    dnn_outputs = {\n",
    "        # \"classifications\"   : classifications,\n",
    "        # \"effectiveArea\"     : effectiveArea,\n",
    "        \"countyArea\"    : countyArea,\n",
    "        \"tiles\"         : tiles\n",
    "    }\n",
    "\n",
    "    # GET BOUNDARY POINTS FROM RESPECTIVE SHAPEFILE\n",
    "    point_boundary_gdf, shp_bounds = getBoundaryPoints(row, distance=100)\n",
    "    \n",
    "    # GET COUNTY BOUNDS IDENTIFIED IN INDEX BY TLNN\n",
    "    bounds_panels = tiles[\"county\"][\"bbox\"]\n",
    "\n",
    "    # SKIP IF WE CAN'T FIND BOUNDARY IN EXISTING DATABASES\n",
    "    if point_boundary_gdf is None:\n",
    "        continue\n",
    "\n",
    "    # DEFINE BOUNDARY STRUCTU\n",
    "    boundaries = {\n",
    "        \"point_boundary_gdf\"    : point_boundary_gdf,\n",
    "        \"shp_bounds\"            : shp_bounds,\n",
    "        \"bounds_panels\"         : bounds_panels,\n",
    "    }\n",
    "\n",
    "    # WHAT ARE WE LOOKING FOR IN EACH IDENTIFIED SQUARE?\n",
    "    key = findKey(row[\"Basename\"])    \n",
    "    if key is None:\n",
    "        print(f\"Could not find key in {filename}\")\n",
    "    \n",
    "    # DO ICP\n",
    "    transform_dict = performICPonIndex(boundaries, dnn_outputs, debug=False, plot=True, icp_iterations=30)\n",
    "\n",
    "    # GET TRANSFORM FROM ICP TO CRS TRANSFORM\n",
    "    output_transform, _ = ICPtoCRSTransform(image_arry, transform_dict)\n",
    "\n",
    "    # GET OUTPUT TRANSFORM INTO AFFINE AND WRITE\n",
    "    output_affine = Affine(*output_transform.flatten()[:6])\n",
    "    write_world_file_from_affine(output_affine, get_world_file_path(output_image_fn))\n",
    "\n",
    "    src = rio.open(output_image_fn)\n",
    "    for i, (k, v) in enumerate(tiles.items()):\n",
    "        tiles[k]['coords'] = getBBOX_coords(src, tiles[k]['bbox'])\n",
    "    error"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
