{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTEBOOK IMPORTS\n",
    "import os, glob, warnings, pickle, re\n",
    "import numpy as np\n",
    "from shutil import copyfile, rmtree\n",
    "from datetime import datetime\n",
    "from fuzzywuzzy import process\n",
    "\n",
    "# IMAGE IMPORTS\n",
    "# from PIL import Image\n",
    "\n",
    "# GIS IMPORTS\n",
    "from affinetransformation import *\n",
    "from affine import Affine\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Polygon, LineString, Point, MultiPoint, box\n",
    "import rasterio as rio\n",
    "import contextily as cx\n",
    "\n",
    "# IMAGE IMPORTS\n",
    "from skimage.morphology import skeletonize\n",
    "from skimage import img_as_bool, img_as_ubyte\n",
    "\n",
    "\n",
    "# PLOTTING IMPORTS\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# CUSTOM UTILITIES\n",
    "from IndexUtils import * \n",
    "from TileUtils import *\n",
    "\n",
    "Image.MAX_IMAGE_PIXELS = 933120000\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "initialize = False\n",
    "\n",
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = r\"D:\\RECTDNN\\uncompress\\\\\"\n",
    "proc_dir  = r\"D:\\RECTDNN\\processing\\2024-05-31_14-05-48\\Tiles\\\\\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stateplanes = gpd.read_file(f\"{data_dir}/AAA_ReferenceDatasets/stateplane.shp\")\n",
    "init_databases(f\"{data_dir}/AAA_ReferenceDatasets/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LIST ALL IMAGES IN DIRECTORY\n",
    "image_files = glob.glob(f\"{input_dir}/*480287*\")\n",
    "image_files = [f for f in image_files if 'w' not in os.path.splitext(f)[1]]\n",
    "\n",
    "# FILTER IMAGES USING HEURISTICS TO GET TILEINDICES\n",
    "patterns = [\"IND\", \"_1.\"]\n",
    "index_files = [file for pattern in patterns for file in glob.glob(input_dir + \"\\\\*\" + pattern + \"*.*[!w]*\")]\n",
    "filtered_files = [file for file in image_files if len(os.path.basename(file)) < 12]\n",
    "index_files.extend(filtered_files)\n",
    "\n",
    "# GET ACTUAL TILES\n",
    "tiles       = list(set(image_files) - set(index_files))\n",
    "tiles_bns   = [os.path.basename(tile).split(\".\")[0] for tile in tiles]\n",
    "\n",
    "with open(f\"{data_dir}/AAA_ReferenceDatasets/IndexCoords.pkl\", 'rb') as handle:\n",
    "    dict = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create the tile database with the detected tiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2190 1493\n"
     ]
    }
   ],
   "source": [
    "duplicate_db, non_dupped_dict, dupped_dict = buildDetectedDatabase(dict)\n",
    "\n",
    "print(len(non_dupped_dict), len(dupped_dict))  \n",
    "\n",
    "detected_tiles = pd.DataFrame.from_dict(non_dupped_dict).T\n",
    "detected_tiles['geometry'] = detected_tiles['coords'].apply(bbox_to_polygon)\n",
    "detected_tiles_gdf = gpd.GeoDataFrame(detected_tiles)\n",
    "detected_tiles_gdf = detected_tiles_gdf[['geometry']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we supplement that database with all existing world files..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn = os.path.join(proc_dir, \"WorldFileDatabase.feather\")\n",
    "if os.path.exists(fn):\n",
    "    df = pd.read_pickle(fn)\n",
    "else:\n",
    "    df = buildWorldFileDatabase(input_dir, duplicate_db, stateplanes)\n",
    "    df.to_pickle(fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can save both databases as shapefiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the function to the 'bbox' column\n",
    "df['geometry'] = df['webmerc'].apply(bbox_to_polygon)\n",
    "gdf = gpd.GeoDataFrame(df)\n",
    "gdf.dropna(axis=0)\n",
    "\n",
    "for key in gdf.keys():\n",
    "    if key == 'geometry':\n",
    "        continue\n",
    "    gdf[key] = gdf[key].astype(str)\n",
    "\n",
    "gdf.to_file(r\"D:\\RECTDNN\\WorldFiles.shp\")\n",
    "detected_tiles_gdf.to_file(r\"D:\\RECTDNN\\Detected.shp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is where we identify Street Corners in each raster using YOLO models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOUND DICTIONARY, LOADING\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "024045f773914271a7d585e63770442d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/220 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "FANN_prior = None\n",
    "RLNN_prior = None\n",
    "model = None\n",
    "\n",
    "color=False\n",
    "\n",
    "plot_params = {\"labels\" : False, }\n",
    "YOLO_params = {\n",
    "    \"device\"  : \"cuda\",     \"find_text\" : False, \n",
    "    \"keyed_text\"  : False,  \"verbose\" : False,  \"get_data\"  : False,\n",
    "    \"target_size\" : 1920,   \"plot_params\" : plot_params, \"ret_values\" : True\n",
    "}\n",
    "\n",
    "# IF WE'VE ALREADY STARTED PROCESSING THINGS, LOAD STATE DICT\n",
    "if os.path.exists(f'{proc_dir}results.pkl'):\n",
    "    print(\"FOUND DICTIONARY, LOADING\")\n",
    "    with open(f'{proc_dir}results.pkl', 'rb') as handle:\n",
    "        results_struct = pickle.load(handle)\n",
    "else:\n",
    "    results_struct = {}\n",
    "\n",
    "# LOOP FOR EACH TILE\n",
    "for i, tile in tqdm(enumerate(tiles), total=len(tiles)):\n",
    "    \n",
    "    # DEFINE WHERE GEOREFERENCED TILE IS SAVED\n",
    "    out_fn = os.path.join(proc_dir, os.path.basename(tile).split(\".\")[0] + \"_FANN.png\")\n",
    "    fin_fn = os.path.join(proc_dir, os.path.basename(tile).split(\".\")[0] + \"_results.pkl\")\n",
    "\n",
    "    # HAVE WE ALREADY PROCESSED THIS TILE? IF SO, SKIP\n",
    "    if results_struct.get(tile, None):\n",
    "        # print(f\"Found in dict, skipping {tile}\")\n",
    "        continue\n",
    "\n",
    "    # WHICH VERSION OF FANN ARE WE USING\n",
    "    if color:\n",
    "        # RUN AND SAVE PREPROCESSING FANN AND RLNN\n",
    "        prepped_fn = os.path.join(proc_dir, os.path.basename(tile).split(\".\")[0] + \"_prepped.png\")                      # FILE NAME\n",
    "        prepped, FANN_prior, RLNN_prior, bounds = findStreetCorners_colorPrep(tile, FANN=FANN_prior, RLNN=RLNN_prior)   # RUN FANN_PRIOR AND RLNN\n",
    "        Image.fromarray(prepped).save(prepped_fn) # SAVE\n",
    "\n",
    "        # RUN FANN\n",
    "        results, model, base = runYOLO_Text(prepped_fn, model=model, model_weights=f\"{data_dir}FANN/YOLO/051624.pt\", **YOLO_params)\n",
    "        \n",
    "    else:\n",
    "        bounds = None\n",
    "\n",
    "        # RUN FANN\n",
    "        results, model, base = runYOLO_Text(tile, model=model, model_weights=f\"{data_dir}FANN/YOLO/051624_bw.pt\", **YOLO_params)\n",
    "\n",
    "    results_struct[tile] = results\n",
    "\n",
    "    ''' IF YOU WANT TO SAVE DETAILED OUTPUT, THIS CODE WORKS, BUT IT'S HELLA SLOW AND BURDENSOME\n",
    "    temp_dict = {\"results\" : results, \"bounds\" : bounds, \"results_2\" : base}\n",
    "    results_struct[tile] = fin_fn\n",
    "    if os.path.exists(fin_fn):\n",
    "        os.remove(fin_fn)\n",
    "    with open(fin_fn, 'wb') as handle:\n",
    "        pickle.dump(temp_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    '''\n",
    "\n",
    "    \n",
    "    # SAVE EVERY N ITERATIONS AND LAST\n",
    "    if i % 60 == 0 or i == len(tiles) - 1:\n",
    "        file_path = f'{proc_dir}results.pkl'\n",
    "        if os.path.exists(file_path):\n",
    "            os.remove(file_path)\n",
    "        with open(file_path, 'wb') as handle:\n",
    "            pickle.dump(results_struct, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae011565d80d4b08839954e20cbd5abd",
       "version_major": 2,
       "version_minor": 0
      },
      "image/png": "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",
      "text/html": [
       "\n",
       "            <div style=\"display: inline-block;\">\n",
       "                <div class=\"jupyter-widgets widget-label\" style=\"text-align: center;\">\n",
       "                    Figure\n",
       "                </div>\n",
       "                <img src='data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAoAAAAHgCAYAAAA10dzkAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAAAhYUlEQVR4nO3dfZBV9X348c+VhxXosvJQ97Ljqmu7bR5AkoKhEhNIlM1Q0GSY1BhsYid2RgtSN5gaKE1Fp9kltCW0bjVj6iiJQ/GPinVqk7I2ZglDnfJYkWTUjAgY2e6kJbvLg7sIp3/kx/3lBjCi3L3s/b5eM2fGe865J5/7nXXu23PvbnJZlmUBAEAyLij3AAAADCwBCACQGAEIAJAYAQgAkBgBCACQGAEIAJAYAQgAkBgBCACQGAEIAJAYAQgAkBgBCACQGAEIAJAYAQgAkBgBCACQGAEIAJAYAQgAkBgBCACQGAEIAJAYAQgAkBgBCACQGAEIAJAYAQgAkBgBCACQGAEIAJAYAQgAkBgBCACQGAEIAJAYAQgAkBgBCACQGAEIAJAYAQgAkBgBCACQGAEIAJAYAQgAkBgBCACQGAEIAJAYAQgAkBgBCACQGAEIAJAYAQgAkBgBCACQGAEIAJAYAQgAkBgBCACQGAEIAJAYAQgAkBgBCACQGAEIAJAYAQgAkBgBCACQGAEIAJAYAQgAkBgBCACQGAEIAJAYAQgAkBgBCACQmKHlHmAwO3HiRLz++utRXV0duVyu3OMAAG9DlmXR29sbdXV1ccEFad4LE4Dvwuuvvx719fXlHgMAeAf2798fl1xySbnHKAsB+C5UV1dHxM9/gEaPHl3maQCAt6Onpyfq6+sL7+MpEoDvwsmPfUePHi0AAWCQSfnrW2l+8A0AkDABCACQGAEIAJAYAQgAkBgBCACQGAEIAJAYAQgAkBgBCACQGAEIAJAYAQgAkBgBCACQGAEIAJAYAQgAkBgBCACQmKHlHoAzu3zJ0+Ue4ay9umJOuUcAAH4FdwABABIjAAEAEiMAAQASIwABABIjAAEAEiMAAQASIwABABIjAAEAEiMAAQASIwABABIjAAEAEjMoA3Djxo1x/fXXR11dXeRyuXjyyScLx44dOxZf/vKXY9KkSTFq1Kioq6uLz3/+8/H6668XXaOvry8WLVoU48ePj1GjRsUNN9wQr7322gC/EgCAgTcoA/Dw4cMxefLkaGtrO+XYkSNHYvv27fGVr3wltm/fHk888US89NJLccMNNxSd19zcHOvXr49169bFpk2b4tChQzF37tw4fvz4QL0MAICyGFruAd6J2bNnx+zZs097rKamJtrb24v23X///fGhD30o9u3bF5deeml0d3fHww8/HN/+9rfjuuuui4iIxx57LOrr6+OZZ56JT3ziEyV/DQAA5TIo7wCere7u7sjlcnHRRRdFRMS2bdvi2LFj0dTUVDinrq4uJk6cGJs3by7TlAAAA2NQ3gE8G2+88UYsWbIk5s+fH6NHj46IiM7Ozhg+fHiMGTOm6Nza2tro7Ow847X6+vqir6+v8Linp6c0QwMAlFBF3wE8duxY3HTTTXHixIl44IEHfuX5WZZFLpc74/HW1taoqakpbPX19edyXACAAVGxAXjs2LG48cYbY8+ePdHe3l64+xcRkc/no7+/Pw4ePFj0nK6urqitrT3jNZcuXRrd3d2Fbf/+/SWbHwCgVCoyAE/G38svvxzPPPNMjBs3ruj4lClTYtiwYUW/LHLgwIF44YUXYvr06We8blVVVYwePbpoAwAYbAbldwAPHToUP/7xjwuP9+zZEzt37oyxY8dGXV1dfPrTn47t27fHv/zLv8Tx48cL3+sbO3ZsDB8+PGpqauLWW2+Nu+66K8aNGxdjx46NL33pSzFp0qTCbwUDAFSqQRmAW7dujY997GOFx4sXL46IiFtuuSWWL18eTz31VEREfOADHyh63rPPPhszZ86MiIivf/3rMXTo0Ljxxhvj6NGjce2118ajjz4aQ4YMGZDXAABQLrksy7JyDzFY9fT0RE1NTXR3d5fk4+DLlzx9zq9Zaq+umFPuEQDgLZX6/XswqMjvAAIAcGYCEAAgMQIQACAxAhAAIDECEAAgMQIQACAxAhAAIDECEAAgMQIQACAxAhAAIDECEAAgMQIQACAxAhAAIDECEAAgMQIQACAxAhAAIDECEAAgMQIQACAxAhAAIDECEAAgMQIQACAxAhAAIDECEAAgMQIQACAxAhAAIDECEAAgMQIQACAxAhAAIDECEAAgMQIQACAxAhAAIDECEAAgMQIQACAxAhAAIDECEAAgMQIQACAxAhAAIDECEAAgMQIQACAxAhAAIDECEAAgMQIQACAxAhAAIDECEAAgMQIQACAxgzIAN27cGNdff33U1dVFLpeLJ598suh4lmWxfPnyqKurixEjRsTMmTNj9+7dRef09fXFokWLYvz48TFq1Ki44YYb4rXXXhvAVwEAUB6DMgAPHz4ckydPjra2ttMeX7lyZaxatSra2tpiy5Ytkc/nY9asWdHb21s4p7m5OdavXx/r1q2LTZs2xaFDh2Lu3Llx/PjxgXoZAABlMbTcA7wTs2fPjtmzZ5/2WJZlsXr16li2bFnMmzcvIiLWrFkTtbW1sXbt2rjtttuiu7s7Hn744fj2t78d1113XUREPPbYY1FfXx/PPPNMfOITnxiw1wIAMNAG5R3At7Jnz57o7OyMpqamwr6qqqqYMWNGbN68OSIitm3bFseOHSs6p66uLiZOnFg4BwCgUg3KO4BvpbOzMyIiamtri/bX1tbG3r17C+cMHz48xowZc8o5J59/On19fdHX11d43NPTc67GBgAYMBV3B/CkXC5X9DjLslP2/bJfdU5ra2vU1NQUtvr6+nMyKwDAQKq4AMzn8xERp9zJ6+rqKtwVzOfz0d/fHwcPHjzjOaezdOnS6O7uLmz79+8/x9MDAJRexQVgQ0ND5PP5aG9vL+zr7++Pjo6OmD59ekRETJkyJYYNG1Z0zoEDB+KFF14onHM6VVVVMXr06KINAGCwGZTfATx06FD8+Mc/Ljzes2dP7Ny5M8aOHRuXXnppNDc3R0tLSzQ2NkZjY2O0tLTEyJEjY/78+RERUVNTE7feemvcddddMW7cuBg7dmx86UtfikmTJhV+KxgAoFINygDcunVrfOxjHys8Xrx4cURE3HLLLfHoo4/G3XffHUePHo0FCxbEwYMHY9q0abFhw4aorq4uPOfrX/96DB06NG688cY4evRoXHvttfHoo4/GkCFDBvz1AAAMpFyWZVm5hxisenp6oqamJrq7u0vycfDlS54+59cstVdXzCn3CADwlkr9/j0YVNx3AAEAeGsCEAAgMQIQACAxAhAAIDECEAAgMQIQACAxAhAAIDECEAAgMQIQACAxAhAAIDECEAAgMQIQACAxAhAAIDECEAAgMQIQACAxAhAAIDECEAAgMQIQACAxAhAAIDECEAAgMQIQACAxAhAAIDECEAAgMQIQACAxAhAAIDECEAAgMQIQACAxAhAAIDECEAAgMQIQACAxAhAAIDECEAAgMQIQACAxAhAAIDECEAAgMQIQACAxAhAAIDECEAAgMQIQACAxAhAAIDECEAAgMQIQACAxAhAAIDECEAAgMQIQACAxFRuAb775Zvz5n/95NDQ0xIgRI+KKK66I++67L06cOFE4J8uyWL58edTV1cWIESNi5syZsXv37jJODQBQehUbgF/72tfiG9/4RrS1tcWPfvSjWLlyZfzVX/1V3H///YVzVq5cGatWrYq2trbYsmVL5PP5mDVrVvT29pZxcgCA0qrYAPyP//iP+OQnPxlz5syJyy+/PD796U9HU1NTbN26NSJ+fvdv9erVsWzZspg3b15MnDgx1qxZE0eOHIm1a9eWeXoAgNKp2AC85ppr4t///d/jpZdeioiI//qv/4pNmzbF7/3e70VExJ49e6KzszOampoKz6mqqooZM2bE5s2byzIzAMBAGFruAUrly1/+cnR3d8d73vOeGDJkSBw/fjy++tWvxmc/+9mIiOjs7IyIiNra2qLn1dbWxt69e097zb6+vujr6ys87unpKdH0AAClU7F3AB9//PF47LHHYu3atbF9+/ZYs2ZN/PVf/3WsWbOm6LxcLlf0OMuyU/ad1NraGjU1NYWtvr6+ZPMDAJRKxQbgn/7pn8aSJUvipptuikmTJsXnPve5+OIXvxitra0REZHP5yPi/98JPKmrq+uUu4InLV26NLq7uwvb/v37S/siAABKoGID8MiRI3HBBcUvb8iQIYU/A9PQ0BD5fD7a29sLx/v7+6OjoyOmT59+2mtWVVXF6NGjizYAgMGmYr8DeP3118dXv/rVuPTSS+P9739/7NixI1atWhVf+MIXIuLnH/02NzdHS0tLNDY2RmNjY7S0tMTIkSNj/vz5ZZ4eAKB0KjYA77///vjKV74SCxYsiK6urqirq4vbbrst/uIv/qJwzt133x1Hjx6NBQsWxMGDB2PatGmxYcOGqK6uLuPkAACllcuyLCv3EINVT09P1NTURHd3d0k+Dr58ydPn/Jql9uqKOeUeAQDeUqnfvweDiv0OIAAApycAAQASIwABABIjAAEAEiMAAQASIwABABIjAAEAEiMAAQASIwABABIjAAEAEiMAAQASIwABABIjAAEAEiMAAQASIwABABIjAAEAEiMAAQASIwABABIjAAEAEiMAAQASIwABABIjAAEAEiMAAQASIwABABIjAAEAEiMAAQASIwABABIjAAEAEiMAAQASIwABABIjAAEAEiMAAQASIwABABIjAAEAEiMAAQASIwABABIjAAEAEiMAAQASIwABABIjAAEAEiMAAQASIwABABIjAAEAEiMAAQASIwABABJT0QH4k5/8JP7gD/4gxo0bFyNHjowPfOADsW3btsLxLMti+fLlUVdXFyNGjIiZM2fG7t27yzgxAEDpVWwAHjx4MD784Q/HsGHD4jvf+U788Ic/jL/5m7+Jiy66qHDOypUrY9WqVdHW1hZbtmyJfD4fs2bNit7e3vINDgBQYkPLPUCpfO1rX4v6+vp45JFHCvsuv/zywj9nWRarV6+OZcuWxbx58yIiYs2aNVFbWxtr166N2267baBHBgAYEBV7B/Cpp56KqVOnxu///u/HxRdfHB/84Afjm9/8ZuH4nj17orOzM5qamgr7qqqqYsaMGbF58+ZyjAwAMCAqNgBfeeWVePDBB6OxsTH+7d/+LW6//fb4kz/5k/jWt74VERGdnZ0REVFbW1v0vNra2sKxX9bX1xc9PT1FGwDAYFOxHwGfOHEipk6dGi0tLRER8cEPfjB2794dDz74YHz+858vnJfL5Yqel2XZKftOam1tjXvvvbd0QwMADICKvQM4YcKEeN/73le0773vfW/s27cvIiLy+XxExCl3+7q6uk65K3jS0qVLo7u7u7Dt37+/BJMDAJRWxQbghz/84XjxxReL9r300ktx2WWXRUREQ0ND5PP5aG9vLxzv7++Pjo6OmD59+mmvWVVVFaNHjy7aAAAGm4r9CPiLX/xiTJ8+PVpaWuLGG2+M//zP/4yHHnooHnrooYj4+Ue/zc3N0dLSEo2NjdHY2BgtLS0xcuTImD9/fpmnBwAonYoNwKuuuirWr18fS5cujfvuuy8aGhpi9erVcfPNNxfOufvuu+Po0aOxYMGCOHjwYEybNi02bNgQ1dXVZZwcAKC0clmWZeUeYrDq6emJmpqa6O7uLsnHwZcvefqcX7PUXl0xp9wjAMBbKvX792BQsd8BBADg9AQgAEBiBCAAQGIEIABAYgQgAEBiBCAAQGIEIABAYgQgAEBiBCAAQGIEIABAYgQgAEBiBCAAQGIEIABAYgQgAEBiBCAAQGIEIABAYgQgAEBiBCAAQGIEIABAYgQgAEBiBCAAQGIEIABAYgQgAEBiBCAAQGIEIABAYgQgAEBiBCAAQGIEIABAYgQgAEBiBCAAQGIEIABAYgQgAEBiBCAAQGIEIABAYgQgAEBiBCAAQGIEIABAYgQgAEBiBCAAQGIEIABAYgQgAEBiBCAAQGIEIABAYgQgAEBiBCAAQGKSCMDW1tbI5XLR3Nxc2JdlWSxfvjzq6upixIgRMXPmzNi9e3f5hgQAGCAVH4BbtmyJhx56KK688sqi/StXroxVq1ZFW1tbbNmyJfL5fMyaNSt6e3vLNCkAwMCo6AA8dOhQ3HzzzfHNb34zxowZU9ifZVmsXr06li1bFvPmzYuJEyfGmjVr4siRI7F27doyTgwAUHoVHYALFy6MOXPmxHXXXVe0f8+ePdHZ2RlNTU2FfVVVVTFjxozYvHnzGa/X19cXPT09RRsAwGAztNwDlMq6deti+/btsWXLllOOdXZ2RkREbW1t0f7a2trYu3fvGa/Z2toa995777kdFABggFXkHcD9+/fHnXfeGY899lhceOGFZzwvl8sVPc6y7JR9v2jp0qXR3d1d2Pbv33/OZgYAGCgVeQdw27Zt0dXVFVOmTCnsO378eGzcuDHa2trixRdfjIif3wmcMGFC4Zyurq5T7gr+oqqqqqiqqird4AAAA6Ai7wBee+21sWvXrti5c2dhmzp1atx8882xc+fOuOKKKyKfz0d7e3vhOf39/dHR0RHTp08v4+QAAKVXkXcAq6urY+LEiUX7Ro0aFePGjSvsb25ujpaWlmhsbIzGxsZoaWmJkSNHxvz588sxMgDAgKnIAHw77r777jh69GgsWLAgDh48GNOmTYsNGzZEdXV1uUcDACipXJZlWbmHGKx6enqipqYmuru7Y/To0ef8+pcvefqcX7PUXl0xp9wjAMBbKvX792BQkd8BBADgzAQgAEBiBCAAQGIEIABAYgQgAEBiBCAAQGIEIABAYgQgAEBiBCAAQGIEIABAYgQgAEBiBCAAQGIEIABAYgQgAEBiBCAAQGIEIABAYgQgAEBiBCAAQGIEIABAYgQgAEBiBCAAQGKGlnsAKsvlS54u9whn7dUVc8o9AgAMKHcAAQASIwABABIjAAEAEiMAAQASIwABABIjAAEAEiMAAQASIwABABIjAAEAEiMAAQASIwABABIjAAEAEiMAAQASIwABABIjAAEAEiMAAQASIwABABIjAAEAEiMAAQASIwABABIjAAEAEiMAAQASIwABABJTsQHY2toaV111VVRXV8fFF18cn/rUp+LFF18sOifLsli+fHnU1dXFiBEjYubMmbF79+4yTQwAMDAqNgA7Ojpi4cKF8dxzz0V7e3u8+eab0dTUFIcPHy6cs3Llyli1alW0tbXFli1bIp/Px6xZs6K3t7eMkwMAlNbQcg9QKt/97neLHj/yyCNx8cUXx7Zt2+KjH/1oZFkWq1evjmXLlsW8efMiImLNmjVRW1sba9eujdtuu60cYwMAlFzF3gH8Zd3d3RERMXbs2IiI2LNnT3R2dkZTU1PhnKqqqpgxY0Zs3rz5tNfo6+uLnp6eog0AYLBJIgCzLIvFixfHNddcExMnToyIiM7OzoiIqK2tLTq3tra2cOyXtba2Rk1NTWGrr68v7eAAACWQRADecccd8fzzz8c//uM/nnIsl8sVPc6y7JR9Jy1dujS6u7sL2/79+0syLwBAKVXsdwBPWrRoUTz11FOxcePGuOSSSwr78/l8RPz8TuCECRMK+7u6uk65K3hSVVVVVFVVlXZgAIASq9g7gFmWxR133BFPPPFEfO9734uGhoai4w0NDZHP56O9vb2wr7+/Pzo6OmL69OkDPS4AwICp2DuACxcujLVr18Y///M/R3V1deF7fTU1NTFixIjI5XLR3NwcLS0t0djYGI2NjdHS0hIjR46M+fPnl3l6AIDSqdgAfPDBByMiYubMmUX7H3nkkfjDP/zDiIi4++674+jRo7FgwYI4ePBgTJs2LTZs2BDV1dUDPC0AwMCp2ADMsuxXnpPL5WL58uWxfPny0g8EAHCeqNjvAAIAcHoCEAAgMRX7ETC8XZcvebrcIyTh1RVzyj0CAP+PO4AAAIkRgAAAiRGAAACJEYAAAIkRgAAAiRGAAACJEYAAAIkRgAAAiRGAAACJEYAAAIkRgAAAiRGAAACJEYAAAIkRgAAAiRGAAACJEYAAAIkRgAAAiRGAAACJEYAAAIkRgAAAiRGAAACJGVruAYA0XL7k6XKPcNZeXTGn3CMAlIQ7gAAAiRGAAACJEYAAAIkRgAAAiRGAAACJEYAAAIkRgAAAifF3AAEgAf4WJ7/IHUAAgMQIQACAxPgIGKCC+JgPeDvcAQQASIwABABIjI+AAeAsDcaP2uEXuQMIAJAYAQgAkBgfAQOcgY/5BoZ1hoHnDiAAQGIEIABAYgQgAEBikg/ABx54IBoaGuLCCy+MKVOmxA9+8INyjwQAUFJJB+Djjz8ezc3NsWzZstixY0d85CMfidmzZ8e+ffvKPRoAQMkkHYCrVq2KW2+9Nf7oj/4o3vve98bq1aujvr4+HnzwwXKPBgBQMsn+GZj+/v7Ytm1bLFmypGh/U1NTbN68+bTP6evri76+vsLj7u7uiIjo6ekpyYwn+o6U5LoAMBiU6v315HWzLCvJ9QeDZAPwpz/9aRw/fjxqa2uL9tfW1kZnZ+dpn9Pa2hr33nvvKfvr6+tLMiMApKxmdWmv39vbGzU1NaX9HzlPJRuAJ+VyuaLHWZadsu+kpUuXxuLFiwuPT5w4Ef/7v/8b48aNO+Nz3qmenp6or6+P/fv3x+jRo8/ptVNkPc8t63nuWdNzy3qee5W0plmWRW9vb9TV1ZV7lLJJNgDHjx8fQ4YMOeVuX1dX1yl3BU+qqqqKqqqqon0XXXRRqUaMiIjRo0cP+n/RzifW89yynueeNT23rOe5Vylrmuqdv5OS/SWQ4cOHx5QpU6K9vb1of3t7e0yfPr1MUwEAlF6ydwAjIhYvXhyf+9znYurUqXH11VfHQw89FPv27Yvbb7+93KMBAJRM0gH4mc98Jv7nf/4n7rvvvjhw4EBMnDgx/vVf/zUuu+yyco8WVVVVcc8995zykTPvjPU8t6znuWdNzy3ree5Z08qSy1L+HWgAgAQl+x1AAIBUCUAAgMQIQACAxAhAAIDECMDz0AMPPBANDQ1x4YUXxpQpU+IHP/hBuUc6L23cuDGuv/76qKuri1wuF08++WTR8SzLYvny5VFXVxcjRoyImTNnxu7du4vO6evri0WLFsX48eNj1KhRccMNN8Rrr702gK/i/NHa2hpXXXVVVFdXx8UXXxyf+tSn4sUXXyw6x5qenQcffDCuvPLKwh/Ovfrqq+M73/lO4bj1fHdaW1sjl8tFc3NzYZ81ffuWL18euVyuaMvn84Xj1rKyCcDzzOOPPx7Nzc2xbNmy2LFjR3zkIx+J2bNnx759+8o92nnn8OHDMXny5Ghrazvt8ZUrV8aqVauira0ttmzZEvl8PmbNmhW9vb2Fc5qbm2P9+vWxbt262LRpUxw6dCjmzp0bx48fH6iXcd7o6OiIhQsXxnPPPRft7e3x5ptvRlNTUxw+fLhwjjU9O5dcckmsWLEitm7dGlu3bo2Pf/zj8clPfrLwJmo937ktW7bEQw89FFdeeWXRfmt6dt7//vfHgQMHCtuuXbsKx6xlhcs4r3zoQx/Kbr/99qJ973nPe7IlS5aUaaLBISKy9evXFx6fOHEiy+fz2YoVKwr73njjjaympib7xje+kWVZlv3sZz/Lhg0blq1bt65wzk9+8pPsggsuyL773e8O2Oznq66uriwiso6OjizLrOm5MmbMmOwf/uEfrOe70NvbmzU2Nmbt7e3ZjBkzsjvvvDPLMj+jZ+uee+7JJk+efNpj1rLyuQN4Hunv749t27ZFU1NT0f6mpqbYvHlzmaYanPbs2ROdnZ1Fa1lVVRUzZsworOW2bdvi2LFjRefU1dXFxIkTrXdEdHd3R0TE2LFjI8KavlvHjx+PdevWxeHDh+Pqq6+2nu/CwoULY86cOXHdddcV7bemZ+/ll1+Ourq6aGhoiJtuuileeeWViLCWKUj6/wnkfPPTn/40jh8/HrW1tUX7a2tro7Ozs0xTDU4n1+t0a7l3797COcOHD48xY8acck7q651lWSxevDiuueaamDhxYkRY03dq165dcfXVV8cbb7wRv/Zrvxbr16+P973vfYU3SOt5dtatWxfbt2+PLVu2nHLMz+jZmTZtWnzrW9+K3/qt34r//u//jr/8y7+M6dOnx+7du61lAgTgeSiXyxU9zrLslH28Pe9kLa13xB133BHPP/98bNq06ZRj1vTs/PZv/3bs3Lkzfvazn8U//dM/xS233BIdHR2F49bz7du/f3/ceeedsWHDhrjwwgvPeJ41fXtmz55d+OdJkybF1VdfHb/xG78Ra9asid/93d+NCGtZyXwEfB4ZP358DBky5JT/curq6jrlv8J4ayd/k+2t1jKfz0d/f38cPHjwjOekaNGiRfHUU0/Fs88+G5dccklhvzV9Z4YPHx6/+Zu/GVOnTo3W1taYPHly/O3f/q31fAe2bdsWXV1dMWXKlBg6dGgMHTo0Ojo64u/+7u9i6NChhTWxpu/MqFGjYtKkSfHyyy/7+UyAADyPDB8+PKZMmRLt7e1F+9vb22P69OllmmpwamhoiHw+X7SW/f390dHRUVjLKVOmxLBhw4rOOXDgQLzwwgtJrneWZXHHHXfEE088Ed/73veioaGh6Lg1PTeyLIu+vj7r+Q5ce+21sWvXrti5c2dhmzp1atx8882xc+fOuOKKK6zpu9DX1xc/+tGPYsKECX4+U1CO3zzhzNatW5cNGzYse/jhh7Mf/vCHWXNzczZq1Kjs1VdfLfdo553e3t5sx44d2Y4dO7KIyFatWpXt2LEj27t3b5ZlWbZixYqspqYme+KJJ7Jdu3Zln/3sZ7MJEyZkPT09hWvcfvvt2SWXXJI988wz2fbt27OPf/zj2eTJk7M333yzXC+rbP74j/84q6mpyb7//e9nBw4cKGxHjhwpnGNNz87SpUuzjRs3Znv27Mmef/757M/+7M+yCy64INuwYUOWZdbzXPjF3wLOMmt6Nu66667s+9//fvbKK69kzz33XDZ37tysurq68H5jLSubADwP/f3f/3122WWXZcOHD89+53d+p/BnOCj27LPPZhFxynbLLbdkWfbzP2Nwzz33ZPl8Pquqqso++tGPZrt27Sq6xtGjR7M77rgjGzt2bDZixIhs7ty52b59+8rwasrvdGsZEdkjjzxSOMeanp0vfOELhX+Xf/3Xfz279tprC/GXZdbzXPjlALSmb99nPvOZbMKECdmwYcOyurq6bN68ednu3bsLx61lZctlWZaV594jAADl4DuAAACJEYAAAIkRgAAAiRGAAACJEYAAAIkRgAAAiRGAAACJEYAAAIkRgAAAiRGAAACJEYAAAIkRgAAAiRGAAACJEYAAAIkRgAAAiRGAAACJEYAAAIkRgAAAiRGAAACJEYAAAIkRgAAAiRGAAACJEYAAAIkRgAAAiRGAAACJEYAAAIkRgAAAiRGAAACJEYAAAIkRgAAAiRGAAACJ+T/O5GFUrWW3BQAAAABJRU5ErkJggg==' width=640.0/>\n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "amount_of_corners = np.array([len(results_struct[list(results_struct.keys())[i]]) for i in range(len(results_struct))])\n",
    "_ = plt.hist(amount_of_corners)\n",
    "print(np.count_nonzero(amount_of_corners <= 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efab4b03896b40e4a0762a4c00112d7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/220 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def bboxTransformToCRS(transform, image):\n",
    "    rev_y_axis = np.array([[1, 0, 0],\n",
    "                        [0,-1, 0],\n",
    "                        [0, 0, 1]])\n",
    "    \n",
    "    translation = np.eye(3)\n",
    "    translation[1, 2] = image.shape[0]\n",
    "\n",
    "    return transform @ translation @ rev_y_axis\n",
    "\n",
    "\n",
    "def bbox_to_coords_realworld(bbox):\n",
    "    # BOUNDING BOX \n",
    "\n",
    "    x_min, y_min, x_max, y_max = bbox\n",
    "\n",
    "    xs = [x_min, x_min, x_max, x_max]\n",
    "    ys = [y_max, y_min, y_min, y_max]\n",
    "    return xs, ys\n",
    "\n",
    "def bbox_to_coords_raster(bbox):\n",
    "    # BOUNDING BOX \n",
    "\n",
    "    x_min, y_min, x_max, y_max = bbox\n",
    "\n",
    "    xs = [x_min, x_min, x_max, x_max]\n",
    "    ys = [y_min, y_max, y_max, y_min]\n",
    "    return xs, ys\n",
    "\n",
    "bad = 0\n",
    "RLNN = None\n",
    "\n",
    "detected_tiles['reference_name'] = detected_tiles.index\n",
    "list_tiles = list(detected_tiles_gdf.index)\n",
    "\n",
    "tile_coords = {}\n",
    "debug_struct = {}\n",
    "for i, tile in tqdm(enumerate(tiles), total=len(tiles)):\n",
    "\n",
    "    comp_length = len(tiles_bns[i]) - 2\n",
    "    curr_tiles = [a if comp_length <= len(a) else \"\" for a in list_tiles]\n",
    "\n",
    "    # KEEP NUMERIC PART OF TILE NAME\n",
    "    p = re.sub(r\"[^0-9]\", \"\", os.path.basename(tile))\n",
    "    \n",
    "    # PERFORM MATCHING\n",
    "    match, score = process.extractOne(tiles_bns[i], list_tiles)\n",
    "    matches = process.extract(tiles_bns[i], curr_tiles)\n",
    "    out_fn = os.path.join(proc_dir, tiles_bns[i] + \".tif\")\n",
    "    \n",
    "    if score > 90:\n",
    "        image = np.asarray(Image.open(tile))\n",
    "\n",
    "        if np.max(image) < 255:\n",
    "            image = image * 255\n",
    "            image = image.astype(np.uint8)\n",
    "\n",
    "        tile_coords[out_fn] = detected_tiles.loc[match]\n",
    "        tile_coords[out_fn]['input_file'] = tile\n",
    "\n",
    "        bounds, RLNN = findBounds(tile, RLNN)\n",
    "        \n",
    "        if len(bounds[0]) < 1:\n",
    "            print(f\"COULD NOT FIND BOUNDS, USING IMAGE EXTENTS {tile}\")\n",
    "            \n",
    "            bbox = [0, 0, image.shape[0], image.shape[1]]\n",
    "        else:\n",
    "            bbox = bounds[0].boxes.xyxy.numpy().astype(np.int32)[0].flatten()\n",
    "        \n",
    "        real_x, real_y = bbox_to_coords_realworld(tile_coords[out_fn][\"coords\"])\n",
    "        pic_x, pic_y   = bbox_to_coords_raster(bbox)\n",
    "\n",
    "        # transform = similarityTransformation(pic_x, pic_y, real_x, real_y)\n",
    "        affine = affineTransformation(pic_x, pic_y, real_x, real_y)\n",
    "        transform = bboxTransformToCRS(affine.matrix, image)\n",
    "\n",
    "        # print(*transform.flatten()[:6])\n",
    "\n",
    "        debug_struct[out_fn] = {\n",
    "            \"match\"  : match,  \"basename\" : tiles_bns[i],\n",
    "            \"matches\": matches, \"bbox\" : bbox,\n",
    "            \"real_x\" : real_x, \"real_y\" : real_y,\n",
    "            \"pic_x\"  : pic_x,  \"pic_y\"  : pic_y,\n",
    "            \"affine\" : affine, \"transform\" : transform\n",
    "        }\n",
    "        try:\n",
    "            with rio.open(out_fn, 'w',\n",
    "                driver='GTiff', count=1, dtype=image.dtype,\n",
    "                height=image.shape[0], width=image.shape[1],\n",
    "                crs=f'EPSG:3857',\n",
    "                transform=rio.Affine(*transform.flatten()[:6])) as dst:\n",
    "                    dst.write(image, 1) \n",
    "        except: \n",
    "            print(f\"Could not save {tiles_bns[i]}\")\n",
    "                \n",
    "    else:\n",
    "        tile_coords[out_fn] = None\n",
    "        bad = bad + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'gpd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 6\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# intersections = gpd.read_file(f\"{data_dir}/AAA_ReferenceDatasets/Intersections.gpkg\", engine='pyogrio', use_arrow=True)\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# C:\\Users\\fhacesga\\OneDrive - University Of Houston\\AAA_RECTDNN\\data\\AAA_ReferenceDatasets\\OSM_Roads\\TexasRoads_LineIntersections.gpkg\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# roads_gdf = gpd.read_file(r\"C:\\Users\\fhacesga\\Downloads\\TxDOT_Street_Definition_-1346186713652838562\\TxDOT_Street_Definition.shp\", engine='pyogrio', use_arrow=True)\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# intersections = gpd.read_file(f\"{data_dir}/AAA_ReferenceDatasets/OSM_Roads/TexasRoads_LineIntersections.gpkg\", engine='pyogrio', use_arrow=True)\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m intersections \u001b[38;5;241m=\u001b[39m \u001b[43mgpd\u001b[49m\u001b[38;5;241m.\u001b[39mread_file(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdata_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/AAA_ReferenceDatasets/OSM_Roads/TexasRoads_LineIntersections_strict.gpkg\u001b[39m\u001b[38;5;124m\"\u001b[39m, engine\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpyogrio\u001b[39m\u001b[38;5;124m'\u001b[39m, use_arrow\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      7\u001b[0m roads_gdf \u001b[38;5;241m=\u001b[39m gpd\u001b[38;5;241m.\u001b[39mread_file(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mfhacesga\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mDownloads\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mTexasRoads_filtered_3857.gpkg\u001b[39m\u001b[38;5;124m\"\u001b[39m, engine\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpyogrio\u001b[39m\u001b[38;5;124m'\u001b[39m, use_arrow\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'gpd' is not defined"
     ]
    }
   ],
   "source": [
    "# intersections = gpd.read_file(f\"{data_dir}/AAA_ReferenceDatasets/Intersections.gpkg\", engine='pyogrio', use_arrow=True)\n",
    "# C:\\Users\\fhacesga\\OneDrive - University Of Houston\\AAA_RECTDNN\\data\\AAA_ReferenceDatasets\\OSM_Roads\\TexasRoads_LineIntersections.gpkg\n",
    "\n",
    "# roads_gdf = gpd.read_file(r\"C:\\Users\\fhacesga\\Downloads\\TxDOT_Street_Definition_-1346186713652838562\\TxDOT_Street_Definition.shp\", engine='pyogrio', use_arrow=True)\n",
    "# intersections = gpd.read_file(f\"{data_dir}/AAA_ReferenceDatasets/OSM_Roads/TexasRoads_LineIntersections.gpkg\", engine='pyogrio', use_arrow=True)\n",
    "intersections = gpd.read_file(f\"{data_dir}/AAA_ReferenceDatasets/OSM_Roads/TexasRoads_LineIntersections_strict.gpkg\", engine='pyogrio', use_arrow=True)\n",
    "roads_gdf = gpd.read_file(r\"C:\\Users\\fhacesga\\Downloads\\TexasRoads_filtered_3857.gpkg\", engine='pyogrio', use_arrow=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getRoadPoints(gdf, distance):\n",
    "    \"\"\"\n",
    "    GENERATED WITH CHATGPT\n",
    "    Interpolate points along the LineString geometries at every `distance` interval.\n",
    "    \n",
    "    Parameters:\n",
    "    gdf (GeoDataFrame): A GeoDataFrame containing LineString geometries.\n",
    "    distance (float): The distance interval at which to interpolate points.\n",
    "    \n",
    "    Returns:\n",
    "    GeoDataFrame: A GeoDataFrame with the interpolated Point geometries.\n",
    "    \"\"\"\n",
    "    points = []\n",
    "\n",
    "    # Efficiently process LineStrings only\n",
    "    for line in gdf.geometry:\n",
    "        if line.geom_type == 'LineString':\n",
    "            num_points = int(line.length // distance) + 1\n",
    "            distances = [i * distance for i in range(num_points)]\n",
    "            points.extend([line.interpolate(d) for d in distances])\n",
    "\n",
    "    # Create a new GeoDataFrame with Point geometries\n",
    "    points_gdf = gpd.GeoDataFrame(geometry=points, crs=gdf.crs)\n",
    "    \n",
    "    return points_gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "roads_full = roads_gdf.copy()\n",
    "roads_min = roads_gdf[roads_gdf['highway'].isin(['abandoned', 'corridor', 'disused', 'living_street', 'motorway', 'motorway_link', 'primary', 'primary_link', \n",
    "                           'secondary', 'secondary_link', 'tertiary', 'tertiary_link', 'road', 'residential'])]\n",
    "roads_min.to_file(r\"C:\\Users\\fhacesga\\Downloads\\TexasRoads_filtered_strict_3857.gpkg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getClosestPoints(kdtrees, proc_points, sear_points, weights=None, proc_limit=1000, idx=None, dist_threshold=None):\n",
    "    assert len(kdtrees) == len(proc_points)\n",
    "    assert len(proc_points) == len(sear_points)\n",
    "\n",
    "    if idx is None:\n",
    "        idx = [[]] * len(kdtrees)\n",
    "\n",
    "    out_proc_points = []\n",
    "    out_to_points   = []\n",
    "    out_weights = []\n",
    "\n",
    "    if weights is None:\n",
    "        weights = [1] * len(sear_points)\n",
    "\n",
    "    for i, kdtree in enumerate(kdtrees):\n",
    "\n",
    "        if proc_points[i].shape[0] > proc_limit:\n",
    "            if len(idx[i]) == 0:\n",
    "                idx[i] = np.random.permutation(proc_points[i].shape[0])[:proc_limit] # np.random.default_rng().choice(proc_points[i].shape[0], size=proc_limit, replace=False)\n",
    "            proc_points_curr = proc_points[i][idx[i]]\n",
    "        else:\n",
    "            proc_points_curr = proc_points[i]\n",
    "\n",
    "        dist, nearest_indices = kdtree.query(proc_points_curr)\n",
    "\n",
    "        if dist_threshold is not None:\n",
    "            proc_points_curr = proc_points_curr[dist < dist_threshold]\n",
    "            nearest_indices  = nearest_indices[dist < dist_threshold]\n",
    "\n",
    "        to_points_temp = np.array([sear_points[i][idx] for idx in nearest_indices])\n",
    "        out_weights.append([weights[i]] * nearest_indices.shape[0]) \n",
    "        out_to_points.append(to_points_temp)\n",
    "        out_proc_points.append(proc_points_curr)\n",
    "\n",
    "\n",
    "    proc_points = np.vstack(out_proc_points)\n",
    "    to_points   = np.vstack(out_to_points)\n",
    "    weights     = np.hstack(out_weights)\n",
    "\n",
    "    return proc_points, to_points, weights, idx\n",
    "\n",
    "\n",
    "def adjustStep_affine_weighted(from_points, to_points, \n",
    "                      shear=True, rotation = True, perspective=True, rotation_limit=None, weights=None,):\n",
    "\n",
    "    if shear and rotation:\n",
    "        transform = affineTransformation(from_points[:, 0], from_points[:, 1], \n",
    "                                             to_points[:, 0], to_points[:, 1],\n",
    "                                             verbose=False, weights=None\n",
    "                                 )\n",
    "        \n",
    "    if not rotation: \n",
    "        transform = scalingTranslationTransformation(from_points[:, 0], from_points[:, 1], \n",
    "                                             to_points[:, 0], to_points[:, 1],\n",
    "                                             verbose=False, weights=None\n",
    "                                 )\n",
    "    else:\n",
    "        transform = similarityTransformation(from_points[:, 0], from_points[:, 1], \n",
    "                                             to_points[:, 0], to_points[:, 1],\n",
    "                                             verbose=False, rotation_limit=rotation_limit, weights=None)\n",
    "    \n",
    "    new_homography = transform.matrix\n",
    "    \n",
    "    if not shear:\n",
    "        scale  = np.sqrt((new_homography[0, 0] ** 2 + new_homography[1, 1] ** 2) / 2)\n",
    "        new_homography[0, 0] = scale \n",
    "        new_homography[1, 1] = scale\n",
    "    if not perspective:\n",
    "        new_homography[2, 0] = 0 \n",
    "        new_homography[2, 1] = 0 \n",
    "    if not rotation:\n",
    "        new_homography[0, 1] = 0 \n",
    "        new_homography[1, 0] = 0 \n",
    "    \n",
    "    return new_homography\n",
    "\n",
    "def performWeightedICPonTile(detections, references, \n",
    "                debug=False, \n",
    "                plot=True,\n",
    "                icp_iterations=30, \n",
    "                rotation=True, \n",
    "                shear=False, \n",
    "                perspective=False,\n",
    "                save_fig=None,\n",
    "                conv=0.01,\n",
    "                rotation_limit=None,\n",
    "                weights=None, \n",
    "                proc_limit = 10000,\n",
    "                plot_datasets=[],\n",
    "                dist_threshold=200\n",
    "                ):\n",
    "\n",
    "    if not isinstance(detections, list):\n",
    "        detections = [detections]\n",
    "\n",
    "    if not isinstance(references, list):\n",
    "        references = [references]\n",
    "\n",
    "    for detection in detections:\n",
    "        detection['x'] = detection['geometry'].x\n",
    "        detection['y'] = detection['geometry'].y\n",
    "\n",
    "    for reference in references:\n",
    "        reference['x'] = reference['geometry'].x\n",
    "        reference['y'] = reference['geometry'].y\n",
    "\n",
    "    # FAST SEARCH STRUCTURE\n",
    "    sear_points = [np.array(reference[['x', 'y']]) for reference in references]\n",
    "    proc_points = [np.array(detection[['x', 'y']])  for detection in detections]\n",
    "\n",
    "    kds = [cKDTree(search) for search in sear_points]    \n",
    "    \n",
    "    # ITERATIVE CLOSEST POINT STRUCTURES\n",
    "    reprojected_points    = []\n",
    "    compounded_homography = np.eye(3)\n",
    "    plotting_points = []\n",
    "    weight_vecs = []\n",
    "    \n",
    "    # OUTPUT STRUCTURES\n",
    "    transforms, grades = [], []\n",
    "    idx = None    \n",
    "\n",
    "    # ITERATE\n",
    "    for i in tqdm(range(icp_iterations), disable=False):\n",
    "        \n",
    "        curr_proc_points, to_points, weight_vec, idx = getClosestPoints(kds, proc_points, sear_points, weights=weights, proc_limit=proc_limit, idx=idx, dist_threshold=200)\n",
    "        \n",
    "\n",
    "        # TAKE ADJUSTMENT STEP\n",
    "        new_homography = adjustStep_affine_weighted(curr_proc_points, to_points,\n",
    "                                        shear=shear, \n",
    "                                        rotation=rotation, \n",
    "                                        perspective=perspective, \n",
    "                                        rotation_limit=rotation_limit, \n",
    "                                        weights=weight_vec)        \n",
    "        \n",
    "        transform = new_homography.copy()\n",
    "\n",
    "        def applyTransformWeighted(transform, points):\n",
    "            return [applyTransform(transform, p) for p in points]\n",
    "\n",
    "        # APPLY TRANSFORM TO ALL POINTS\n",
    "        proc_points = applyTransformWeighted(transform, proc_points)\n",
    "\n",
    "        # COMPOUND TRANSFORMATION\n",
    "        compounded_homography = compounded_homography @ transform\n",
    "        \n",
    "        # APPLY TRANSFORM FROM ADJUSTMENT TO PROCESSING POINTS AND APPEND TO LIST\n",
    "        curr_proc_points_rep = applyTransform(transform, curr_proc_points)\n",
    "        reprojected_points.append(curr_proc_points_rep)\n",
    "\n",
    "        # PUT ON OUTPUT STRUCTURES\n",
    "        transforms.append(compounded_homography)\n",
    "        weight_vecs.append(weight_vec)\n",
    "        \n",
    "        \n",
    "        def gradeWeightedFitFullDatasets(kdtrees, proc_points, transform, weights=weights, dist_threshold=None):\n",
    "            grade = 0\n",
    "            for i, kdtree in enumerate(kdtrees):\n",
    "                curr_points = applyTransform(transform, proc_points[i])\n",
    "                dist, _ = kdtree.query(curr_points)\n",
    "                if dist_threshold is not None:\n",
    "                    dist = dist[dist < dist_threshold]\n",
    "                grade = grade + np.sqrt(np.sum((dist * weights[i]) ** 2) / dist.shape[0])\n",
    "            return grade\n",
    "        \n",
    "        curr_grade = gradeWeightedFitFullDatasets(kds, proc_points, compounded_homography, weights=weights, dist_threshold=dist_threshold)\n",
    "        grades.append(curr_grade)\n",
    "\n",
    "        if debug and i % 10 == 0:\n",
    "            scale  = np.sqrt((new_homography[0, 0] ** 2 + new_homography[1, 1] ** 2) / 2)\n",
    "            offset = np.sqrt((new_homography[1, 2] ** 2 + new_homography[0, 2] ** 2) / 2)\n",
    "            print(f\"Scale: {scale:.2f} Offset: {offset:.2f} Grades: {curr_grade}\")\n",
    "            print(compounded_homography)\n",
    "\n",
    "    # GET BEST TRANSFORMS\n",
    "    best_transform = transforms[np.argmin(grades)]\n",
    "    best_points    = reprojected_points[np.argmin(grades)]\n",
    "    \n",
    "    if debug:\n",
    "        plt.plot(range(len(grades)), grades)\n",
    "        plt.scatter(np.argmin(grades), grades[np.argmin(grades)])\n",
    "        plt.show()\n",
    "    \n",
    "    if plot:\n",
    "        # fig, ax = plotICP_streets(reprojected_points, initial=initial, plot_skip=5, best=best_points)\n",
    "        fig, ax = plotWeightedICP(reprojected_points, ref_gdfs=plot_datasets, plot_skip=5, best=best_points, weights=weight_vecs)\n",
    "        if save_fig:\n",
    "            fig.savefig(save_fig)\n",
    "        plt.show()\n",
    "    \n",
    "    transform_dict = {\n",
    "        \"reproj\"  : reprojected_points,\n",
    "        \"best\"    : best_transform,\n",
    "        \"list\"    : transforms,\n",
    "        \"grades\"  : grades\n",
    "    }\n",
    "\n",
    "    return best_transform, transform_dict\n",
    "\n",
    "def plotWeightedICP(reprojected_points, ref_gdfs=[], plot_skip=2, best=None, weights=None, s_base=0.5):\n",
    "    icp_iterations = len(reprojected_points)\n",
    "    fig, ax = plt.subplots()\n",
    "    colormap = plt.get_cmap('cool') \n",
    "    \n",
    "    if weights is None:\n",
    "        weights = np.ones(reprojected_points.shape[0])\n",
    "\n",
    "    for gdf in ref_gdfs:\n",
    "        gdf.plot(ax=ax, markersize=2, marker='x', linewidth=0.5)\n",
    "\n",
    "    for i in np.arange(plot_skip, icp_iterations, plot_skip):\n",
    "        ax.scatter(reprojected_points[i][:, 0], reprojected_points[i][:, 1], \n",
    "            color=colormap(i / icp_iterations), s=weights[i]*s_base, label=f\"Iteration {i}\")\n",
    "\n",
    "    if best is not None:\n",
    "        ax.scatter(best[:, 0], best[:, 1], color='red', s=1, marker='x', label=\"Best Fit\")\n",
    "        \n",
    "    ax.legend()\n",
    "    ax.grid()\n",
    "    ax.axis(\"equal\")\n",
    "    return fig, ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 43\u001b[0m\n\u001b[0;32m     40\u001b[0m bestgrades \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     41\u001b[0m numcorners \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m---> 43\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mmodel\u001b[49m:\n\u001b[0;32m     44\u001b[0m     model \u001b[38;5;241m=\u001b[39m TPNN(num_classes\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, finalpadding\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, inputsize\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m     45\u001b[0m     checkpoint \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mfhacesga\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mOneDrive - University Of Houston\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mAAA_RECTDNN\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mdata/FANN/checkpoint_101123.pth\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "def calcCenter(a):\n",
    "    # print(a,  (a[0] + a[2]) / 2, (a[1] + a[3]) / 2)\n",
    "    return (a[0] + a[2]) / 2, (a[1] + a[3]) / 2\n",
    "\n",
    "def pointsToGeodataFrame(ra, y, x):\n",
    "    xs, ys = rio.transform.xy(ra.transform, y, x)\n",
    "    xy = list(zip(xs, ys))\n",
    "    points = MultiPoint(xy)\n",
    "    detections = gpd.GeoDataFrame(index=[0], geometry=[points]).explode(ignore_index=False, index_parts=False)\n",
    "    return detections\n",
    "\n",
    "def draw_bounding_boxes(bboxes, shape):\n",
    "    # Create a zero numpy array with the specified shape\n",
    "    img = np.zeros(shape, dtype=np.uint8)\n",
    "    \n",
    "    # Iterate through each bounding box\n",
    "    for bbox in bboxes:\n",
    "        x1, y1, x2, y2 = np.int32(bbox)\n",
    "        # Fill the region specified by the bounding box with 255\n",
    "        img[y1:y2, x1:x2] = 255\n",
    "    \n",
    "    return img\n",
    "\n",
    "def cleanImageBBOX(image, bbox, rep_value = 0, add=100):\n",
    "    image[:bbox[1]+add, :] = rep_value\n",
    "    image[bbox[3]-add:, :] = rep_value\n",
    "    image[:, :bbox[0]+add] = rep_value\n",
    "    image[:, bbox[2]-add:] = rep_value\n",
    "    return image\n",
    "\n",
    "def cleanCenterBBOX(coords, bbox):\n",
    "    x1, y1, x2, y2 = bbox\n",
    "    \n",
    "    # Check which coordinates are within the bounding box limits\n",
    "    mask = (coords[:, 0] >= x1) & (coords[:, 0] <= x2) & (coords[:, 1] >= y1) & (coords[:, 1] <= y2)\n",
    "    \n",
    "    # Filter the coordinates using the mask\n",
    "    return coords[mask]\n",
    "\n",
    "bestgrades = []\n",
    "numcorners = []\n",
    "\n",
    "allgrades = []\n",
    "\n",
    "try:\n",
    "    model\n",
    "except NameError:\n",
    "    model = TPNN(num_classes=2, finalpadding=1, inputsize=2)\n",
    "    checkpoint = torch.load(r'C:\\Users\\fhacesga\\OneDrive - University Of Houston\\AAA_RECTDNN\\data/FANN/checkpoint_101123.pth')\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    model = model.to('cuda')\n",
    "\n",
    "for i, (out_name, db) in enumerate(tile_coords.items()):\n",
    "    if db is not None:\n",
    "        \n",
    "        # GET STREET CORNERS FROM TPNN OUTPUTS\n",
    "        street_corners = results_struct[tile_coords[out_name]['input_file']]\n",
    "\n",
    "        # SKIP IF TOO FEW CORNERS\n",
    "        if len(street_corners) < 3:\n",
    "            continue\n",
    "\n",
    "        # OPEN RASTER AND GET BOUNDING BOX\n",
    "        ra = rio.open(out_name)\n",
    "        bounds  = ra.bounds\n",
    "        image   = ra.read(1)\n",
    "\n",
    "        # VALID BBOX FOR OBSERVATIONS OF ROADS\n",
    "        bbox = debug_struct[out_name]['bbox']\n",
    "\n",
    "        # RUN ROADS DETECTION ON CNN AND PREP FOR ICP\n",
    "        roads, _    = split_and_run_cnn(image, model, tilesize=1024, num_dim=3, edges=10, dims_rep=[0], n_pyramids=2, device=\"cuda\", verbose=True)\n",
    "        roads_thin  = roads[:, :, 1] > 0.95\n",
    "        roads_thin  = cleanImageBBOX(roads_thin, bbox)\n",
    "        roads_thin  = skeletonize(roads_thin)    # USE SKELETONIZATION ALGORITHM TO THIN ROADS\n",
    "        y, x        = np.where(roads_thin[:, :])            # GET X, Y COORDINATES OF IDENTIFIED ROAD POINTS\n",
    "        street_det  = pointsToGeodataFrame(ra, y, x)        # CONVERT X, Y COORDINATES TO GDF AND REPROEJCT TO CURRENT ESTIMATE OF RASTER POSITION\n",
    "\n",
    "        # USING CURRENT ENLARGED RASTER EXTENTS, GET RELEVANT ROADS FROM OPENSTREETMAP FILE\n",
    "        bounds_poly = enlarged_bounds(ra, n=1)              # ENLARGED EXTENTS - NOTE, SET TO 1 (NO ENLARGEMENT) BECAUSE I'M NOT SURE HOW NEEDED THIS IS\n",
    "        roads_clipped = gpd.clip(roads_min, bounds_poly)    # CLIP\n",
    "        streets = getRoadPoints(roads_clipped, 0.5)         # ROAD POINTS ALONG STREETS, 0.5 IN M\n",
    "\n",
    "        # RUN YOLO DETECTION ON STREET INTERSECTIONS AND PREP FOR DATASET\n",
    "        corner_bbox = [street_corners[a]['bbox'] for a in street_corners]\n",
    "        corner_arry = np.array([calcCenter(a) for a in corner_bbox ]) \n",
    "        corner_arry = np.int32(corner_arry)                 # CONVERT TO INT32\n",
    "        corner_arry = cleanCenterBBOX(corner_arry, bbox)\n",
    "\n",
    "        # USE RASTER TRANSFORM TO GET REAL-WORLD ESTIMATES OF STREET CORNERS\n",
    "        corner_gdf = pointsToGeodataFrame(ra, corner_arry[:, 1], corner_arry[:, 0])\n",
    "        \n",
    "        # GET SHAPEFILE OF STREET INTERSECTIONS\n",
    "        corners = gpd.clip(intersections, bounds_poly)\n",
    "        \n",
    "        # DEFINE OUTPUT FILENAME\n",
    "        ICP_fn = os.path.join(proc_dir, os.path.basename(out_name).split(\".\")[0] + \"_ICP.tif\")\n",
    "        \n",
    "        # ACTUALLY PERFORM ICP AND SAVE OUTPUT GRADE\n",
    "        # best_transform, transform_dict = performICPonTile(detections, streets, plot=True, save_fig=ICP_fn, icp_iterations=500, conv=1e-6)\n",
    "        # best_transform, transform_dict = performICPonTile(detections, streets, plot=True, icp_iterations=50, conv=1e-6, rotation_limit=20)\n",
    "        # out = performWeightedICPonTile([street_det, corner_gdf], [streets, corners], weights=[1, 1/50])\n",
    "        best_transform, transform_dict = performWeightedICPonTile([street_det, corner_gdf], [streets, corners], icp_iterations=30, plot_datasets=[roads_clipped, corners], weights=[1, 1/25], plot=False, )\n",
    "        \n",
    "        bestgrades.append(np.min(transform_dict['grades']))\n",
    "\n",
    "        # SAVE WITH REGISTRATION\n",
    "        raster_name = os.path.join(proc_dir, os.path.basename(out_name).split(\".\")[0] + \"_registered2.tif\")\n",
    "        transform = best_transform @ getMatrixFromAffine(ra.transform) \n",
    "        \n",
    "        # SAVE POINTS USED FOR ESTIMATION\n",
    "        shp_name = os.path.join(proc_dir, os.path.basename(out_name).split(\".\")[0] + \"_XY.gpkg\")\n",
    "        a = gpd.GeoDataFrame(crs=\"EPSG:3857\", geometry=gpd.points_from_xy(transform_dict['reproj'][0][:, 0], transform_dict['reproj'][0][:, 1]))\n",
    "        a.to_file(shp_name)\n",
    "\n",
    "        # SAVE ANCILLARY FILES\n",
    "        out_struct = {\n",
    "            \"best_transform\" : best_transform,\n",
    "            \"transform_dict\" : transform_dict,\n",
    "        }\n",
    "\n",
    "        allgrades.append(transform_dict)\n",
    "        \n",
    "        try:\n",
    "            with rio.open(raster_name, 'w',\n",
    "                driver='GTiff', count=3, dtype=image.dtype,\n",
    "                height=image.shape[0], width=image.shape[1],\n",
    "                crs=f'EPSG:3857',\n",
    "                transform=rio.Affine(*transform.flatten()[:6])) as dst:\n",
    "                    dst.write(image, 1) \n",
    "                    dst.write(roads_thin * 255, 2) \n",
    "                    dst.write(draw_bounding_boxes(corner_bbox, image.shape[:2]), 3) \n",
    "\n",
    "            with open(raster_name[:-4] + \".pkl\", 'wb') as handle:\n",
    "                pickle.dump(out_struct, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "        except:\n",
    "             print(f\"Could not save photo {out_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_bounding_boxes(bboxes, shape):\n",
    "    # Create a zero numpy array with the specified shape\n",
    "    img = np.zeros(shape, dtype=np.uint8)\n",
    "    \n",
    "    # Iterate through each bounding box\n",
    "    for bbox in bboxes:\n",
    "        x1, y1, x2, y2 = np.int32(bbox)\n",
    "        # Fill the region specified by the bounding box with 255\n",
    "        img[y1:y2, x1:x2] = 255\n",
    "    \n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a list of all .pkl file paths\n",
    "pkl_files = glob.glob(r'D:\\RECTDNN\\processing\\2024-05-31_14-05-48\\Tiles\\*registered1.pkl')\n",
    "\n",
    "# Load the content of each .pkl file into a list\n",
    "pkl_data = []\n",
    "for file in pkl_files:\n",
    "    with open(file, 'rb') as f:\n",
    "        pkl_data.append(pickle.load(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>POINT (-10645707.393 3512697.583)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>POINT (-10645864.720 3512819.735)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>POINT (-10646884.339 3512437.850)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>POINT (-10645161.689 3512588.848)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>POINT (-10646937.977 3515060.100)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>POINT (-10646223.897 3516532.466)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>POINT (-10645482.412 3514678.834)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>POINT (-10648270.442 3514021.119)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>POINT (-10647734.137 3516656.439)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>POINT (-10651005.511 3513255.113)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             geometry\n",
       "0   POINT (-10645707.393 3512697.583)\n",
       "0   POINT (-10645864.720 3512819.735)\n",
       "0   POINT (-10646884.339 3512437.850)\n",
       "0   POINT (-10645161.689 3512588.848)\n",
       "0   POINT (-10646937.977 3515060.100)\n",
       "..                                ...\n",
       "0   POINT (-10646223.897 3516532.466)\n",
       "0   POINT (-10645482.412 3514678.834)\n",
       "0   POINT (-10648270.442 3514021.119)\n",
       "0   POINT (-10647734.137 3516656.439)\n",
       "0   POINT (-10651005.511 3513255.113)\n",
       "\n",
       "[80 rows x 1 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' THE BELOW IS THE ORIGINAL ICP ON INTERSECTIONS\n",
    "def calcCenter(a):\n",
    "    # print(a,  (a[0] + a[2]) / 2, (a[1] + a[3]) / 2)\n",
    "    return (a[0] + a[2]) / 2, (a[1] + a[3]) / 2\n",
    "\n",
    "bestgrades = []\n",
    "numcorners = []\n",
    "\n",
    "for i, (out_name, db) in enumerate(tile_coords.items()):\n",
    "    if db is not None:\n",
    "        \n",
    "        # GET STREET CORNERS FROM TPNN OUTPUTS\n",
    "        street_corners = results_struct[tile_coords[out_name]['input_file']]\n",
    "\n",
    "        # SKIP IF TOO FEW CORNERS\n",
    "        if len(street_corners) < 3:\n",
    "            continue\n",
    "\n",
    "        # OPEN RASTER AND GET BOUNDING BOX\n",
    "        ra = rio.open(out_name)\n",
    "        bounds  = ra.bounds\n",
    "        image   = ra.read(1)\n",
    "\n",
    "        # CONVERT STREET CORNERS TO NUMPY ARRAY\n",
    "        street_corners_arry = np.array([calcCenter(street_corners[a]['bbox']) for a in street_corners])\n",
    "        streets = np.zeros(image.shape)\n",
    "        streetcoords = np.int32(street_corners_arry)\n",
    "        streets[streetcoords[:, 1], streetcoords[:, 0]] = 255\n",
    "\n",
    "        # USE RASTER TRANSFORM TO GET REAL-WORLD ESTIMATES OF STREET CORNERS\n",
    "        xs, ys = rio.transform.xy(ra.transform, street_corners_arry[:, 1], street_corners_arry[:, 0])\n",
    "        numcorners.append(len(xs))\n",
    "        print(out_name, len(xs))\n",
    "        \n",
    "        # GET IDENTIFIED STREET INTERSECTIONS\n",
    "        xy = list(zip(xs, ys))\n",
    "        points = MultiPoint(xy)\n",
    "        TLNN = gpd.GeoDataFrame(index=[0], geometry=[points]).explode(ignore_index=False, index_parts=False)\n",
    "        error\n",
    "        # GET SHAPEFILE OF STREET INTERSECTIONS\n",
    "        bounds_poly = enlarged_bounds(ra, n=1.5)\n",
    "        STCN = gpd.clip(intersections, bounds_poly)\n",
    "\n",
    "        ICP_fn = os.path.join(proc_dir, os.path.basename(out_name).split(\".\")[0] + \"_ICP.tif\")\n",
    "        best_transform, transform_dict = performICPonTile(TLNN, STCN, plot=True, save_fig=ICP_fn, icp_iterations=500)\n",
    "        bestgrades.append(np.min(transform_dict['grades']))\n",
    "\n",
    "        raster_name = os.path.join(proc_dir, os.path.basename(out_name).split(\".\")[0] + \"_registered.tif\")\n",
    "        transform = best_transform @ getMatrixFromAffine(ra.transform) \n",
    "        \n",
    "        shp_name = os.path.join(proc_dir, os.path.basename(out_name).split(\".\")[0] + \"_XY.gpkg\")\n",
    "        a = gpd.GeoDataFrame(crs=\"EPSG:3857\", geometry=gpd.points_from_xy(transform_dict['reproj'][0][:, 0], transform_dict['reproj'][0][:, 1]))\n",
    "        a.to_file(shp_name)\n",
    "\n",
    "        try:\n",
    "            with rio.open(raster_name, 'w',\n",
    "                driver='GTiff', count=3, dtype=image.dtype,\n",
    "                height=image.shape[0], width=image.shape[1],\n",
    "                crs=f'EPSG:3857',\n",
    "                transform=rio.Affine(*transform.flatten()[:6])) as dst:\n",
    "                    dst.write(image, 1) \n",
    "                    dst.write(image, 2) \n",
    "                    dst.write(streets, 3) \n",
    "        except:\n",
    "             print(f\"Could not save photo {out_name}\")\n",
    "        error\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
