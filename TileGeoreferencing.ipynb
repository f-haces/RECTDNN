{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTEBOOK IMPORTS\n",
    "import os, glob, warnings, pickle, re\n",
    "import numpy as np\n",
    "from shutil import copyfile, rmtree\n",
    "from datetime import datetime\n",
    "from fuzzywuzzy import process\n",
    "\n",
    "# IMAGE IMPORTS\n",
    "# from PIL import Image\n",
    "\n",
    "# GIS IMPORTS\n",
    "from affinetransformation import *\n",
    "from affine import Affine\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Polygon, LineString, Point, MultiPoint, box\n",
    "import rasterio as rio\n",
    "import contextily as cx\n",
    "\n",
    "\n",
    "# PLOTTING IMPORTS\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# CUSTOM UTILITIES\n",
    "from IndexUtils import * \n",
    "from TileUtils import *\n",
    "\n",
    "Image.MAX_IMAGE_PIXELS = 933120000\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "initialize = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = r\"D:\\RECTDNN\\uncompress\\\\\"\n",
    "proc_dir  = r\"D:\\RECTDNN\\processing\\2024-05-31_14-05-48\\Tiles\\\\\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stateplanes = gpd.read_file(f\"{data_dir}/AAA_ReferenceDatasets/stateplane.shp\")\n",
    "\n",
    "init_databases(f\"{data_dir}/AAA_ReferenceDatasets/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LIST ALL IMAGES IN DIRECTORY\n",
    "image_files = glob.glob(f\"{input_dir}/*\")\n",
    "image_files = [f for f in image_files if 'w' not in os.path.splitext(f)[1]]\n",
    "\n",
    "# FILTER IMAGES USING HEURISTICS TO GET TILEINDICES\n",
    "patterns = [\"IND\", \"_1.\"]\n",
    "index_files = [file for pattern in patterns for file in glob.glob(input_dir + \"\\\\*\" + pattern + \"*.*[!w]*\")]\n",
    "filtered_files = [file for file in image_files if len(os.path.basename(file)) < 12]\n",
    "index_files.extend(filtered_files)\n",
    "\n",
    "# GET ACTUAL TILES\n",
    "tiles       = list(set(image_files) - set(index_files))\n",
    "tiles_bns   = [os.path.basename(tile).split(\".\")[0] for tile in tiles]\n",
    "\n",
    "with open(f\"{data_dir}/AAA_ReferenceDatasets/IndexCoords.pkl\", 'rb') as handle:\n",
    "    dict = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create the tile database with the detected tiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2190 1493\n"
     ]
    }
   ],
   "source": [
    "verbose = False\n",
    "dupped_dict = {}\n",
    "non_dupped_dict = {}\n",
    "\n",
    "db = {}\n",
    "\n",
    "possible_tiles = 0\n",
    "\n",
    "for fn in dict.keys():\n",
    "\n",
    "    # GET AFFIEN TRANSFORM FROM CURRENT INDEX\n",
    "    affine   = Affine(*dict[fn][\"output_transform\"].flatten()[:6])\n",
    "\n",
    "    db[findKey(fn)] = []\n",
    "\n",
    "    possible_tiles = possible_tiles + len(dict[fn]['tile'].keys())\n",
    "    if verbose:\n",
    "        print('-' * 10 + fn + '-' * 10 + str(len(dict[fn]['tile'].keys())))\n",
    "    for i in dict[fn]['tile'].keys():\n",
    "\n",
    "        # SPLIT NEW LINES AND FILTER THOSE WITH LESS THAN 3 NUMBERS\n",
    "        text_ori = dict[fn]['tile'][i]['text'].split(\"\\n\")\n",
    "        text = [a for a in text_ori if len(\"\".join(re.findall(\"\\d+\", a))) > 3]\n",
    "\n",
    "        # FIND KEY BASED ON INDEX NAME\n",
    "        curr_key = findKey(fn)\n",
    "\n",
    "        # EXTRACT ONE OF THE LIST WITH KEY\n",
    "        data = process.extractOne(curr_key, text)\n",
    "        if data is None:\n",
    "            if verbose:\n",
    "                print(\"NOT FOUND \"+ \" /n \".join(text_ori))\n",
    "            continue\n",
    "        found_text, score = data\n",
    "\n",
    "        # IF SCORE IS GOOD ENOUGH\n",
    "        if score > 60:\n",
    "\n",
    "            # FIND INDEX OF MATCHED TEXT IN LINES \n",
    "            idx = text.index(found_text)\n",
    "            \n",
    "            # FIND ALL NUMBERS IN MATCHED TEXT\n",
    "            foundnumbers = \"\".join(re.findall(\"\\d+\", text[idx].replace(\" \", \"\")))\n",
    "            \n",
    "            # REMOVE ANY CHARACTERS PRIOR TO PARTIAL MATCH TO KEY\n",
    "            for a in range(len(curr_key), 1, -1):\n",
    "                currentnumbers = foundnumbers.split(curr_key[-a:])[-1]\n",
    "                if currentnumbers != foundnumbers:\n",
    "                    break\n",
    "            \n",
    "            # IF WE HAVE EXACTLY 5 CHARACTERS, AND THE LAST IS 8, IT'S LIKELY IT WAS A MISREAD \"B\"\n",
    "            if len(currentnumbers) == 5 and (currentnumbers[-1] == \"8\" or currentnumbers[-1] == \"7\"):\n",
    "                currentnumbers = currentnumbers[:-1]\n",
    "\n",
    "            if verbose:\n",
    "                print(curr_key + currentnumbers + \" | \" +foundnumbers + \" | \" +  \" /n \".join(text))\n",
    "\n",
    "            # CALCULATE COORDS FROM AFFINE \n",
    "            bbox = dict[fn]['tile'][i]['bbox']\n",
    "            left, bottom = affine * (bbox[0], bbox[1])\n",
    "            right, top   = affine * (bbox[2], bbox[3])\n",
    "\n",
    "            # PREPARE DICT \n",
    "            out_dict = dict[fn]['tile'][i]\n",
    "            out_dict['coords'] = np.array([left, bottom, right, top])\n",
    "\n",
    "            # SAVE OUTPUT\n",
    "            dupped_dict[curr_key + currentnumbers] = out_dict\n",
    "            \n",
    "            data = non_dupped_dict.get(curr_key + currentnumbers, None)\n",
    "            if data is None: \n",
    "                non_dupped_dict[curr_key + currentnumbers] = out_dict\n",
    "\n",
    "            else:\n",
    "                i=0\n",
    "                while data is not None:\n",
    "                    data = non_dupped_dict.get(curr_key + currentnumbers + f\"_{i}\", None)\n",
    "                    i = i + 1\n",
    "                non_dupped_dict[curr_key + currentnumbers + f\"_{i}\"] = out_dict\n",
    "\n",
    "            db[findKey(fn)].append(curr_key + currentnumbers)\n",
    "\n",
    "print(len(non_dupped_dict), len(dupped_dict))  \n",
    "\n",
    "detected_tiles = pd.DataFrame.from_dict(non_dupped_dict).T\n",
    "detected_tiles['geometry'] = detected_tiles['coords'].apply(bbox_to_polygon)\n",
    "detected_tiles_gdf = gpd.GeoDataFrame(detected_tiles)\n",
    "detected_tiles_gdf = detected_tiles_gdf[['geometry']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we supplement that database with all existing world files..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# READ ALL THE WORLD FILES FROM A DIRECTORY AND CREATE A DATAFRAME\n",
    "data = read_world_files_from_directory(input_dir)\n",
    "columns = ['filename', 'line1', 'line2', 'line3', 'line4', 'line5', 'line6']\n",
    "df = pd.DataFrame(data, columns=columns)\n",
    "\n",
    "# CONVERT ALL READ PARAMETERS TO NUMERIC\n",
    "for col in [col for col in df.columns if \"line\" in col]:\n",
    "    df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "\n",
    "# FIND GEOMETRY FOR EACH ROW\n",
    "df['key']   = df['filename'].apply(findTileKey, db=db)  # FIND THE KEY FOR THE FILENAME\n",
    "df['key_n'] = pd.to_numeric(df['key'], errors='coerce') # CONVERT IT TO NUMERIC\n",
    "df[\"GEOID\"] = df[\"key_n\"].apply(getGEOID)               # GET GEOID FOR EACH INDEX\n",
    "df['county_polygon'] = df[\"GEOID\"].apply(getGeometry)   # USE FIND GEOMETRY FUNCTION\n",
    "\n",
    "# HEURISTICS - DEFINE WHETHER THE FOUND TRANSFORM IS STATEPLANE \n",
    "# BY IT'S SCALE. IF IT'S BIGGER THAN 1, PROBABLY (MOST FILE'S RESOLUTION IS < 0.5 m)\n",
    "df['STATEPLANE'] = df['line1'] > 1\n",
    "\n",
    "# INTERSECT DF WITH STATE PLANE SHAPEFILE \n",
    "geo_df   = gpd.GeoDataFrame(df, geometry=df['county_polygon']).set_crs(\"EPSG:3857\").to_crs(\"EPSG:4326\")\n",
    "df_plane = geo_df.overlay(stateplanes, how='intersection')\n",
    "\n",
    "# CALCULATE EPSG CODE\n",
    "df['epsg'] = geo_df.apply(getEPSG, df_plane=df_plane, axis=1)\n",
    "del geo_df, df_plane\n",
    "\n",
    "df['geotransform'] = df['filename'].apply(getGeotransform, input_dir=input_dir)\n",
    "df['affine'] = df['geotransform'].apply(getAffine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53572d94de42458ca50017334caf7def",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/178 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NO BOUNDS FOUND D:\\RECTDNN\\uncompress\\48201C0195M.tif\n",
      "NO BOUNDS FOUND D:\\RECTDNN\\uncompress\\48201C0415M.tif\n",
      "NO BOUNDS FOUND D:\\RECTDNN\\uncompress\\48201C0970M.tif\n",
      "NO BOUNDS FOUND D:\\RECTDNN\\uncompress\\48201C1030L.tif\n"
     ]
    }
   ],
   "source": [
    "webmercator = []\n",
    "\n",
    "RLNN = None\n",
    "def notify(mess, level=2):\n",
    "    if level < 4:\n",
    "        print(mess)\n",
    "\n",
    "for i, row in tqdm(df.iterrows(), total=df.shape[0]):\n",
    "    fn = row['filename'].split(\".\")[0]\n",
    "    image_files = glob.glob(f'{os.path.join(input_dir, fn)}*[!w]')\n",
    "\n",
    "    if pd.isna(row['epsg']):\n",
    "        notify(f\"NO EPSG {fn}\")\n",
    "        webmercator.append([])\n",
    "        continue\n",
    "\n",
    "    if len(image_files) == 0:\n",
    "        notify(f\"NO CORRESPONDING IMAGE {fn}\")\n",
    "        webmercator.append([])\n",
    "        continue\n",
    "    bounds, RLNN = findBounds(image_files[0], model=RLNN, verbose=False, device=\"cuda\")\n",
    "\n",
    "    if len(bounds[0]) == 0:\n",
    "        notify(f\"NO BOUNDS FOUND {image_files[0]}\")\n",
    "        webmercator.append([])\n",
    "        continue\n",
    "\n",
    "    bbox = bounds[0].boxes.xyxy.numpy()[0]\n",
    "\n",
    "    in_crs  = rio.crs.CRS.from_string(f\"{row['epsg']}\")\n",
    "    out_crs = rio.crs.CRS.from_epsg(f\"3857\")\n",
    "\n",
    "    left, bottom = row['affine'] * (bbox[0], bbox[1])\n",
    "    right, top   = row['affine'] * (bbox[2], bbox[3])\n",
    "\n",
    "    new_bbox = rio.warp.transform_bounds(in_crs, out_crs, left, bottom, right, top)\n",
    "    webmercator.append(new_bbox)\n",
    "    # print(bbox, [bottom, left, top, right], new_bbox)\n",
    "\n",
    "df[\"webmerc\"] = webmercator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the function to the 'bbox' column\n",
    "df['geometry'] = df['webmerc'].apply(bbox_to_polygon)\n",
    "gdf = gpd.GeoDataFrame(df)\n",
    "gdf.dropna(axis=0)\n",
    "\n",
    "for key in gdf.keys():\n",
    "    if key == 'geometry':\n",
    "        continue\n",
    "    gdf[key] = gdf[key].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf.to_file(r\"D:\\RECTDNN\\WorldFiles.shp\")\n",
    "detected_tiles_gdf.to_file(r\"D:\\RECTDNN\\Detected.shp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df465116e9974e36804d07cfe419192c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2251 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found in dict, skipping D:\\RECTDNN\\uncompress\\4800350550B.jpg\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\fhacesga\\Anaconda3\\envs\\yolo\\lib\\site-packages\\PIL\\ImageFile.py:515\u001b[0m, in \u001b[0;36m_save\u001b[1;34m(im, fp, tile, bufsize)\u001b[0m\n\u001b[0;32m    514\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 515\u001b[0m     fh \u001b[38;5;241m=\u001b[39m \u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfileno\u001b[49m()\n\u001b[0;32m    516\u001b[0m     fp\u001b[38;5;241m.\u001b[39mflush()\n",
      "\u001b[1;31mAttributeError\u001b[0m: '_idat' object has no attribute 'fileno'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[96], line 45\u001b[0m\n\u001b[0;32m     41\u001b[0m     results_struct[tile] \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresults\u001b[39m\u001b[38;5;124m\"\u001b[39m : results, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbounds\u001b[39m\u001b[38;5;124m\"\u001b[39m : bounds}\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     44\u001b[0m     \u001b[38;5;66;03m# RUN FANN\u001b[39;00m\n\u001b[1;32m---> 45\u001b[0m     results, model \u001b[38;5;241m=\u001b[39m \u001b[43mrunYOLO_Text\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mdata_dir\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43mFANN/YOLO/051624_bw.pt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mYOLO_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     46\u001b[0m     results_struct[tile] \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresults\u001b[39m\u001b[38;5;124m\"\u001b[39m : results, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbounds\u001b[39m\u001b[38;5;124m\"\u001b[39m : bounds}\n\u001b[0;32m     48\u001b[0m \u001b[38;5;66;03m# SAVE EVERY N ITERATIONS AND LAST\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[95], line 90\u001b[0m, in \u001b[0;36mrunYOLO_Text\u001b[1;34m(image_fn, model, model_weights, save_dir, device, verbose, get_data, find_text, keyed_text, target_size, conf_threshold, plot_params)\u001b[0m\n\u001b[0;32m     87\u001b[0m     outputs[i] \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbbox\u001b[39m\u001b[38;5;124m\"\u001b[39m : bbox, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m : data, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m : text, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkeyed_text\u001b[39m\u001b[38;5;124m\"\u001b[39m : word, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconfidence\u001b[39m\u001b[38;5;124m\"\u001b[39m : conf[i]}\n\u001b[0;32m     89\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m save_dir \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m---> 90\u001b[0m     \u001b[43mresults\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43msave_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mplot_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     92\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m outputs, model\n",
      "File \u001b[1;32mc:\\Users\\fhacesga\\Anaconda3\\envs\\yolo\\lib\\site-packages\\ultralytics\\engine\\results.py:312\u001b[0m, in \u001b[0;36mResults.save\u001b[1;34m(self, filename, *args, **kwargs)\u001b[0m\n\u001b[0;32m    310\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m filename:\n\u001b[0;32m    311\u001b[0m     filename \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresults_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mPath(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpath)\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 312\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplot\u001b[49m\u001b[43m(\u001b[49m\u001b[43msave\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    313\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m filename\n",
      "File \u001b[1;32mc:\\Users\\fhacesga\\Anaconda3\\envs\\yolo\\lib\\site-packages\\ultralytics\\engine\\results.py:300\u001b[0m, in \u001b[0;36mResults.plot\u001b[1;34m(self, conf, line_width, font_size, font, pil, img, im_gpu, kpt_radius, kpt_line, labels, boxes, masks, probs, show, save, filename)\u001b[0m\n\u001b[0;32m    298\u001b[0m \u001b[38;5;66;03m# Save results\u001b[39;00m\n\u001b[0;32m    299\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m save:\n\u001b[1;32m--> 300\u001b[0m     \u001b[43mannotator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    302\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m annotator\u001b[38;5;241m.\u001b[39mresult()\n",
      "File \u001b[1;32mc:\\Users\\fhacesga\\Anaconda3\\envs\\yolo\\lib\\site-packages\\ultralytics\\utils\\plotting.py:339\u001b[0m, in \u001b[0;36mAnnotator.save\u001b[1;34m(self, filename)\u001b[0m\n\u001b[0;32m    337\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msave\u001b[39m(\u001b[38;5;28mself\u001b[39m, filename\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimage.jpg\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    338\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Save the annotated image to 'filename'.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 339\u001b[0m     \u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mim\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mImage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mImage\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mImage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfromarray\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mim\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\fhacesga\\Anaconda3\\envs\\yolo\\lib\\site-packages\\PIL\\Image.py:2413\u001b[0m, in \u001b[0;36mImage.save\u001b[1;34m(self, fp, format, **params)\u001b[0m\n\u001b[0;32m   2410\u001b[0m         fp \u001b[38;5;241m=\u001b[39m builtins\u001b[38;5;241m.\u001b[39mopen(filename, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw+b\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   2412\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 2413\u001b[0m     \u001b[43msave_handler\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2414\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m   2415\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m open_fp:\n",
      "File \u001b[1;32mc:\\Users\\fhacesga\\Anaconda3\\envs\\yolo\\lib\\site-packages\\PIL\\PngImagePlugin.py:1398\u001b[0m, in \u001b[0;36m_save\u001b[1;34m(im, fp, filename, chunk, save_all)\u001b[0m\n\u001b[0;32m   1396\u001b[0m     _write_multiple_frames(im, fp, chunk, rawmode, default_image, append_images)\n\u001b[0;32m   1397\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1398\u001b[0m     \u001b[43mImageFile\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_save\u001b[49m\u001b[43m(\u001b[49m\u001b[43mim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_idat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mzip\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrawmode\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1400\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m info:\n\u001b[0;32m   1401\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m info_chunk \u001b[38;5;129;01min\u001b[39;00m info\u001b[38;5;241m.\u001b[39mchunks:\n",
      "File \u001b[1;32mc:\\Users\\fhacesga\\Anaconda3\\envs\\yolo\\lib\\site-packages\\PIL\\ImageFile.py:519\u001b[0m, in \u001b[0;36m_save\u001b[1;34m(im, fp, tile, bufsize)\u001b[0m\n\u001b[0;32m    517\u001b[0m     _encode_tile(im, fp, tile, bufsize, fh)\n\u001b[0;32m    518\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mAttributeError\u001b[39;00m, io\u001b[38;5;241m.\u001b[39mUnsupportedOperation) \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m--> 519\u001b[0m     \u001b[43m_encode_tile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbufsize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    520\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(fp, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mflush\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    521\u001b[0m     fp\u001b[38;5;241m.\u001b[39mflush()\n",
      "File \u001b[1;32mc:\\Users\\fhacesga\\Anaconda3\\envs\\yolo\\lib\\site-packages\\PIL\\ImageFile.py:538\u001b[0m, in \u001b[0;36m_encode_tile\u001b[1;34m(im, fp, tile, bufsize, fh, exc)\u001b[0m\n\u001b[0;32m    535\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m exc:\n\u001b[0;32m    536\u001b[0m     \u001b[38;5;66;03m# compress to Python file-compatible object\u001b[39;00m\n\u001b[0;32m    537\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 538\u001b[0m         errcode, data \u001b[38;5;241m=\u001b[39m \u001b[43mencoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbufsize\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m:]\n\u001b[0;32m    539\u001b[0m         fp\u001b[38;5;241m.\u001b[39mwrite(data)\n\u001b[0;32m    540\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m errcode:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "FANN_prior = None\n",
    "RLNN_prior = None\n",
    "model = None\n",
    "\n",
    "color=False\n",
    "\n",
    "plot_params = {\"labels\" : False, }\n",
    "YOLO_params = {\n",
    "    \"device\"  : \"cuda\",     \"find_text\" : False, \n",
    "    \"keyed_text\"  : False,  \"verbose\" : False,  \"get_data\"  : False,\n",
    "    \"target_size\" : 1920,   \"plot_params\" : plot_params\n",
    "}\n",
    "\n",
    "# IF WE'VE ALREADY STARTED PROCESSING THINGS, LOAD STATE DICT\n",
    "if os.path.exists(f'{proc_dir}results.pkl'):\n",
    "    with open(f'{proc_dir}results.pkl', 'rb') as handle:\n",
    "        results_struct = pickle.load(handle)\n",
    "else:\n",
    "    results_struct = {}\n",
    "\n",
    "# LOOP FOR EACH TILE\n",
    "for i, tile in tqdm(enumerate(tiles), total=len(tiles)):\n",
    "    \n",
    "    # DEFINE WHERE GEOREFERENCED TILE IS SAVED\n",
    "    out_fn = os.path.join(proc_dir, os.path.basename(tile).split(\".\")[0] + \"_FANN.png\")\n",
    "\n",
    "    # HAVE WE ALREADY PROCESSED THIS TILE? IF SO, SKIP\n",
    "    if results_struct.get(tile, None):\n",
    "        print(f\"Found in dict, skipping {tile}\")\n",
    "        continue\n",
    "\n",
    "    # WHICH VERSION OF FANN ARE WE USING\n",
    "    if color:\n",
    "        # RUN AND SAVE PREPROCESSING FANN AND RLNN\n",
    "        prepped_fn = os.path.join(proc_dir, os.path.basename(tile).split(\".\")[0] + \"_prepped.png\")                      # FILE NAME\n",
    "        prepped, FANN_prior, RLNN_prior, bounds = findStreetCorners_colorPrep(tile, FANN=FANN_prior, RLNN=RLNN_prior)   # RUN FANN_PRIOR AND RLNN\n",
    "        Image.fromarray(prepped).save(prepped_fn) # SAVE\n",
    "\n",
    "        # RUN FANN\n",
    "        results, model = runYOLO_Text(prepped_fn, model=model, model_weights=f\"{data_dir}FANN/YOLO/051624.pt\", save_dir=out_fn, **YOLO_params)\n",
    "        results_struct[tile] = {\"results\" : results, \"bounds\" : bounds}\n",
    "\n",
    "    else:\n",
    "        # RUN FANN\n",
    "        results, model = runYOLO_Text(tile, model=model, model_weights=f\"{data_dir}FANN/YOLO/051624_bw.pt\", save_dir=out_fn, **YOLO_params)\n",
    "        results_struct[tile] = {\"results\" : results, \"bounds\" : bounds}\n",
    "\n",
    "    # SAVE EVERY N ITERATIONS AND LAST\n",
    "    if i % 10 == 0 or i == len(tiles) - 1:\n",
    "        with open(f'{proc_dir}results.pkl', 'wb') as handle:\n",
    "            pickle.dump(results_struct, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbf52250eeb1440282cc5a9547705e25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2251 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COULD NOT FIND BOUNDS, USING IMAGE EXTENTS D:\\RECTDNN\\uncompress\\485470A_1.tif\n",
      "COULD NOT FIND BOUNDS, USING IMAGE EXTENTS D:\\RECTDNN\\uncompress\\4802960125C.jpg\n",
      "COULD NOT FIND BOUNDS, USING IMAGE EXTENTS D:\\RECTDNN\\uncompress\\4802870260E.jpg\n",
      "COULD NOT FIND BOUNDS, USING IMAGE EXTENTS D:\\RECTDNN\\uncompress\\4800450042B.jpg\n",
      "COULD NOT FIND BOUNDS, USING IMAGE EXTENTS D:\\RECTDNN\\uncompress\\4803070015D.jpg\n",
      "COULD NOT FIND BOUNDS, USING IMAGE EXTENTS D:\\RECTDNN\\uncompress\\4854560010D.jpg\n",
      "COULD NOT FIND BOUNDS, USING IMAGE EXTENTS D:\\RECTDNN\\uncompress\\4802660225.tif\n",
      "COULD NOT FIND BOUNDS, USING IMAGE EXTENTS D:\\RECTDNN\\uncompress\\4854560015.tif\n",
      "COULD NOT FIND BOUNDS, USING IMAGE EXTENTS D:\\RECTDNN\\uncompress\\4802670002C.tif\n",
      "COULD NOT FIND BOUNDS, USING IMAGE EXTENTS D:\\RECTDNN\\uncompress\\4800450032C.jpg\n",
      "COULD NOT FIND BOUNDS, USING IMAGE EXTENTS D:\\RECTDNN\\uncompress\\4802660225C.tif\n",
      "COULD NOT FIND BOUNDS, USING IMAGE EXTENTS D:\\RECTDNN\\uncompress\\4854560015B.jpg\n",
      "COULD NOT FIND BOUNDS, USING IMAGE EXTENTS D:\\RECTDNN\\uncompress\\4802960075D.jpg\n"
     ]
    }
   ],
   "source": [
    "def bboxTransformToCRS(transform, image):\n",
    "    rev_y_axis = np.array([[1, 0, 0],\n",
    "                        [0,-1, 0],\n",
    "                        [0, 0, 1]])\n",
    "\n",
    "    # move = original_homography @ np.array([0, image_t.shape[0], 0])\n",
    "    translation = np.eye(3)\n",
    "    translation[1, 2] = image.shape[0]\n",
    "\n",
    "    return transform @ translation @ rev_y_axis\n",
    "\n",
    "\n",
    "def bbox_to_coords_realworld(bbox):\n",
    "    '''  \n",
    "    x1, y1, x2, y2 = bbox\n",
    "\n",
    "    x_min = np.min([x1, x2])    \n",
    "    x_max = np.max([x1, x2])    \n",
    "    y_min = np.min([y1, y2])    \n",
    "    y_max = np.max([y1, y2])  \n",
    "    '''\n",
    "\n",
    "    x_min, y_min, x_max, y_max = bbox\n",
    "\n",
    "    xs = [x_min, x_min, x_max, x_max]\n",
    "    ys = [y_max, y_min, y_min, y_max]\n",
    "    return xs, ys\n",
    "\n",
    "def bbox_to_coords_raster(bbox):\n",
    "    '''\n",
    "    x1, y1, x2, y2 = bbox\n",
    "\n",
    "    x_min = np.min([x1, x2])    \n",
    "    x_max = np.max([x1, x2])    \n",
    "    y_min = np.min([y1, y2])    \n",
    "    y_max = np.max([y1, y2])    \n",
    "\n",
    "    \n",
    "    '''\n",
    "    x_min, y_min, x_max, y_max = bbox\n",
    "\n",
    "    xs = [x_min, x_min, x_max, x_max]\n",
    "    ys = [y_min, y_max, y_max, y_min]\n",
    "    return xs, ys\n",
    "\n",
    "bad = 0\n",
    "RLNN = None\n",
    "\n",
    "detected_tiles['reference_name'] = detected_tiles.index\n",
    "list_tiles = list(detected_tiles_gdf.index)\n",
    "\n",
    "tile_coords = {}\n",
    "debug_struct = {}\n",
    "for i, tile in tqdm(enumerate(tiles), total=len(tiles)):\n",
    "    \n",
    "    \n",
    "\n",
    "    # KEEP NUMERIC PART OF TILE NAME\n",
    "    p = re.sub(r\"[^0-9]\", \"\", os.path.basename(tile))\n",
    "    \n",
    "    # PERFORM MATCHING\n",
    "    match, score = process.extractOne(tiles_bns[i], list_tiles)\n",
    "\n",
    "    out_fn = os.path.join(proc_dir, tiles_bns[i] + \".tif\")\n",
    "    \n",
    "    if score > 90:\n",
    "        image = np.asarray(Image.open(tile))\n",
    "\n",
    "        if np.max(image) < 255:\n",
    "            image = image * 255\n",
    "            image = image.astype(np.uint8)\n",
    "\n",
    "        tile_coords[p] = detected_tiles.loc[match]\n",
    "        bounds, RLNN = findBounds(tile, RLNN)\n",
    "        \n",
    "        if len(bounds[0]) < 1:\n",
    "            print(f\"COULD NOT FIND BOUNDS, USING IMAGE EXTENTS {tile}\")\n",
    "            \n",
    "            bbox = [0, 0, image.shape[0], image.shape[1]]\n",
    "        else:\n",
    "            bbox = bounds[0].boxes.xyxy.numpy().astype(np.int32)[0].flatten()\n",
    "        \n",
    "        real_x, real_y = bbox_to_coords_realworld(tile_coords[p][\"coords\"])\n",
    "        pic_x, pic_y   = bbox_to_coords_raster(bbox)\n",
    "\n",
    "        # transform = similarityTransformation(pic_x, pic_y, real_x, real_y)\n",
    "        affine = affineTransformation(pic_x, pic_y, real_x, real_y)\n",
    "        transform = bboxTransformToCRS(affine.matrix, image)\n",
    "\n",
    "        # print(*transform.flatten()[:6])\n",
    "\n",
    "        debug_struct[p] = {\n",
    "            \"real_x\" : real_x, \"real_y\" : real_y,\n",
    "            \"pic_x\"  : pic_x,  \"pic_y\"  : pic_y,\n",
    "            \"affine\" : affine, \"transform\" : transform\n",
    "\n",
    "        }\n",
    "\n",
    "        with rio.open(out_fn, 'w',\n",
    "            driver='GTiff', count=1, dtype=image.dtype,\n",
    "            height=image.shape[0], width=image.shape[1],\n",
    "            crs=f'EPSG:3857',\n",
    "            transform=rio.Affine(*transform.flatten()[:6])) as dst:\n",
    "                dst.write(image, 1) \n",
    "                \n",
    "    else:\n",
    "        tile_coords[p] = None\n",
    "        bad = bad + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: {'bbox': array([     391.17,        1964,      433.63,      2011.1]),\n",
       "  'data': <PIL.Image.Image image mode=1 size=42x48>,\n",
       "  'text': None,\n",
       "  'keyed_text': None,\n",
       "  'confidence': 0.46481782},\n",
       " 1: {'bbox': array([     706.26,      879.28,      747.67,      923.73]),\n",
       "  'data': <PIL.Image.Image image mode=1 size=41x44>,\n",
       "  'text': None,\n",
       "  'keyed_text': None,\n",
       "  'confidence': 0.43216625},\n",
       " 2: {'bbox': array([     461.75,      1361.4,      494.56,      1393.7]),\n",
       "  'data': <PIL.Image.Image image mode=1 size=33x32>,\n",
       "  'text': None,\n",
       "  'keyed_text': None,\n",
       "  'confidence': 0.40378115},\n",
       " 3: {'bbox': array([     262.43,      1637.4,      290.59,      1668.4]),\n",
       "  'data': <PIL.Image.Image image mode=1 size=28x31>,\n",
       "  'text': None,\n",
       "  'keyed_text': None,\n",
       "  'confidence': 0.40176573},\n",
       " 4: {'bbox': array([     427.47,      1321.8,      460.93,      1358.9]),\n",
       "  'data': <PIL.Image.Image image mode=1 size=33x37>,\n",
       "  'text': None,\n",
       "  'keyed_text': None,\n",
       "  'confidence': 0.37235332},\n",
       " 5: {'bbox': array([     296.99,      1670.9,      326.76,      1702.6]),\n",
       "  'data': <PIL.Image.Image image mode=1 size=30x32>,\n",
       "  'text': None,\n",
       "  'keyed_text': None,\n",
       "  'confidence': 0.37152433},\n",
       " 6: {'bbox': array([        330,      1707.8,      366.32,        1746]),\n",
       "  'data': <PIL.Image.Image image mode=1 size=37x39>,\n",
       "  'text': None,\n",
       "  'keyed_text': None,\n",
       "  'confidence': 0.3326605},\n",
       " 7: {'bbox': array([     643.53,      1568.6,      687.29,      1613.7]),\n",
       "  'data': <PIL.Image.Image image mode=1 size=44x45>,\n",
       "  'text': None,\n",
       "  'keyed_text': None,\n",
       "  'confidence': 0.32426256},\n",
       " 8: {'bbox': array([     546.11,      1669.3,      589.04,      1709.7]),\n",
       "  'data': <PIL.Image.Image image mode=1 size=43x40>,\n",
       "  'text': None,\n",
       "  'keyed_text': None,\n",
       "  'confidence': 0.32226682},\n",
       " 9: {'bbox': array([     253.32,      1629.4,      288.84,      1660.4]),\n",
       "  'data': <PIL.Image.Image image mode=1 size=35x31>,\n",
       "  'text': None,\n",
       "  'keyed_text': None,\n",
       "  'confidence': 0.32175982},\n",
       " 10: {'bbox': array([     197.71,      1571.1,      239.95,      1611.4]),\n",
       "  'data': <PIL.Image.Image image mode=1 size=42x40>,\n",
       "  'text': None,\n",
       "  'keyed_text': None,\n",
       "  'confidence': 0.31459597},\n",
       " 11: {'bbox': array([     200.23,        1570,      234.56,      1605.3]),\n",
       "  'data': <PIL.Image.Image image mode=1 size=34x36>,\n",
       "  'text': None,\n",
       "  'keyed_text': None,\n",
       "  'confidence': 0.31033686},\n",
       " 12: {'bbox': array([     608.43,      1532.4,      642.09,      1566.9]),\n",
       "  'data': <PIL.Image.Image image mode=1 size=34x34>,\n",
       "  'text': None,\n",
       "  'keyed_text': None,\n",
       "  'confidence': 0.29994276},\n",
       " 13: {'bbox': array([     392.47,      1614.3,      430.87,      1653.3]),\n",
       "  'data': <PIL.Image.Image image mode=1 size=38x39>,\n",
       "  'text': None,\n",
       "  'keyed_text': None,\n",
       "  'confidence': 0.25623384}}"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   -0.13152,          -0, -1.0944e+07],\n",
       "       [          0,    -0.13152,  3.4161e+06],\n",
       "       [          0,           0,           1]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transform.matrix"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
