{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af66f8d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "import rasterio as rio\n",
    "from rasterio.crs import CRS\n",
    "\n",
    "import cv2\n",
    "from affine import Affine\n",
    "import numpy as np\n",
    "import glob\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from affine import Affine\n",
    "from itertools import product\n",
    "\n",
    "from WorldFileUtils import *\n",
    "\n",
    "Image.MAX_IMAGE_PIXELS = 933120000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57a4bcab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep(image):\n",
    "    image = np.asarray(image).astype(np.uint8)\n",
    "    image = np.uint8(255 - image)\n",
    "    return image\n",
    "\n",
    "def prepedges(image):\n",
    "    image = np.asarray(image).astype(np.uint8)\n",
    "    image = cv2.Canny(image,50,100)\n",
    "    image = cv2.dilate(image, np.ones((3,3), np.uint8), iterations=30)\n",
    "    return np.asarray(image ).astype(np.uint8)\n",
    "\n",
    "def prepedges_fine(image):\n",
    "    image = np.asarray(image).astype(np.uint8)\n",
    "    image = cv2.Canny(image,50,100)\n",
    "    image = cv2.dilate(image, np.ones((3,3), np.uint8), iterations=5)\n",
    "    return np.asarray(image ).astype(np.uint8)\n",
    "\n",
    "# REFERENCE IMAGE FROM QGIS\n",
    "template = prep(Image.open(r\"Harris_Boundary_hollow.png\"))[:,:,0]\n",
    "\n",
    "# TILE INDEX TO TEST ON\n",
    "image    = prepedges(Image.open(r\"masks_black.png\"))\n",
    "image_f  = prepedges_fine(Image.open(r\"masks_black.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a9ed4fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReturnValues:\n",
    "    def __init__(self, _result, _mask, _rotated_template, _scale, _angle):\n",
    "        self.result = _result\n",
    "        self.mask = _mask\n",
    "        self.rotated_template = _rotated_template\n",
    "        self.scale = _scale\n",
    "        self.angle = _angle\n",
    "\n",
    "class InputValues:\n",
    "    def __init__(self, scale, angle):\n",
    "        self.angle = angle\n",
    "        self.scale = scale\n",
    "    def __str__(self):\n",
    "        return f\"{self.scale} {self.scale}\"\n",
    "        \n",
    "def wrapPatternMatch(inputvalue):\n",
    "    \"\"\"\n",
    "    Wrapper function for pattern match to only have one input for multithreading\n",
    "\n",
    "    Args:\n",
    "        inputvalue:  Custom class with values for function\n",
    "\n",
    "    Returns:\n",
    "        RVs          Custom wrapper class with required values\n",
    "    \"\"\"\n",
    "    return patternMatch(image, template, inputvalue.scale, inputvalue.angle)\n",
    "\n",
    "def patternMatch(image, template, scale, angle, method=cv2.TM_SQDIFF):\n",
    "    \"\"\"\n",
    "    Pattern matching with rescaling and rotating. \n",
    "\n",
    "    Args:\n",
    "        image:       Image to template match (2D array)\n",
    "        template:    Template to use for matching (2D array)\n",
    "        scale:       Scale for which to rescale as percent of original image width\n",
    "        angle:       Angle to which to rotate template\n",
    "        method:      Method to use for template matching\n",
    "\n",
    "    Returns:\n",
    "        RVs          Custom wrapper class with required values\n",
    "    \"\"\"\n",
    "    \n",
    "    # RESIZE THE TEMPLATE TO APPROPRIATE SCALE\n",
    "    scaled_template = cv2.resize(template, None, fx=scale, fy=scale)\n",
    "    \n",
    "    # ROTATE THE TEMPLATE TO APPROPRIATE ANGLE\n",
    "    rotation_matrix = cv2.getRotationMatrix2D((scaled_template.shape[1] / 2, scaled_template.shape[0] / 2), angle, 1.0)\n",
    "    rotated_template = cv2.warpAffine(scaled_template, rotation_matrix, (scaled_template.shape[1], scaled_template.shape[0]))\n",
    "    \n",
    "    # CREATE MASK TO NOT COUNT ZEROS IN TEMPLATE\n",
    "    mask = np.where(rotated_template == 0, 0, 255).astype(np.uint8)\n",
    "    \n",
    "    # RUN PATTERNMATCHING\n",
    "    result = cv2.matchTemplate(image, rotated_template, method, mask=mask)    \n",
    "    return ReturnValues(result, mask,rotated_template, scale, angle)\n",
    "\n",
    "def postprocess_results(result_list, scales, angles, opt_max):\n",
    "    \"\"\"\n",
    "    This converts the results from the patternmatching workflow to \n",
    "    actionable information as described below\n",
    "\n",
    "    Args:\n",
    "        result_list: List of 2D arrays containing results from pattern matching\n",
    "        scales:      1D array of scales used for current pattern matching \n",
    "        angles:      1D array of angles used for current pattern matching \n",
    "        opt_max:     Flag indicating whether best is Max or Min. False = Min\n",
    "\n",
    "    Returns:\n",
    "        x:           Best predicted X for pattern matching\n",
    "        y:           Best predicted Y for pattern matching\n",
    "        br:          Tuple containing (X, Y) coordinates of predicted bottom right corner\n",
    "        rf:          Predicted rescale factor\n",
    "        ang:         Predicted angle\n",
    "    \"\"\"\n",
    "    \n",
    "    # FLATTEN ALL ARRAYS TO CALCULATE CUTOFF VALUES FOR CANDIATES\n",
    "    elem_list = [x.flatten() for x in result_list]\n",
    "    elem_list = np.hstack(elem_list)\n",
    "    \n",
    "    # CUTOFF VALUES FOR CANDIDATES\n",
    "    if opt_max:\n",
    "        thresh = np.percentile(elem_list, 99.9)\n",
    "        loc_list = [x > thresh for x in result_list]\n",
    "    else:\n",
    "        thresh = np.percentile(elem_list, 0.1)\n",
    "        loc_list = [x < thresh for x in result_list]\n",
    "        \n",
    "    # VOTES ON DIFFERENT PATTERN MATCHING AT DIFFERENT VALUES\n",
    "    votes = np.array([np.count_nonzero(x) for x in loc_list])\n",
    "    \n",
    "    rf  = np.sum(votes * scales) / np.sum(votes)\n",
    "    ang = np.sum(votes * angles) / np.sum(votes)\n",
    "    \n",
    "    # LIST OF X AND Y VALUES\n",
    "    x_list = np.hstack([np.where(x)[0] for x in loc_list])\n",
    "    y_list = np.hstack([np.where(x)[1] for x in loc_list])\n",
    "    \n",
    "    # RETURN MEDIAN OF VALUES\n",
    "    x = int(np.median(x_list))\n",
    "    y = int(np.median(y_list))\n",
    "    \n",
    "    # BOTTOM RIGHT VALUE\n",
    "    br = (int(y + template.shape[1] * rf), int(x + template.shape[0] * rf))\n",
    "    \n",
    "    return x, y, br, rf, ang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "93188853",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SearchOptimalMatch(initial_guess, perturbance, angle=0, change_ang=None, retall=True, rngpert=2):\n",
    "    \n",
    "    # WHICH ANGLES AND SCALES TO SEARCH\n",
    "    if change_ang is None:\n",
    "        scales = np.arange(initial_guess-perturbance, initial_guess+perturbance+1e-5, perturbance/rngpert)\n",
    "        inputs = [InputValues(scale, angle) for scale in scales]\n",
    "        angles = [0]\n",
    "    else:\n",
    "        scales = np.arange(initial_guess-perturbance, initial_guess+perturbance+1e-5, perturbance/rngpert)\n",
    "        angles = np.arange(angle-change_ang, angle+change_ang+1e-5, change_ang/2)\n",
    "        inputs = [InputValues(scale, angle) for scale, angle in product(scales, angles)]\n",
    "        scales = [IV.scale for IV in inputs]\n",
    "        angles  = [IV.angle for IV in inputs]\n",
    "                \n",
    "    # INITIALIZE BEST MATCH VARIABLES\n",
    "    best_match_scale = 1.0\n",
    "    best_match_angle = 0.0\n",
    "    \n",
    "    # IS BEST MAX OR MIN? FALSE = MIN\n",
    "    opt_max = False\n",
    "    if opt_max:\n",
    "        best_match_value = -1 * np.inf\n",
    "    else:\n",
    "        best_match_value = np.inf\n",
    "        \n",
    "    result_list = list()\n",
    "    best_loc_list = list()\n",
    "    rect_corner_list = list()\n",
    "\n",
    "    with ThreadPoolExecutor(max_workers=8) as executor:\n",
    "        for retvalue in tqdm(executor.map(wrapPatternMatch, inputs), total=len(inputs)):\n",
    "\n",
    "            mask = retvalue.mask\n",
    "            result = retvalue.result\n",
    "            rotated_template = retvalue.rotated_template\n",
    "            scale = retvalue.scale\n",
    "            angle = retvalue.angle\n",
    "            if not opt_max:\n",
    "                result = np.sqrt(result / np.count_nonzero(mask))\n",
    "\n",
    "            result_list.append(result)\n",
    "            min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(result)\n",
    "\n",
    "            if opt_max:\n",
    "                best_val = max_val\n",
    "                best_loc = max_loc\n",
    "                bottom_right = (best_loc[0] + int(rotated_template.shape[1]), best_loc[1] + int(rotated_template.shape[0]))\n",
    "\n",
    "                best_loc_list.append(best_loc)\n",
    "                rect_corner_list.append(bottom_right)\n",
    "\n",
    "            else:\n",
    "                best_val = min_val\n",
    "                best_loc = min_loc\n",
    "                bottom_right = (best_loc[0] + int(rotated_template.shape[1]), best_loc[1] + int(rotated_template.shape[0]))\n",
    "                best_loc_list.append(best_loc)\n",
    "                rect_corner_list.append(bottom_right)            \n",
    "\n",
    "            print(scale, angle, best_val)\n",
    "        \n",
    "        postprocess = postprocess_results(result_list, scales, angles, opt_max)\n",
    "    \n",
    "    if not retall:\n",
    "        return postprocess[3]\n",
    "    return postprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc6958f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a5d0a097532487689446323a07af194",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7000000000000001 0 216.62223399738718\n",
      "0.7500000000000001 0 215.6942329081225\n",
      "0.8000000000000002 0 216.78464493077408\n",
      "0.8500000000000002 0 204.41115459919004\n",
      "0.9000000000000002 0 208.84378380878118\n",
      "New Guess: 0.868405879365459 0.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c574cb7075b466ab3f6ad8cc28dabb5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8184058793654589 0 215.9508292292257\n",
      "0.843405879365459 0 206.19018216747364\n",
      "0.868405879365459 0 180.93880574374046\n",
      "0.893405879365459 0 206.6386741173798\n",
      "0.918405879365459 0 212.63262653488525\n",
      "New Guess: 0.868405879365459 0.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "682626fb8e2e487ba6540e41caf8b215",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.843405879365459 0 206.19018216747364\n",
      "0.8559058793654589 0 203.9508696244984\n",
      "0.8684058793654589 0 180.93880574374046\n",
      "0.8809058793654588 0 190.5873356924205\n",
      "0.8934058793654588 0 206.6386741173798\n",
      "New Guess: 0.8705303580813294 0.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "783b4fece8474dfb89e768758da594ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8580303580813294 0 201.06806545887088\n",
      "0.8642803580813294 0 183.98855551085148\n",
      "0.8705303580813294 0 180.74920454884904\n",
      "0.8767803580813294 0 186.84215725664637\n",
      "0.8830303580813293 0 194.825116455651\n",
      "New Guess: 0.8698789292739293 0.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d679cbf5fcc423ba3bac713c3017349",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8573789292739293 -1.0 194.02931054950855\n",
      "0.8573789292739293 -0.5 192.75474811169656\n",
      "0.8573789292739293 0.0 202.6500511952986\n",
      "0.8573789292739293 0.5 193.79005099742318\n",
      "0.8573789292739293 1.0 192.51298488591968\n",
      "0.8636289292739293 -1.0 188.68351020977087\n",
      "0.8636289292739293 -0.5 184.72704950800684\n",
      "0.8636289292739293 0.0 185.67588414314156\n",
      "0.8636289292739293 0.5 183.64715840329973\n",
      "0.8636289292739293 1.0 185.70074082826682\n",
      "0.8698789292739293 -1.0 181.85124086522555\n",
      "0.8698789292739293 -0.5 178.52225485365565\n",
      "0.8698789292739293 0.0 180.52628770938796\n",
      "0.8698789292739293 0.5 180.2149232736075\n",
      "0.8698789292739293 1.0 186.8776176199957\n",
      "0.8761289292739293 -1.0 178.10291682855438\n",
      "0.8761289292739293 -0.5 175.44745888798573\n",
      "0.8761289292739293 0.0 186.22529746667593\n",
      "0.8761289292739293 0.5 188.7176209551062\n",
      "0.8761289292739293 1.0 195.3469347984824\n",
      "0.8823789292739292 -1.0 179.60170172529058\n",
      "0.8823789292739292 -0.5 183.74141713414875\n",
      "0.8823789292739292 0.0 193.44052215206565\n",
      "0.8823789292739292 0.5 194.85532204631116\n",
      "0.8823789292739292 1.0 197.70932308703607\n",
      "New Guess: 0.8730761903985677 -0.44261598548853626\n",
      "0.8730761903985677\n"
     ]
    }
   ],
   "source": [
    "curr_guess = 0.8\n",
    "perturbations = [0.1, 0.05, 0.025, 0.0125]\n",
    "\n",
    "for i, pert in enumerate(perturbations):\n",
    "    x, y, br, rescale_factor, angle = SearchOptimalMatch(curr_guess, pert)\n",
    "    curr_guess = rescale_factor\n",
    "    print(f\"New Guess: {curr_guess} {angle}\")\n",
    "    \n",
    "ang_search    = 1\n",
    "x, y, br, rescale_factor, angle = SearchOptimalMatch(curr_guess, perturbations[-1], change_ang=ang_search)\n",
    "curr_guess = rescale_factor\n",
    "\n",
    "print(f\"New Guess: {curr_guess} {angle}\")\n",
    "print(rescale_factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1b9c3b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "three_band = np.dstack([image, image, image])\n",
    "_ = cv2.rectangle(three_band, (y, x), br, (0, 255, 0), 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e7c1eaea",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfw_file        = \"Harris_Boundary_hollow.pgw\"\n",
    "template_affine = get_affine_from_geotransform(get_geotransform_from_tfw(tfw_file)[0])\n",
    "calc_affine     = Affine(1 / rescale_factor, 0, -y, 0, 1 / rescale_factor, -x) * Affine.rotation(angle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a793b040",
   "metadata": {},
   "outputs": [],
   "source": [
    "# out_affine = combineAffine(template_affine, calc_affine)\n",
    "out_affine = template_affine * calc_affine\n",
    "write_world_file_from_affine(out_affine, \"data/TileIndices/48201CIND0_0992.tfw\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
